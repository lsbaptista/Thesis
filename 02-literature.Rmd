\begingroup
\titleformat{\chapter}[display]
{\normalfont\huge\bfseries\centering}{\chaptertitlename\ \thechapter}{20pt}{\Huge}
# Modelação Estatística na Otimização de Portfólios
\newpage

```{r, include=FALSE}
knitr::opts_chunk$set(tidy=FALSE, message = FALSE,warning =  FALSE,fig.align = "center",fig.show = "hold")
```

## Introdução

O valor da cotação de activos financeiros, como acções ou opções, são representados de forma sequencial ao longo do tempo, considerando determinado intervalo, que pode ser segundos, minutos, dias, semanas ou outro intervalo considerado útil para representação dos dados ao longo do tempo. Quando tal acontece estamos em presença de series temporais. 

Os preços de activos financeiros ao longo do tempo formam o que é denominado por processos estocásticos. Processos estocásticos são uma classe de series temporais onde o valor da variável muda ao longo de tempo de forma aleatória. Os processo estocásticos podem ser classificados de discretos ou contínuos, sendo que na análise de activos financeiros, embora estes sigam processos discretos, serão considerados processos estocásticos contínuos ao longo do tempo. Estes modelos acabam por ser bastante úteis na modelização dos preços de activos financeiros de acordo com @Hull2018.

### Modelação do preço de acções

Os preços das acções seguem habitualmente o que é conhecido por um processo de Markov, onde apenas o valor presente importa para prever o valor futuro. Desta forma a única informação relevante é o seu valor no momento, em que os valores e trajecto verificado no passado não irão ter importância na definição da distribuição probabilística do preço no futuro [@Hull2018].Desta forma as propriedades de Markov no preço das acções é consistente com a eficiência dos mercados na forma fraca (o preço dos ativos financeiros reflete toda a informação respeitante aos mesmos), constituindo esta uma das três formas de eficiência de mercado definidas por Eugene Fama^[Ver "https://pt.wikipedia.org/wiki/Eugene_Fama"].

De modo a entender-se melhor o modelo matemático utilizado para simular preços de activos financeiros importa apresentar os modelos que levaram a apresentação final do mesmo, iniciando-se desta forma pela apresentação do modelo de Wiener.

O processo de Wiener é um processo particular do processo estocástico Markov, referido como movimento Browniano, descrevendo a evolução de uma variável com distribuição normal padrão. Para ser considerado um processo de Wiener a variável *z* têm que apresentar as seguintes propriedades:

```{proposition,wiener1}
A mudança dz durante um pequeno periodo de tempo dt é

$$dz = \varepsilon \sqrt{dt}\qquad   \varepsilon \sim N(0,1)$$
```

```{proposition,wiener2}
O valor de dz para dois curtos intevalos de tempo diferentes, dt, são independentes.
```

Desta forma a variável *z* segue um processo de Wiener, sendo uma variável independente e identicamente distribuída (i.i.d), que tem uma distribuição normal e segue um processo de Markov.

A variação da média por unidade de tempo para um processo estocástico é conhecido como *drift rate* sendo que a variância por unidade de tempo é conhecida por taxa de variância. O processo de Wiener apresenta um *drift rate* de 0 e uma taxa de variância de 1. No processo generalizado de Wiener (também conhecido como movimento Browniano (BM)), é incluindo um amplificador/redutor na parte aleatória do processo de forma a ajustar o processo a propriedades especificas de cada activo, ilustrado na equação \@ref(eq:gwiener). Este processo descreve a evolução de um processo de uma variável com distribuição normal, onde $\mu$ representa o valor esperado por unidade de tempo, o *drift rate* e o $\sigma^2$ representa a taxa de variância por unidade de tempo, em que  $\varepsilon \sqrt{dt}\qquad$ representa um processo de Wiener.

 \begin{equation} 
  \delta S = \mu\delta t +\sigma\varepsilon\sqrt{\delta t}\qquad\varepsilon \sim N(0,1);
  (\#eq:gwiener)
\end{equation} 

O termo $\sigma\varepsilon\sqrt{\delta t}$ é o que vai introduzir variabilidade ao caminho percorrido por *S*, sendo que *S* representa o valor do activo no momento *t*. A diferença relativo a um processo de Wiener é que no processo generalizado de Wiener a taxa de desvio e variância pode ter como valor qualquer constante, sendo que no processo de Wiener esses valores são de 0 e 1 respectivamente.

Outro processo estocástico, conhecido como processo Itô, pode ser introduzido, representando um processo generalizado de Wiener, sendo que neste caso o valor dos parâmetros $\mu$ e $\sigma$ são funções do valor subjacente da variável *S* e do tempo *t*. Este modelo é o que vai ser utilizado para simulação do preço das acções sendo representado pelas seguintes equações:

\begin{equation} 
  \frac{\delta S}{S} = \mu\delta t +\sigma\varepsilon\sqrt{\delta t}\qquad\varepsilon \sim N(0,1);
  (\#eq:ito)
\end{equation} 
\begin{equation} 
  In S_1 - InS_0 \approx\phi\Big[\Big(\mu-\frac{\sigma^2}{2}\Big)\delta t, \sigma\sqrt{\delta t}\Big]
  (\#eq:Inito)
\end{equation} 
\begin{equation} 
  S_1 =S_0 e^{\Big(\mu-\frac{\sigma^2}{2}\Big)\delta t + \sigma\varepsilon\sqrt{\delta t}}
  (\#eq:logprice)
\end{equation} 

Nesta equação $S_0$ e o $S_1$ representam o valor do activo no momento inicial e no momento final, o $\mu$ representa a taxa de retorno anual esperado, sendo que $\sigma$ representa o desvio padrão ou volatilidade da acção, parâmetro muito importante para a determinação do valor de vários derivados, havendo várias formas de calcular este valor como veremos mais adiante. Estes valores são função do corrente valor de $S_0$ e do tempo actual *t*. Numa economia neutra face ao risco $\mu$ é igual a taxa de juro sem risco. O $\varepsilon$ representa uma variável com distribuição normal N(0,1). 

Este processo é conhecido como movimento Browniano geométrico (GBM). De acordo com @AppliedFinancial um "GBM pode ser considerado como um movimento probabilístico contínuo no qual o logaritmo da quantidade que varia aleatoriamente segue um movimento Browniano (processo de Wiener) com desvio." Este modelo é a base do modelo de Black-Scholes, que será revisto mais adiante, aquando do cálculo da volatilidade implícita nas opções.

Tendo em consideração a equação \@ref(eq:logprice), *S* segue uma distribuição lognormal. Uma distribuição lognormal é mais realístico de acordo com o movimento do preço das acções, prevenindo que o valor se torne negativo.

Em simulação, este processo é realizado considerando uma distribuição normal com média e variância dada pela equação \@ref(eq:Inito) [@FRM1].

### Simulação de Monte Carlo

A simulação de Monte Carlo consiste na geração de valores a partir de uma determinada distribuição ou amostra, sendo que "o termo Monte Carlo é usado para se referir a técnicas que envolvem simulação computacional"[@ProgSim,pp.457]. 

Ao simular os preços dos activos financeiros iremos utilizar a técnica de Monte Carlo de modo a gerar amostras aleatórias de acordo com a equação \@ref(eq:logprice). Os preços serão simulados criando várias tentativas com valores aleatórios para $\varepsilon$ a partir de N(0,1). A precisão dos valores obtidos na simulação depende do número de tentativas efectuadas, sendo considerado 1000 tentativas por cada dia, em que o cálculo do valor médio dessas tentativas é o valor simulado para cada um dos dias.

## Modelo auto-regressivo de médias móveis (ARMA)

Antes de entrar no tema relativo a volatilidade, vamos introduzir o tema relativo ao modelo auto-regressivo de médias móveis ou ARMA, sendo um modelo que descreve processos estocásticos estacionários, ou seja, processos cujo parâmetros como a média e a variância não mudam ao longo do tempo, combinando dois factores, um relativo ao processo autoregressivo (AR) de ordem *p* e outro relativo à média móvel (MA) de ordem *q*, permitindo desta forma que o número de parâmetros seja pequeno e alcançando parcimônia na parametrização (@parcimonia).

Como a estacionariedade é um pressuposto assente em muitos processos estatísticos utilizados em séries temporais, dados não-estacionários são muitas vezes transformados de modo a tornarem-se estacionários (@station).

Para podermos entender melhor este processo, introduz-se o termo da auto-correlação, referindo-se à medida da relação linear entre valores desfasados ou *lagged values* numa serie temporal, medindo a força e a direcção da associação linear, sendo que os coeficientes de correlação são visualizados em gráfico através da função de auto-correlação ou *ACF* (@foregeorge). Series temporais que não demonstram auto-correlação são designados por ruído branco, apresentando variáveis independentes e distribuídas de forma idêntica com uma média zero. Isso significa que todas as variáveis têm a mesma variância e cada valor tem uma correlação zero com todos os outros valores da série.

O que se pretende ao trabalhar com os retornos doas activos e não com o preço destas, é ter dados que apresentem um processo estocástico estacionário, sendo que os dados não apresentem auto-correlação.

Voltando ao termo ARMA(p,q), onde o *p* representa a ordem da parte referente ao processo autoregressivo, ou seja, ao AR(p), este é útil porque nos fornece um modo de ter dependência em relação ao tempo exibindo um declínio geométrico,sendo que as correlações entre as variáveis mais afastadas no tempo vão diminuindo, podendo ser descrito pela seguinte equação \@ref(eq:ar)

\begin{equation} 
  y_t =c+\phi_1y_{t-1}+\phi_2y_{t-2}+...+\phi_py_{t-p}+\varepsilon_t\qquad   -1<\phi<1
  (\#eq:ar)
\end{equation} 
\begin{equation} 
  \nonumber \varepsilon \sim i.i.d. \quad N(0,\sigma_{\epsilon}^{2})
\end{equation}
onde $\varepsilon$ representa ruído branco e o $\phi$ parâmetros do modelo. No modelo AR(1) o valor de $\phi$ é igual ao valor da autocorrelação no momento de desfasamento 1 (*lag 1*).  O valor de *c* é a média das mudanças entre observações consecutivas. Se *c* for positivo, então a mudança média é um aumento no valor de $y_t$, mas se for negativo ocorrerá o inverso. Um processo autoregressivo AR (1) é aquele em que o valor atual é baseado no valor imediatamente anterior, enquanto um processo AR (2) é aquele em que o valor atual é baseado nos dois valores anteriores. Um processo AR (0) é usado para ruído branco e não tem dependência entre os termos. 

A interpretação deste modelo é que os valores presentes da variável dependem do seu valor passado.

O *q* refere-se à ordem da média móvel, ou MA(q), descrito do seguinte modo:

\begin{equation} 
  y_t =c+\varepsilon_t+\theta_1\varepsilon_{t-1}+\theta_2\varepsilon_{t-2}+...+\theta_q\varepsilon_{t-q}\qquad   -\infty<\theta<\infty 
  (\#eq:ma)
\end{equation}
\begin{equation} 
  \nonumber \varepsilon \sim i.i.d. \quad N(0,\sigma_{\epsilon}^{2})
\end{equation} 

A variável $y_t$ é uma série de variáveis aleatórias não correlacionadas com média zero e variância constante, sendo $\theta$ o parâmetro relativo à média móvel, onde a média móvel utiliza valores referentes aos erros no modelo de regressão. Este modelo é ideal, por exemplo quando se quer criar um modelo que apenas exibe dependência em relação a um período, como em retornos sobrepostos, na evolução de taxas de juro e para a taxa crescimento de variáveis macroeconómicas.

O modelo ARMA(p,q) é definido pela equação \@ref(eq:arma)

\begin{equation} 
  y_t =c+\phi_1y_{y-1}+...+\phi_py_{y-p}+\theta_1\varepsilon_{t-1}+...+\theta_q\varepsilon_{t-q}
  (\#eq:arma)
\end{equation}

No mundo real, os processos de retorno podem ser estacionários, combinado-se o modelo ARMA e o modelo GARCH, onde usamos ARMA para ajustar a média e GARCH para ajustar a variância, visto que nos modelos ARMA a variância condicional dado o passado é constante.

De acordo com @oscar:
\begin{spacing}{1}
\begin{adjustwidth}{28.3464pt}{28.3464pt}\footnotesize
"Para entender melhor o modelo ARMA-GARCH, devemos esclarecer a distinção entre a média e variância incondicional e a variância e média  condicional de uma série temporal de retornos. A média incondicional e a variância são apenas a média e a variância da distribuição dos retornos, que são assumidos como constantes ao longo do todo o período considerado. Pode ser considerada como a média e a variância média de longo prazo durante esse período. Por exemplo, se o modelo for o simples "os retornos são independentes e distribuídos de forma idêntica (i.i.d.)", podemos desconsiderar a ordenação dos retornos na amostra e apenas estime a média e a variância da amostra.
Por outro lado, a média condicional e a variância condicional mudarão a cada momento. A média condicional e a variância condicional dependem do histórico de retornos até aquele ponto. Ou seja, nós contamos com as propriedades dinâmicas dos retornos, considerando sua distribuição em qualquer ponto no tempo como sendo condicional a todos as informações até esse ponto. As previsões feitas a partir dos modelos ARMA-GARCH não são iguais às atuais estimativas. Em vez disso, as previsões de retorno e volatilidade podem ser maiores ou menores do que a média no curto prazo, mas a medida que o horizonte de previsão aumenta as previsões de retorno e de volatilidade convergem para a volatilidade incondicional de longo prazo." (p.17)
\normalsize\end{adjustwidth}
\end{spacing}
\medskip

## Volatilidade

Na indústria financeira o desvio padrão associado a instrumentos financeiros é definido como volatilidade. Desta forma quando estamos a falar de volatilidade estamos a considerar o desvio padrão observado.

De acordo com @HullRisk2018:
\begin{spacing}{1}
\begin{adjustwidth}{28.3464pt}{28.3464pt}\footnotesize
"A variável volatilidade, $\sigma$, é definida como o desvio padrão do retorno fornecido pela variável por unidade de tempo quando o retorno é expresso usando juros compostos. Quando a volatilidade é usada para valorizar opções, a unidade de tempo é normalmente 1 ano, sendo a volatilidade o desvio padrão do retorno compostos por ano. Quando a volatilidade é usada para a gestão de risco, a unidade de tempo usual é 1 dia de forma a que a volatilidade é o desvio padrão do retorno composto por dia." (pp.213-214)
\normalsize\end{adjustwidth}
\end{spacing}
\medskip
Vários são os modelos para cálculo da volatilidade, sendo que um dos modelos mais simples é o do cálculo da variância de acordo com a equação \@ref(eq:estdesviopadrao) utilizando os dados históricos dos retornos, sendo que neste modelo o peso atribuído aos dados é o mesmo independentemente da sua antiguidade. Outros modelos como a média móvel exponencial ponderada (EWMA) e heteroscedasticidade condicional auto-regressiva generalizada (GARCH) são modelos, que embora utilizem dados históricos, reconhecem que tanto a volatilidade como a correlação não são constantes ao longo do tempo, atribuindo maior peso aos dados mais recentes. Por fim, um dos modelos que não integra dados históricos mas sim as expectativas futuras para o cálculo da volatilidade é o da volatilidade implícita, utilizando o modelo de Black-Scholes-Merton na valorização das respectivas opções relativamente ao subjacente.

Nos cálculos que utilizem dados históricos a escolha do tamanho da amostra *n* deve ser grande o suficiente de modo a garantir uma melhor precisão nas estatísticas obtidas, sendo que neste caso devemos considerar que a volatilidade não é constante ao longo do tempo e que valores mais antigos podem não ser tão relevantes como os valores mais recentes. De acordo com [@Hull2018] esse valor deve ser compreendido entre 90 a 180 dias para a cotação de activos. 

Para o cálculo da volatilidade anual utiliza-se os número de dias de negociação, sendo considerado 252 dias por ano como valor de referência.

### Heterocedasticidade condicional auto-regressiva  (ARCH)

Existem equações para o cálculo da variância que atribuem igual peso aos valores passados independentemente da sua antiguidade. Outros métodos atribuem mais peso aos dados mais recentes, pois pressupõem-se que esses carregam mais informação útil acerca da variável em estudo, criando modelos que prevêem com menor erro os valores futuros em estudo.

Uma das formas de cálculo da variância por dia tendo em consideração os valores mais recentes dos retornos é aplicando a equação

\begin{equation} 
  \sigma_{n}^{2} =\sum_{i=1}^{m}\alpha_i r_{n-1}^{2}
  (\#eq:weight)
\end{equation} 
A variável $\alpha$ representa o peso associado a observação *i* dos retornos, sendo que a soma dos respectivos pesos deve ser igual a 1. O *n* representa o período em análise (dia, semana, ...), o *m* é o número de observações e o *r* representa o retorno nesse período de tempo.

Tendo em consideração @Hull2018 se a média a longo prazo da taxa de variância for considerada e assignado um peso a ela então teremos

\begin{equation} 
  \sigma_{n}^{2} =\gamma\mathcal{V}_{L}+\sum_{i=1}^{m}\alpha_i r_{n-1}^{2}
  (\#eq:arch)
\end{equation} 
sendo que $\mathcal{V}_{L}$ é a taxa de variância de longo prazo e $\gamma$ é o peso associado a $\mathcal{V}_{L}$, sendo que os repectivos pesos devem somar 1, de acordo com $$\gamma + \sum_{i=1}^{m}\alpha_i = 1$$


A equação \@ref(eq:arch) é conhecida como um modelo Heterocedasticidade condicional auto-regressiva ou ARCH(m)^[Introduzido por Robert F.Engle em 1982, tendo-lhe sido atribuído o prémio Nobel da economia em 2003], sendo que em finanças é uma das classes de modelos mais utilizada para prever a volatilidade. A variável aleatória *r* segue uma distribuição normal, sendo no entanto prática comum considerar outros tipos de distribuições, como a distribuição t-student, devido ao factos da distribuição dos retornos apresentarem caudas mais pesadas que uma distribuição normal.

Auto-regressivo significa que a variância presente depende do seu próprio passado e não num regressor exógeno. O facto de ser condicional significa que a variância de amanhã depende das variâncias mais recentes. Já a heteroscedasticidade significa que a variância não é constante ao longo do tempo.

O pressuposto destes modelos é que a variância dos retornos seguem um processo previsível, sendo que os modelos ARCH são menos convincentes na previsão quando a volatilidade têm alterações bruscas. A apresentação do modelo ARCH serve como forma introdutória de apresentação aos modelos da média móvel exponencial ponderada (EWMA) e heteroscedasticidade condicional auto-regressiva generalizada (GARCH).

### Média móvel exponencial ponderada (EWMA)

O modelo da média móvel exponencial ponderada (EWMA) é um estimador calculado a partir de amostras sequenciais da população onde é atribuindo maior peso aos valores mais recentes, sendo que esse peso diminui exponencialmente a medida que vamos recuando no tempo. A formula utilizada para actualizar o valor para a volatilidade é

\begin{equation} 
  \sigma_{n}^{2} = \lambda\sigma_{n-1}^{2}+(1-\lambda) r_{n-1}^{2} 
  (\#eq:ewma)
\end{equation} 
sendo um caso particular da equação \@ref(eq:weight), onde os pesos $\alpha_{i}$ diminuem exponencialmente à medida que nos afastamos no tempo. Neste caso $\alpha_{i+1} = \lambda\alpha_{i}$, onde 0<$\lambda\leq1$ representa o factor de decaimento, sendo $\sigma_{n-1}^{2}$ a estimativa da volatilidade realizada no dia n-1, e $ r_{n-1}$ a mudança percentual diária mais recente no retorno. Para o valor de $\lambda$ atribuído na equação "estudos empíricos mostram que o fator de decaimento ($\lambda$) com valor de 0,94 fornece uma boa estimativa para todos os ativos."[@riskmetrics,p.4]

De modo a entender porque à volatilidade obtida através da EWMA correspondem pesos que diminuem exponencialmente vamos substituir $\sigma_{n-1}^{2}$ pela lado direito da igualdade da equação \@ref(eq:ewma) de  modo a obter

\begin{equation} 
  \sigma_{n}^{2} = (1-\lambda)(r_{n-1}^{2}+\lambda r_{n-2}^{2})+\lambda^{2}\sigma_{n-2}^{2}
  (\#eq:ewma1)
\end{equation} 
Continuando a substituir acabamos por obter
\begin{equation} 
  \sigma_{n}^{2} = (1-\lambda)\sum_{i=1}^{m}\lambda^{i-1} r_{n-1}^{2}+\lambda^{m} r_{n-m}^{2}
  (\#eq:ewma2)
\end{equation}

Como podemos ver pela equação \@ref(eq:ewma2) o "peso de $r_{i}$ decresce a uma taxa $\lambda$ a medida que vamos recuando no tempo. Cada peso é $\lambda$ vezes o peso anterior." [@HullRisk2018,p.226]. Como os pesos diminuem geometricamente, o EWMA também é referido como média móvel geométrica. 

### Heteroscedasticidade condicional auto-regressiva generalizada (GARCH)

Em 1986 um modelo mais flexível que o modelo ARCH foi proposto, sendo este o modelo generalizada ARCH^[Introduzido por Bollerslev(1986)]. De acordo com @volatilitymodels "Uma grande vantagem dos modelos GARCH é que os retornos não são assumidos independentes, e mesmo se forem assumidos condicionais gaussianos para retornos anteriores, incondicionalmente, eles não são gaussianos, porque o agrupamento de volatilidade gera leptocurtose"(p.2). Também, e de acordo com @portanalyse, "A volatilidade agora depende de ambos, uma combinação linear dos erros quadráticos da previsão (um termo autoregressivo) e variâncias condicional passada (um termo de média móvel)."(p.136)

A equação que define o modelo GARCH(1,1) é

\begin{equation} 
  \sigma_{n}^{2} = \gamma\mathcal{V}_{L} + \alpha r_{n-1}^{2} + \beta\sigma_{n-1}^{2}
  (\#eq:garch)
\end{equation}

onde $\gamma$ é o peso atribuído a $\mathcal{V}_{L}$, $\alpha$ é o peso atribuído a $r_{n-1}$ e $\beta$ é o peso atribuído a $\sigma_{n-1}$. Nesta equação, verifica-se que $\sigma_{n}^{2}$ é calculado a partir da taxa de variância média de longo prazo $\mathcal{V}_{L}$, como também a partir de $\sigma_{n-1}$ e $r_{n-1}$, sendo que o modelo EWMA é um caso particular do modelo GARCH(1,1) onde $\gamma=0$, $\alpha=1-\lambda$ e $\beta=\lambda$. Tal como referido nos modelos anteriores, a soma dos diferentes pesos deve ser igual a 1, sendo $$\gamma+\sigma+\beta=1$$

O modelo genérico de GARCH é GARCH(p,q) onde o modelo calcula $\sigma_{n}^{2}$ a partir das observações *p* mais recentes de $r^2$ e as mais recentes estimações *q* da taxa de variância. Desta forma, o modelo "'(1,1)' em GARCH(1,1) indica que $\sigma_{n}^{2}$ é baseado nas mais recentes observações de $r^2$ e nas mais recentes estimações da taxa de variância."[@Hull2018,p.227]

Considerando $\omega=\gamma\mathcal{V}_{L}$, o modelo GARCH(1,1) pode ser definido como

\begin{equation} 
  \sigma_{n}^{2} = \omega + \alpha r_{n-1}^{2} + \beta\sigma_{n-1}^{2}
  (\#eq:garch2)
\end{equation}

A equação \@ref(eq:garch2) é a que costuma ser utilizada de forma a estimar os parâmetros. De notar de que para obter um processo estável GARCH(1,1) é necessário que $\sigma+\beta<1$, ou então o peso aplicado a variância de longo prazo é negativo. A soma $\sigma+\beta$ representa o que é conhecido como a persistência. A persistência num modelo GARCH representa o modo como a volatilidades decai rapidamente após um grande choque. Se o valor para a persistência for elevado isso significa que as observações distantes um do outro ainda estão fortemente correlacionados e que decaem a um ritmo lento.

A estimação dos parâmetros, tanto para o modelo EWMA como para o modelo GARCH(1,1), é realizado utilizando um processo conhecido como verosimilhança máxima, onde se utilizam os dados históricos de modo a escolher os parâmetros que maximizem a probabilidade de ocorrência dos dados, de acordo com a equação

\begin{equation} 
  \sum_{i=1}^{m}\bigg[-ln(\sigma_{i}^{2})-\frac{r_{i}^{2}}{\sigma_{i}^{2}}\bigg]
  (\#eq:mgarch)
\end{equation}

Os modelos standard GARCH não apresentam resposta adequada em modelos onde os dados tenham diferenças significativas devido ao impacto de boas ou más noticias, por exemplo, no comportamento da variável em estudo, sendo que existem outros modelos desenvolvidos com base no modelo standard GARCH para dar resposta a essas oscilações, como o modelo EGARCH. 

### Heteroscedasticidade condicional auto-regressiva generalizada exponencial (EGARCH)

O modelo EGARCH será utilizado na modelação da volatilidade da cotação de uma das empresas aqui em análise, sendo importante uma breve descrição do modelo. 

Este modelo foi desenvolvido para capturar as assimetrias na volatilidade induzidas por grandes oscilações positivas e negativas nos retornos dos activos.

De acordo com @marta este modelo é expresso pela equação onde a variância condicionada, $\sigma_t^2$ é uma função assimétrica dos valores passados de $r_t$, ou seja:

\begin{equation} 
  Ln \sigma_{n}^{2}= \alpha_0+\sum_{i=1}^n\beta_iln\sigma_{n-1}^2+\sum_{i=1}^n\alpha_i(\frac{|r_{n-i}|}{\sigma_{n-i}})+\sum_{i=1}^n\gamma_i(\frac{r_{n-i}|}{\sigma_{n-i}})
  (\#eq:egarch)
\end{equation}
sendo que $\alpha_0$, $\beta_i$, $\alpha_i$ e $\gamma_i$ são parâmetros do modelo, $r_{t-i}$ o retorno observado em *n-i* e $\sigma_{t-i}$ o desvio padrão observado em *n-i*. Também, e de acordo com @marta o "modelo EGARCH garante que a variância será sempre positiva, por ser apresentada em logaritmos, sendo isto um fator vantajoso"(p.17). No entanto, e devido a sua extrutura exponencial, o modelo pode sobrestimar o impacto de observações anómalas na volatilidade.

### Volatilidade implícita

O modelo de Black-Scholes-Merton^[Os autores, Robert Merton e Myron Scholes, foram reconhecidos com o Nobel da economia em 1997] foi um modelo desenvolvido nos anos 70, considerado um ponto de ruptura na definição do preço de opções sobre acções europeias. 

De entre os pressupostos^[Para mais informação ver @BlackScholes,pp. 640, capitulo "The valuation formula"] utilizados para derivar a equação diferencial, importa salientar de que a taxa de juro sem risco, $r_j$, é constante e a mesma ao longo do tempo. De acordo com @Hull2018 "É importante considerar que a avaliação sem risco (ou o pressuposto de que todos os investidores são neutros ao risco) é meramente um artifício para obter solução para a equação diferencial de Black-Scholes-Merton"(p.312).

O processo que se assume ser aplicado ao preço dos activos é o descrito pela equação \@ref(eq:ito). De salientar de que nenhumas das variáveis da equação é afectada pelas preferências de risco dos investidores, sendo que as variáveis que aparecem na equação são o valor presente do activo financeiro, tempo, volatilidade e a taxa de juro sem risco. 

As soluções obtidas a partir da equação diferenciável de interesse para cálculo da volatilidade implícita, são as aqui apresentadas para valorizar opções de compra (*call*) e opções de venda (*put*) do tipo europeias:

\begin{equation} 
  c = S_0N(d_1) - Ke^{-r_{j}T}N(d_2);
  (\#eq:call)
\end{equation} 
e
\begin{equation} 
  p = Ke^{-r_{j}T}N(-d_2) - S_0N(-d_1);
  (\#eq:put)
\end{equation} 
onde
\begin{equation} 
  d_1 = \frac{In(S_0/K)+(r_{j}+\sigma^2/2)T}{\sigma\sqrt{T}}
  (\#eq:d1)
\end{equation}
\begin{equation} 
  d_2 = \frac{In(S_0/K)+(r_{j}-\sigma^2/2)T}{\sigma\sqrt{T}}=d_1-\sigma\sqrt{T}
  (\#eq:d2)
\end{equation}

A função N(d) representa a função distribuição para uma distribuição normal padrão, sendo a probabilidade de uma variável ser menor que d (ver exemplo na figura \@ref(fig:fdistribuicao)). O valor de N(d) pode ser obtido com a função do R pnorm(). A variável *T* representa o tempo medido em dias de negociação que faltam até a expiração da opção dividido pelos dias de negociação nesse ano, sendo *S~0~* o valor do activo subjacente no tempo 0, *$r_j$* a taxa de juro sem risco, $\sigma$ a volatilidade anual e *K* o preço de exercício da opção.

```{r, fdistribuicao,echo=FALSE,fig.cap='Função distribuição N(d)',out.width="45%"}
knitr::include_graphics("image/fdistribuicao.png")
```
\FloatBarrier
\centering 
Fonte: Elaboração própria.

\justifying
\bigskip

O parâmetro da volatilidade não é um parâmetro que se consiga obter ou observar directamente, sendo um valor que representa a volatilidade esperada pelos investidores no futuro, conhecido como *volatilidade implícita*. Um modo de obter este valor é a partir dos restantes parâmetros, ou seja, tendo o valor de uma opção de compra, e considerando os valores de *S~0~*, *K*, *$r_j$* e *T*, substituir estes pelos respectivos valores e obter o valor de $\sigma$ que iguale o valor da *call* utilizando as equações \@ref(eq:call) e \@ref(eq:d1) através de processos por aproximação iterativo. 

A volatilidade implícita será diferente consoante o preço de exercício da opção, considerando todos os outros parâmetros iguais. Da conjugação dos valore de volatilidade obtidos para cada um dos preços de exercício da opção obtêm-se um gráfico conhecido como *volatility smile* (figura \@ref(fig:volatilitysmile)). Este gráfico será o mesmo, quer se esteja a considerar uma opção do tipo *call* ou a mesma equivalente opção do tipo *put*.

```{r, volatilitysmile,echo=FALSE,fig.cap='Volatility Smile',out.width = "60%"}
knitr::include_graphics("image/volatilitysmile.png")
```
\FloatBarrier
\centering 
Fonte: [@volatilitysmile, pp.182]

\justifying
\bigskip
Como de pode ver pela figura \@ref(fig:volatilitysmile) a opção é considerada *out-the-money* se o seu valor for inferior ao do respectivo subjacente, *at-the-money* se for superior e *in-the-money* se o valor for igual. No cálculo do valor da volatilidade será utilizado o valor de preço de exercício *in-the-money* de opções do tipo *call*, ou na impossibilidade do valor do subjacente ser o mesmo do *K*, o mais próximo deste.

Quando comparado com outros métodos para calcular a volatilidade onde os dados utilizados são dados históricos, este método incorpora o sentimento presente dos investidores relativo a volatilidade futura de um determinado ativo ou instrumento financeiro.

## Portefólios média-variância

A otimização de portefólios através da diversificação é um conceito básico que teve origem em @Markowitz1952, criando o conceito de fronteira eficiente, onde dado um conjunto de ativos financeiros é possível combiná-los formando infinitas combinações, e deste modo  portefólios, de acordo com as restrições que se queira aplicar aos mesmos.

Para aplicação deste modelo deve-se obter os seguintes dados dos instrumentos financeiros que vão constituir o portefólio:

- A taxa do retorno esperado, E(r);
- O desvio padrão dos retornos, $\sigma$;
- O coeficiente de correlação,$\rho$, entre cada um dos activos.

O retorno esperado vai depender de vários factores, como a taxa de retorno sem risco que se verifica no mercado, a taxa de inflação e o risco a que o investidor estará sujeito, sendo que quanto maior o risco, maior será o retorno esperado.

As séries dos retornos diários para cada um dos activos é calculada de acordo com a seguinte equação:

\begin{equation} 
  R_i = ln\Big(\frac{S_1}{S_0}\Big)
  (\#eq:logRet)
\end{equation} 
onde  $S_0$ e o $S_1$ representam o valor do activo no momento inicial e no momento final.
A média dos retornos de cada um dos activos é calculada de acordo com a sua média aritmética:
\begin{equation} 
  \overline{R} = \frac{\displaystyle\sum_{i=1}^n R_i}{n}
  (\#eq:meanRet)
\end{equation}  
O retorno de um portefólio de activos financeiros será uma média ponderada do retorno dos activos individuais, de acordo com a seguinte equação
\begin{equation} 
    R_{p} = \sum_{i=1}^{N}(X_{i}R_{ij})
  (\#eq:retp)
\end{equation}
onde $X_{i}$ representa a fracção investida no activo *i*.
O desvio padrão representa a volatilidade, ou risco, associada ao activo. Considerando que essa volatilidade é calculada com base nos dados históricos e nas formulas acima, então a estatística da amostra para o desvio padrão representa-se pela seguinte formula:

\begin{equation} 
  \hat{\sigma} = \sqrt\frac{\displaystyle\sum_{i=1}^n (R_i-\overline{R})^2}{n-1}
  (\#eq:estdesviopadrao)
\end{equation} 

A variância para o portefólio é um pouco mais complicada a calcular do que o cálculo para o retorno e para as variância individuais de cada um dos activos, como podemos verificar pela seguinte equação

\begin{equation} 
  \sigma_{p}^{2} = \sum_{j=1}^{N}(X_{j}^{2}\sigma_{j}^{2})+\sum_{j=1}^{N}\sum_{k=1}^{N}(X_{j}X_{k}\sigma_{jk})
  (\#eq:estdesviopadraop)
\end{equation} 
onde $k\neq j$ de modo não repetir a variância de cada um dos ativos, representada no primeiro somatório da equação. O termo $\sigma_{jk}$ designa-se por covariância representando o modo como 2 activos se movem conjuntamente, sendo o valor calculado do seguinte modo,

\begin{equation} 
  Cov(R_{i},R_{j}) = E([R_{i}-E(R_{i})][R_{j}-E(R_{j})])
  (\#eq:covariancia)
\end{equation} 

Se todos os termos forem independentes, isto é, a covariância for igual a 0, então apenas se mantêm o primeiro termo/somatório na equação\@ref(eq:estdesviopadraop).

Quando se pretende interpretar o valor da covariância é prática comum utilizar o que se designa por coeficiente de correlação, sendo que o valor obtido varia entre -1 e +1, sendo que o -1 representa uma correlação negativa perfeita e o +1 uma correlação positiva perfeita. Se o valor for 0 então não existe relação linear entre as variáveis. De forma genérica podemos afirmar que a correlação mede a força da relação linear entre 2 variáveis, sendo a sua forma matemática $$\rho_{ij}=\frac{\sigma_{ij}}{\sigma_{i}\sigma_{j}}$$
Aos incluir-mos mais activos no nosso portefólio estamos a diversificar o risco e a diminuir a variância esperada do portefólio. De acordo com @Goetzmann2014:
\begin{spacing}{1}
\begin{adjustwidth}{28.3464pt}{28.3464pt}\footnotesize
"A contribuição para a variância da carteira da variância dos títulos individuais vai para zero à medida que N fica muito grande. No entanto, a contribuição dos termos de covariância aproxima-se do valor da covariância média conforme N aumenta.O risco individual dos activos pode ser diversificados, mas a contribuição para o risco total causado pelos termos de covariância não podem ser diversificados" (pp.56-57).
\normalsize\end{adjustwidth}
\end{spacing}
\medskip
Na (figura \@ref(fig:covusa)) podemos ver que a partir de um determinado número de activos, normalmente compreendido entre 15 e 20, a percentagem de risco que pode ser eliminada pela diversificação estabiliza.

(ref:covusa) Evolução da covariância ao aumentar a diversificação no portefólio.
```{r, covusa, echo=FALSE, fig.cap="(ref:covusa)", out.width="60%"}
knitr::include_graphics("image/covusa.png")
```
\FloatBarrier
\centering 
Fonte: [@Goetzmann2014, pp.58]

\justifying
\bigskip

Com base no apresentado até agora, o que se propõe é optimizar um portefólio em que os activos que o constituem apresentem pesos de modo a minimizar o risco, ou seja, minimizar a variância total, sem a possibilidade de vendas a descoberto e de investimento em activos sem risco, determinando a carteira eficiente. O problema a que se propõe é minimizar  $\sigma_{p}^{2}$ de acordo com a equação \@ref(eq:estdesviopadraop), sujeito ás seguintes restrições:

\begin{equation} 
  \sum_{i=1}^{N}X_{i}\overline{R}_{i}=\overline{R}_{p}
  (\#eq:und)
\end{equation} 
$$X_{i}\geq0$$ e $$\sum_{i=1}^{N}X_{i}=1$$
O problema pode ser resolvido construindo a função Lagrangeana

\begin{equation} 
  \mathcal{L} = \sum_{i=1}^{N}\sum_{k=1}^{N}(X_{i}X_{k}\sigma_{ik})+\lambda_{1}(\overline{R}_{p}-\sum_{i=1}^{N}X_{i}\overline{R}_{i})+\lambda_{2}(1-\sum_{i=1}^{N}X_{i})
  (\#eq:lagrangeana)
\end{equation} 
embora a sua resolução envolva normalmente métodos computacionais. 

Desta forma, se considerar-mos a figura \@ref(fig:eficient) a fronteira eficiente para o conjunto de portefólios encontra-se entre o ponto II e o ponto III, sendo que de acordo com os pressupostos de minimização do risco o ponto referente a II é o que apresenta um menor risco na fronteira eficiente definida.

(ref:eficient) Fronteira eficiente
```{r, eficient, echo=FALSE, fig.cap="(ref:eficient)", out.width="60%"}
knitr::include_graphics("image/eficient.png")
```
\FloatBarrier
\centering 
Fonte: [@invest, p.33]

\justifying
\medskip
A definição e optimização de portefólios está sujeita a outras restrições que não serão aqui apresentadas, tais como custos de *trading*, custos de oportunidade ou custos associados a regulamentação e fiscalidade^[O artigo @Fabozzi2014 "60 Years of portefólio optimization:Practical challenges and current trends" aborda várias outras restrições na abordagem da optimização na média-variância proposta por Markowitz].

## Value at Risk (VaR)

A quantificação do risco é fundamental para a gestão e atenuação de perdas no valor da carteira ao longo do tempo. Na gestão da carteira a aplicação de métricas de risco permite a adaptação contínua do portfólio aos fatores de risco quantificáveis, podendo-se, através de uma gestão ativa, manter o investidor devidamente informado relativamente ao risco que o seu investimento incorpora e poder tomar medidas proactivas de adaptação do investimento ao nível de risco verificado, tendo em consideração o perfil do investidor.O Value at Risk (VaR) é uma dessas métricas de risco.

O Value at Risk (VaR)^[Markowitz foi dos primeiros autores a contemplar a análise de risco em investimentos, como se pode verificar em @Markowitz1952] é uma medida probabilística para a perda máxima provável de uma carteira para um nível de confiança determinado,num horizonte temporal especificado. Pode-se definir o VaR como "descrevendo o quantil da distribuição de ganhos e perdas projectado ao longo do horizonte alvo. Se *c* for o intervalo de confiança selecionado, VaR corresponde ao nível inferior da cauda 1-*c* "[@philippe,pp.17]. Este valor é sempre positivo.

O cálculo do valor do VaR é de carácter obrigatório para entidades financeiras e seguradoras, sendo que os reguladores, dependendo da sua jurisdição, determinam os parâmetros quantitativos a serem utilizados.
No caso do Banco Central Europeu^[ver relatório técnico @ecb], esses parâmetros são de que o cálculo deve ser efectuado para um intervalo temporal de 10 dias de negociação e para um intervalo de confiança de 99%, sendo considerado para esses cálculos pelo menos 250 dias negociação de observação de valores históricos.

O cálculo do VaR pode ser realizado de modos diferentes, existindo vários métodos, sendo considerados métodos de tipo não paramétrico, como o método histórico em que não se assume nenhum pressuposto na distribuição desses dados, ou métodos do tipo paramétrico, onde se assume um determinado tipo de distribuição dos dados. Para efeito desta dissertação será aplicado um método paramétrico para cálculo do VaR.

### VaR Paramétrico (Gaussiana)

O VaR paramétrico pressupõe que os retornos diários apresentem uma distribuição normal (figura \@ref(fig:var)), sendo que a sua representação matemática se encontra definida na equação \@ref(eq:var).

\begin{equation} 
  VaR_{t+1}^{p} = -\sigma_{t+1}\Phi_{p}^{-1}
  (\#eq:var)
\end{equation} 
(ref:var) VaR com intervalo confiança 95% e 99%. 
```{r, var, echo=FALSE, fig.cap="(ref:var)", out.width="60%"}
knitr::include_graphics("image/VaR.png")
```
\FloatBarrier
\centering 
Fonte: [@phdthesis, pp.13]

\justifying
\bigskip
O $\Phi (p)$ representa a função distribuição e $\Phi^{-1} (p)$ a sua inversa, sendo que, por exemplo, para um intervalo de confiança de 99% o valor de $\Phi^{-1} (p)$ corresponde a -2.33. Se considerarmos que a volatilidade prevista a 1 dia é de 2%, teremos um VaR = -0.020*(-2.33), o que corresponde a um valor de 0.0466. Podemos interpretar o VaR como sendo a existência de 1% de probabilidade de perder mais do que 4.66% do valor investido no activo no dia de hoje. 

O *Daily Value at Risk* (DEaR) é o valor diariamente em risco, sendo calculado de acordo com a equação \@ref(eq:dear).

\begin{equation} 
  €DEaR = € \textnormal{Valor de mercado do investimento} * VaR
  (\#eq:dear)  
\end{equation} 

O valor do VaR a mais de um dia pode-se calcular a partir do DEaR a um dia, de acordo com a equação \@ref(eq:vardays), onde N representa o número de dias.

\begin{equation} 
  VaR = DEaR*\sqrt{N}
  (\#eq:vardays)
\end{equation} 

Se estivermos a analisar o VaR de um portefólio, esse é calculado da mesma forma que a variância de um portefólio (equação \@ref(eq:varport)), considerando o DEaR individual de cada componente.

\begin{equation} 
  DEaR_{portefólio}^{2} = \sum_{i=1}^{N}\sum_{j=1}^{N}Cov(DEaR_i,DEaR_j)
  (\#eq:varport)
\end{equation} 
onde
\begin{equation} 
  Cov(DEaR_i,DEaR_j) = DEaR_{i}DEaR_{j}\rho(DEaR_i,DEaR_j)
  (\#eq:covport)
\end{equation}

Por exemplo, considerando 2 activos, A e B, constituintes de um portefólio, teríamos:

\begin{equation} 
  DEaR_{A+B}^{2} = DEar_{A}^{2}+DEaR_{B}^{2}+2\rho_{AB} DEaR_{A} DEaR_B
  (\#eq:ab)
\end{equation}

### VaR Paramétrico (Aproximação Cornish-Fisher)

Quando a distribuição dos retornos apresentam excesso de curtose^[medida de dispersão que caracteriza o achatamento da curva da função de distribuição] e/ou assimetria^[permite distinguir as distribuições assimétricas] relativamente a uma distribuição normal pode-se proceder à aproximação Cornish-Fisher, permitindo desta forma uma aproximação ao VaR. Por exemplo, na figura \@ref(fig:quant) temos uma distribuição com curtose leptocúrtica, sendo caracterizada por um pico mais alto e caudas mais pesadas que uma distribuição normal.
\bigskip

```{r, quant,echo=FALSE,fig.cap='Curtosis',out.width = "60%"}
knitr::include_graphics("image/kurtosis.png")
```
\centering 
Fonte: [@quant, pp.46]

\justifying

O cálculo do VaR com aproximação Cornish-Fisher (CF) efectua-se de acordo com a equação \@ref(eq:varcf), sendo que para calcular o valor referente a CF se aplica a equação \@ref(eq:cf).

\begin{equation} 
  VaR_{t+1}^{p} = -\sigma_{t+1}*CF_{p}^{-1}
  (\#eq:varcf)
\end{equation} 
onde
\begin{equation} 
  CF_{p}^{-1} = \Phi_{p}^{-1} + \frac{\zeta_{1}}{6}[(\Phi_{p}^{-1})^2-1] + \frac{\zeta_{2}}{24}[(\Phi_{p}^{-1})^3-3\Phi_{p}^{-1}] - \frac{\zeta_{1}^{2}}{36}[2(\Phi_{p}^{-1})^3-5\Phi_{p}^{-1}]
  (\#eq:cf)
\end{equation}

Os parâmetros referentes a $\zeta_1$ e $\zeta_2$ são respectivamente os valores da assimetria e do excesso de curtose. Esses valores são obtidos de acordo com as equações \@ref(eq:assimetria) e \@ref(eq:curtose).

\begin{equation} 
 \zeta_1 = \frac{1}{n}\sum\bigg[\frac{X_i - \overline{X}}{\sigma}\bigg]^3
  (\#eq:assimetria)
\end{equation} 
\begin{equation} 
 \zeta_2 = \frac{1}{n}\sum\bigg[\frac{X_i - \overline{X}}{\sigma}\bigg]^4 - 3
  (\#eq:curtose)
\end{equation} 
