% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  12pt,
  a4paper,
  openany]{book}
\usepackage{lmodern}
\usepackage{setspace}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
  \setmainfont[]{Arial}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[left=3.5cm,right=2cm,top=3cm,bottom=3cm, asymmetric]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\pagestyle{plain}
\usepackage{booktabs}
\usepackage{amsmath,amsfonts,amsthm,bm} % Math packages
\usepackage{mathtools, cases}
\usepackage{fontspec}
\usepackage[utf8]{inputenc}
\usepackage[portuguese]{babel}

\usepackage{etoolbox}

\usepackage{ragged2e}

\usepackage{titlesec}

\usepackage{setspace}

\usepackage{changepage}

\usepackage{graphicx}
\usepackage{placeins}

\usepackage{makeidx}
\makeindex
\usepackage[nottoc]{tocbibind}

\makeatletter
\patchcmd{\ttl@save@mkschap}{*}{}{}{}
\makeatother
\usepackage{indentfirst}
\usepackage{floatrow}
\floatsetup[figure]{capposition=top}
\floatsetup[table]{capposition=top}
\usepackage{subfig}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\ifluatex
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{apalike}

\author{}
\date{\vspace{-2.5em}}

\begin{document}

%titlepage
\thispagestyle{empty}
\begin{center}
\begin{minipage}{0.90\linewidth}
    \centering
%University logo
    \includegraphics[width=1\textwidth]{image/biglogo.png}

%Thesis title
    {\uppercase{\Large Impacto da volatilidade na otimização de portfolios financeiros\par}}
    \vspace{2cm}
%Author's name
    {\Large Leonel da Silva Baptista\par}
    \vspace{2cm}
%Degree
    {\Large Mestrado em Estatística, Matemática e Computação\par}
    {\Large Ramo Estatística Computacional\par}
    \vspace{2cm}

%Date
    {\Large 2020}
\end{minipage}
\end{center}


%titlepage
\thispagestyle{empty}
\begin{center}
\begin{minipage}{0.90\linewidth}
    \centering
%University logo
    \includegraphics[width=1\textwidth]{image/logo.png}

%Thesis title
    {\uppercase{\Large Impacto da volatilidade na otimização de portfolios financeiros\par}}
    \vspace{2cm}
%Author's name
    {\Large Leonel da Silva Baptista\par}
    \vspace{2cm}
%Degree
    {\Large Mestrado em Estatística, Matemática e Computação\par}
    {\Large Ramo Estatística Computacional\par}
    \vspace{2cm}
%oriented
    {\Large Dissertação orientada pelo\par}
    {\Large Professor Doutor Amílcar Manuel do Rosário Oliveira\par}
    \vspace{2cm}
%Date
    {\Large 2020}
\end{minipage}
\end{center}

\pagenumbering{gobble}% Remove page numbers (and reset to 1)

\clearpage

\chapter*{Resumo}
\fontsize{12}{21}\selectfont
A presente dissertação têm como âmbito a análise de três métodos diferentes de obter a volatilidade de instrumentos financeiros, nomeadamente valores mobiliários, e seu consequente impacto no resultado da rentabilidade de portfolios constituídos utilizando como pressuposto a média variância, assim como a sua exposição ao risco, sendo que a volatilidade constitui uma peça central na constituição de determinados instrumentos financeiros e respetivo calculo de exposição ao risco.

Os métodos analisados para calculo da volatilidade são a Média Movel Exponencial (EWMA), o modelo da heteroscedasticidade condicional auto-regressiva generalizada (GARCH) e a volatilidade implícita. Os dois primeiros métodos têm como subjacentes dados históricos dos instrumentos financeiros, sendo que a volatilidade implícita é a volatilidade esperada pelo mercado, sendo obtida através da cotação das opções dos respetivos subjacentes.

A análise de risco é efetuada aplicando dois métodos complementares de análise. O Value at Risk (VaR), que contempla a percentagem de perdas que excedem o VaR e o Expected shortfall (ES), que contempla a magnitude dessas perdas.

Este trabalho é realizado tendo como ferramenta de apoio a linguagem de programação R.
\bigbreak

\noindent\textbf{Palavras chave:} Volatilidade, portfolio, rentabilidade, risco, R




\pagenumbering{roman}% Arabic page numbers (and reset to 1)
\setcounter{page}{2}

\chapter*{Abstract}
\fontsize{12}{21}\selectfont
The scope of this dissertation is to analyze three different methods of obtaining the volatility of financial instruments, namely securities, and their consequent impact on the profitability of portfolios constituted using the assumption of mean-variance, as well as their exposure to risk, volatility is a central element in the constitution of certain financial instruments and the respective calculation of exposure to risk.

The methods analyzed for calculating the volatility are the Exponential Moving Average (EWMA), the generalized autoregressive conditional heteroscedasticity model (GARCH) and the implied volatility. The first two methods are based on historical data on financial instruments, the implied volatility being the volatility expected by the market, being obtained through the quotation of the options of the respective underlying.

The risk analysis is carried out using two complementary methods of analysis. Value at Risk (VaR), which includes the percentage of losses that exceed VaR and Expected shortfall (ES), which considers the magnitude of these losses.

This work is carried out using the R programming language as a support tool.

\bigbreak

\noindent\textbf{Keywords:} Volatility, portfolio, profitability, risk, R

\newenvironment{dedication}
  {\clearpage           % we want a new page
   \itshape             % the text is in italics
   \raggedleft          % flush to the right margin
  }
  {\par % end the paragraph
   \vspace{\stretch{3}} % space at bottom is three times that at the top
   \clearpage           % finish off the page
  }
\begin{dedication}
{\Large Dedicado a minha esposa\par}
\end{dedication}

\chapter*{Agradecimentos}

\renewcommand*\contentsname{Índice}
{
\setcounter{tocdepth}{2}
\tableofcontents
}
\listoftables
\listoffigures
\setstretch{1.5}
\hypertarget{simbologia-e-notauxe7uxf5es}{%
\chapter*{Simbologia e notações}\label{simbologia-e-notauxe7uxf5es}}
\addcontentsline{toc}{chapter}{Simbologia e notações}

\mainmatter

\hypertarget{intro}{%
\chapter*{Introdução}\label{intro}}
\addcontentsline{toc}{chapter}{Introdução}

A estatística aplicada ao sector financeiro têm sido pratica comum nas últimas décadas, sendo que a sua aplicação não se resume apenas a estatística descritiva, tendo vindo a beneficiar dos avanços verificados na aplicação de ferramentas estatísticas para analise preditiva dos dados, devido essencialmente aos avanços tecnológicos no hardware de equipamentos informáticos que permitem a aplicação de algoritmos mais complexos que de outro modo não seria possível utilizar, pelo menos em tempo útil.

Um dos sectores com grande aplicabilidade dos métodos matemáticos e estatísticos nas finanças é a analise quantitativa, sendo as principais áreas de aplicação a estruturação de derivados, gestão do risco, trading automático e gestão de investimentos.

Historicamente, a analise quantitativa iniciou-se em 1900 com Louis Jean-Baptiste Alphonse Bachelier, onde a sua tese de doutoramento forneceu um modelo para estipular o preço de opções considerando uma distribuição normal (\url{https://en.wikipedia.org/wiki/Quantitative_analysis_(finance)}).

Na década de 50, Harry Markowitz escreveu um artigo intitulado ``Portfolio Selection'' que viria a revolucionar o modo como selecionar uma carteira de instrumentos financeiros, aplicando princípios de correlação e variância de modo a constituir portfolios de ações , onde a ``fronteira eficiente'' representa portfolios que maximizam retornos de acordo com o risco assumido, providenciando modelos que demonstravam que só com a diversificação de investimentos é que se conseguiria atingir a eficiência, embora só bastante mais tarde esta teoria começa-se a ver a sua aplicabilidade nas instituições financeiras. A aplicabilidade de técnicas estatísticas fica saliente quando Markowitz estipula que ``para usar a regra da média-variância na seleção de ações devemos ter procedimentos para encontrar \(\mu_i\) e \(\sigma_{ij}\) razoáveis. Estes procedimentos, eu acredito, devem combinar técnicas estatísticas e julgamento prático do Homem'' \citep[pp.91]{Markowitz1952}. As limitações do modelo prendem-se com pressuposto que não representam exatamente a realidade, como o pressuposto de que os retornos das ações seguem uma distribuição normal, sendo que a distribuição dos retornos segue muitas vezes uma distribuição com curtose leptocúrtica, apresentando caudas pesadas e um pico superior ao da distribuição normal.

Na década de 60, Sharpe, Lintner and Mossin desenvolveram um modelo para equilíbrio de mercado, definido como \emph{Capital Asset Pricing Model} (CAPM), descrevendo a relação entre risco sistemático e o retorno esperado. O modelo pressupõe que, se todos os investidores contêm o mesmo portfolio, então, em equilíbrio esse deve ser o portfolio de mercado. De acordo com \citet{Sharpe1964}, em equilíbrio os preços dos ativos de capital foram ajustados de forma que o investidor consiga atingir qualquer ponto desejado ao longo da reta do mercado capital, ou \emph{capital market line} (CMP), pressupondo que o investidor siga uma estratégia de diversificação do investimento. O CMP pode ser utilizado de modo a otimizar um portfolio caso seja contemplado uma taxa de juro sem risco na sua estruturação, sendo o ponto tangente a curva denominada de fronteira eficiente.

Também na década de 60 foi apresentado pela primeira vez o modelo de Black-Scholes-Merton, fornecendo uma solução para valorizar opções europeias e outros derivados. O modelo assume que os preços têm uma distribuição lognormal e que a volatilidade é constante ao longo do tempo. A volatilidade que é assumida neste modelo é a volatilidade implícita da opção, ou seja, a volatilidade para o qual o valor dado pelo modelo Black-Scholes-Merton iguala o preço de mercado. Outros modelos foram desenvolvidos de modo a valorizar opções e outros derivados financeiros, entre eles a arvore binomial e simulação de Monte Carlo.

Os vários modelos apresentados têm como finalidade contribuir para uma decisão mais informada por parte do investidor, sendo que na generalidade o investidor irá optar pelo investimento que apresenta um maior retorno de acordo com o risco a que se dispõem estar exposto, tendo em consideração o seu perfil e expectativas.A escolha do portfólio é feita resolvendo um problema de otimização, no qual o risco do portfólio é minimizado sendo definido como retrição o valor desejado de retorno esperado. Desta forma é importante quantificar o risco. Existem vários modelos para quantificar o risco, ou seja quantificar a perda esperada de acordo com a hipótese de ocorrência de determinado cenário, sendo que 2 desses modelos para análise do risco são o \emph{Value at Risk} (VaR) e o \emph{Expected Shortfall}, também denominado \emph{Conditional Value at Risk} (CVaR). De acordo com \citet{HistVaR}, em 1922 no New York Stock Exchange já eram exigidos requisitos de capital a alguns dos seus membros, tendo na década de 50 Markowitz e Roy, separadamente, publicado metodos para quantificar o VaR, sendo ambos bastante similares e com a finalidade de quantificar o risco a que estaria exposto um portfolio. A necessidade de utilizar medidas de risco mais sofisticada tornou-se mais visível na década de 80 devido ao aparecimento de produtos mais complexos e ao aumento da volatilidade dos mercados, sendo que devido a regulamentação cada vez mais exigente, como o Basel III e Solvency II, as instituições financeiras e seguradoras devem implementar mecanismos de gestão de risco, sendo que os requisitos de capital são bastante mais exigentes desde a ocorrência da crise do subprime em 2007. De acordo com os acordos de Basel o VaR deve ser estimado diariamente utilizando o percentil 99\textsuperscript{th}.

Todos estes modelos têm tido aplicabilidade na análise quantitativa financeira, sendo que novos modelos foram sendo desenvolvidos ou apenas melhorados de modo a dar resposta à realidade verificada no mercado. Como podemos subentender uma das disciplinas fundamentais na definição destes modelos é o conhecimento de estatística e a sua aplicação prática, quer através de técnicas paramétricas, onde se assume um pressuposto forte de que os valores de uma variável têm uma distribuição normal, seja através de técnicas não paramétricas, onde não se assume que a distribuição dos valores de uma variável apresentam distribuição normal.

O trabalho desenvolvido ao longo desta tese, propõem-se analisar o impacto que poderá ter o método de calculo da volatilidade sobre a definição de um portfolio, o seu retorno esperado assim como quantificar o risco a que se estará exposto. Desde os primeiros trabalhos de \citet{Markowitz1952} acerca da otimização de portfolios que vários outros trabalhos foram desenvolvidos para constituição e otimização de portfolios, sendo que nesta dissertação se irá aplicar o método introduzido por \citet{Markowitz1952}, utilizando a teoria da média-variância para a constituição de um portfolio. O mesmo se poderá afirmar acerca do cálculo da exposição ao risco por um portfolio, sendo, no entanto, o VaR e o CVaR dois dos métodos mais utilizados para quantificar essa métrica, sendo que de acordo com \citet{OptVaR2000} o CVaR é conhecido por ter melhores propriedades que o VaR. Como iremos ver existem diferentes métodos de calculo do VaR e CVaR, sendo que neste trabalho iremos utilizar a que for mais adequada ao tipo de dados em análise.

Como inicialmente referido, o objetivo é analisar as diferentes formas de calcular a variância, sendo que iremos focar-nos em três formas diferentes de calcular esse valor, análisar a sua implicação no resultado final, assim como o valor que resulta da quantificação de risco e o seu impacto na perceção pelo investidor.

A investigação decorrerá aplicando-se os diferentes métodos de calculo da variância a dados do mercado, assim como os pressupostos teóricos de cada um dos métodos, sendo constituída uma carteira de ações integrantes do Euro Stoxx 50, calculando o seu retorno final para cada uma das volatilidades, assim como o risco a que está exposto um investidor. O retorno obtido será também comparado com um \emph{benchmark}, neste caso o Euro Stoxx 50.

Ao longo deste percurso será também análisada a forma como é constituídos um portfolio, a teoria subjacente a média-variância, as retrições aplicáveis ao modelo desenvolvido, assim como a teoria subjacente aos vários métodos para análise da exposição ao risco aquando da constituição de um portfolio.

A aplicação pratica dos métodos aos dados do mercado será realizado com o apoio da linguagem de programação R, utilizando para esse efeito os vários ``packages'' disponíveis para aplicação ao sector financeiro. Um dos capítulos será dedicado a apresentação e descrição dos principais ``packages'' utilizados para análise dos dados, sendo que o R é parte integrante desta dissertação como ferramenta de análise estatísticas e aplicabilidade ao sector financeiro.

\begingroup
\titleformat{\chapter}[display]
{\normalfont\huge\bfseries\centering}{\chaptertitlename\ \thechapter}{20pt}{\Huge}

\hypertarget{modelauxe7uxe3o-estatuxedstica-na-otimizauxe7uxe3o-de-portfuxf3lios}{%
\chapter{Modelação Estatística na Otimização de Portfólios}\label{modelauxe7uxe3o-estatuxedstica-na-otimizauxe7uxe3o-de-portfuxf3lios}}

\newpage

\hypertarget{series-temporais}{%
\section{Series Temporais}\label{series-temporais}}

O valor da cotação de activos financeiros, como acções ou opções, são representados de forma sequencial ao longo do tempo, considerando determinado intervalo, que pode ser segundos, minutos, dias, semanas ou outro intervalo considerado útil para representação dos dados ao longo do tempo. Quando tal acontece estamos em presença de series temporais.

Os preços de activos financeiros ao longo do tempo formam o que é denominado por processos estocásticos. Processos estocásticos são uma classe de series temporais onde o valor da variável muda ao longo de tempo de forma aleatória. Os processo estocásticos podem ser classificados de discretos ou contínuos, sendo que na análise de activos financeiros, embora estes sigam processos discretos, serão considerados processos estocásticos contínuos ao longo do tempo, sendo que estes modelos acabam por ser bastante úteis na modelização dos preços de activos financeiros de acordo com \citet{Hull2018}.

\hypertarget{modelauxe7uxe3o-do-preuxe7o-de-acuxe7uxf5es}{%
\subsection{Modelação do preço de acções}\label{modelauxe7uxe3o-do-preuxe7o-de-acuxe7uxf5es}}

Os preços das acções seguem habitualmente o que é conhecido por um processo de Markov, onde apenas o valor presente importa para prever o valor futuro. Desta forma a única informação relevante é o seu valor no momento, sendo que os valores e trajecto verificado no passado não irão ter importância na definição da distribuição probabilística do preço no futuro \citep{Hull2018}.Desta forma as propriedades de Markov no preço das acções é consistente com a eficiência dos mercados na forma fraca, constituindo esta uma das três formas de eficiência de mercado definidas por Eugene Fama\footnote{Ver ``\url{https://pt.wikipedia.org/wiki/Eugene_Fama}''}.

O modelo representado aqui e que será utilizado para simular preços de activos financeiros atravessou vários pressupostos até a sua conclusão final, sendo apresentado de uma forma muito sucinta as principais etapas de desenvolvimento desse modelo.

Um dos primeiros modelos era representado por um processo de Wiener, sendo este um processo particular do processo estocástico Markov, referido como movimento Browniano, descrevendo a evolução de uma variável com distribuição normal padrão. A modelação pressupõe que a variável z possa ser dada pela seguinte equação:

\begin{equation} 
  dz = \varepsilon \sqrt{dt}\qquad   \varepsilon \sim N(0,1);
  \label{eq:wiener}
\end{equation}

Desta forma a variável z segue um processo de Wiener, sendo uma variável independente e identicamente distribuída (i.i.d).

Como este modelo não preenchia todos os pressupostos, aplicou-se um processo generalizado de Wiener (também conhecido como movimento Browniano (BM)), onde é incluindo um amplificador/redutor na parte aleatória do processo de forma a ajustar o processo a propriedades especificas de cada acção, ilustrado na equação \eqref{eq:gwiener}. Este processo descreve a evolução de um processo de uma variável com distribuição normal, com um desvio \(\mu\) por unidade de tempo e uma taxa de variância de \(\sigma^2\) também por unidade de tempo.

\begin{equation} 
  \delta S = \mu\delta t +\sigma\varepsilon\sqrt{\delta t}\qquad\varepsilon \sim N(0,1);
  \label{eq:gwiener}
\end{equation}

A diferença relativo a um processo de Wiener é que no processo generalizado de Wiener a taxa de desvio e variância pode ter como valor qualquer constante, sendo que no processo de Wiener esses valores são de 0 e 1 respectivamente.

Outro processo estocástico, conhecido como processo Itô, foi desenvolvido, representando um processo generalizado de Wiener, sendo que neste caso o valor dos parâmetros \(\mu\) e \(\sigma\) são funções do valor subjacente da variável S e do tempo t. Este modelo é o que vai ser utilizado para simulação do preço das acções sendo representado pelas seguintes equações:

\begin{equation} 
  \frac{\delta S}{S} = \mu\delta t +\sigma\varepsilon\sqrt{\delta t}\qquad\varepsilon \sim N(0,1);
  \label{eq:ito}
\end{equation}
\begin{equation} 
  In S_1 - InS_0 \approx\phi\Big[\Big(\mu-\frac{\sigma^2}{2}\Big)\delta t, \sigma\sqrt{\delta t}\Big]
  \label{eq:Inito}
\end{equation}
\begin{equation} 
  S_1 =S_0 e^{\Big(\mu-\frac{\sigma^2}{2}\Big)\delta t + \sigma\varepsilon\sqrt{\delta t}}
  \label{eq:logprice}
\end{equation}

Nesta equação o \(\mu\) representa a taxa de retorno anual esperado, sendo que \(\sigma\) representa o desvio padrão ou volatilidade da acção, parâmetro muito importante para a determinação do valor de vários derivados, havendo várias formas de calcular este valor como veremos mais adiante. Estes valores são função do corrente valor de S e do tempo actual t. Numa economia neutra face ao risco \(\mu\) é igual a taxa de juro sem risco. O \(\varepsilon\) representa uma variável com distribuição normal(N(0,1)).

Este processo é conhecido como movimento Browniano geométrico (GBM). De acordo com \citet{AppliedFinancial} um ``GBM pode ser considerado como um movimento probabilístico contínuo no qual o logaritmo da quantidade que varia aleatoriamente segue um movimento Browniano (processo de Wiener) com desvio.'' Este modelo é a base do modelo de Black-Scholes, que será revisto mais adiante, aquando do cálculo da volatilidade implícita nas opções.

Tendo em consideração a equação \eqref{eq:logprice}, \emph{S} segue uma distribuição lognormal. Uma distribuição lognormal é mais realístico de acordo com o movimento do preço das acções, prevenindo que o valor se torne negativo.

Em simulação, este processo é realizado considerando uma distribuição normal com média e variância dada pela equação \eqref{eq:Inito} \citep{FRM1}.

\hypertarget{simulauxe7uxe3o-de-monte-carlo}{%
\subsection{Simulação de Monte Carlo}\label{simulauxe7uxe3o-de-monte-carlo}}

A simulação de Monte Carlo consiste na geração de valores a partir de uma determinada distribuição ou amostra, sendo que ``o termo Monte Carlo é usado para se referir a técnicas que envolvem simulação computacional''\citep[pp.457]{ProgSim}.

Ao simular os preços dos activos financeiros iremos utilizar a técnica de Monte Carlo de modo a gerar amostras aleatórias de acordo com a equação \eqref{eq:logprice}. Os preços serão simulados criando várias tentativas com valores aleatórios para \(\varepsilon\) a partir de \(\phi\)(0,1). A precisão dos valores obtidos na simulação depende do número de tentativas efectuadas, sendo considerado 1000 tentativas por cada dia e considerar o valor médio dessas tentativas como o valor simulado para cada um dos dias simulados.

\hypertarget{volatilidade}{%
\section{Volatilidade}\label{volatilidade}}

Na indústria financeira o desvio padrão associado a instrumentos financeiros é definido como volatilidade. Desta forma quando estamos a falar de volatilidade estamos a considerar o desvio padrão observado.

De acordo com \citet{HullRisk2018}:

\begin{spacing}{1}
\begin{adjustwidth}{28.3464pt}{28.3464pt}\footnotesize
"A variável volatilidade, $\sigma$, é definida como o desvio padrão do retorno fornecido pela variável por unidade de tempo quando o retorno é expresso usando juros compostos. Quando a volatilidade é usada para valorizar opções, a unidade de tempo é normalmente 1 ano, sendo a volatilidade o desvio padrão do retorno compostos por ano. Quando a volatilidade é usada para a gestão de risco, a unidade de tempo usual é 1 dia de forma a que a volatilidade é o desvio padrão do retorno composto por dia." (pp.213-214)
\normalsize\end{adjustwidth}
\end{spacing}
\medskip

Vários são os modelos para calculo da volatilidade, sendo que um dos modelos mais simples é o do cálculo da variância de acordo com a equação \eqref{eq:estdesviopadrao} utilizando os dados históricos dos retornos, sendo que neste modelo o peso atribuído aos dados é o mesmo independentemente da sua antiguidade. Outros modelos como a Média Móvel Exponencial Ponderada (EWMA) e Heteroscedasticidade condicional auto-regressiva generalizada (GARCH) são modelos, que embora utilizem dados históricos, reconhecem que tanto a volatilidade como a correlação não são constantes ao longo do tempo, atribuindo maior peso aos dados mais recentes. Por fim, um dos modelos que não integra dados históricos mas sim as expectativas futuras para o cálculo da volatilidade é o da volatilidade implícita, utilizando o modelo de Black-Scholes-Merton na valorização das respectivas opções relativamente ao subjacente.

Nos cálculos que utilizem dados históricos a escolha do tamanho da amostra \emph{n} deve ser grande o suficiente de modo a garantir uma melhor precisão nas estatísticas obtidas, sendo que neste caso devemos considerar que a volatilidade não é constante ao longo do tempo e que valores mais antigos podem não ser tão relevantes como os valores mais recentes. De acordo com \citep{Hull2018} esse valor deve ser compreendido entre 90 a 180 dias para a cotação de activos.

Para o calculo da volatilidade anual utiliza-se os número de dias de negociação, sendo considerado 252 dias por ano como valor de referência.

\hypertarget{autoregressive-conditional-heteroscedasticity-arch}{%
\subsection{AutoRegressive Conditional Heteroscedasticity (ARCH)}\label{autoregressive-conditional-heteroscedasticity-arch}}

Existem equações para o cálculo da variância que atribuem igual peso aos valores passados independentemente da sua antiguidade. Outros métodos atribuem mais peso aos dados mais recentes, pois pressupõem-se que esses carregam mais informação útil acerca da variável em estudo, criando modelos que prevêem com menor erro os valores futuros em estudo.

Uma das formas de cálculo da volatilidade tendo em consideração os valores mais recentes dos retornos é aplicando a equação

\begin{equation} 
  \sigma_{n}^{2} =\sum_{i=1}^{m}\alpha_i\mu_{n-1}^{2}
  \label{eq:weight}
\end{equation}

A variável \(\alpha\) representa o peso associado a observação \emph{i} dos retornos, sendo que a soma dos respectivos pesos deve ser igual a 1.

Tendo em consideração \citet{Hull2018} se a média a longo prazo da taxa de variância for considerada e assignado um peso a ela então teremos

\begin{equation} 
  \sigma_{n}^{2} =\gamma\mathcal{V}_{L}+\sum_{i=1}^{m}\alpha_i\mu_{n-1}^{2}
  \label{eq:arch}
\end{equation}

sendo que \(\mathcal{V}_{L}\) é a taxa de variância de longo prazo e \(\gamma\) é o peso associado a cada \(\mathcal{V}_{L}\), sendo que os repectivos pesos devem somar 1, de acordo com \[\gamma + \sum_{i=1}^{m}\alpha_i = 1\]

A equação \eqref{eq:arch} é conhecida como um modelo \emph{AutoRegressive Conditional Heteroscedasticity} ou ARCH(m)\footnote{Introduzido por Robert F.Engle em 1982, tendo-lhe sido atribuído o prémio Nobel da economia em 2003}, sendo que em finanças é uma das classes de modelos mais utilizada para prever a volatilidade. O \emph{m} representa o número de observações, sendo que a variável aleatória \(\mu\) segue uma distribuição normal, sendo no entanto prática comum considerar outros tipos de distribuições como a distribuição t-student, devido ao factos da distribuição dos retornos apresentarem caudas mais pesadas que uma distribuição normal.

Auto-regressivo significa que a variância presente depende do seu próprio passado e não num regressor exógeno. O facto de ser condicional significa que a variância de amanhã depende das variâncias mais recentes. Já a heteroscedasticidade significa que a variância não é constante ao longo do tempo. Quando a variância e a covariância variam ao longo do tempo falamos de heteroscedasticidade condicional.

O pressuposto destes modelos é de que a variância dos retornos seguem um processo previsível, sendo que os modelos ARCH são menos convincentes na previsão quando a volatilidade têm alterações bruscas. A apresentação do modelo ARCH serve como forma introdutória de apresentação aos modelos \emph{exponentially weighted moving average} (EWMA) e \emph{generalized autoregressive conditional heteroskedasticity} (GARCH).

\hypertarget{exponentially-weighted-moving-average-ewma}{%
\subsection{Exponentially weighted moving average (EWMA)}\label{exponentially-weighted-moving-average-ewma}}

O modelo da média móvel exponencial ponderada (EWMA) é um estimador calculado a partir de amostras sequenciais da população onde é atribuindo maior peso aos valores mais recentes, sendo que esse peso diminui exponencialmente a medida que vamos recuando no tempo. A formula utilizada para actualizar o valor para a volatilidade é

\begin{equation} 
  \sigma_{n}^{2} = \lambda\sigma_{n-1}^{2}+(1-\lambda)\mu_{n-1}^{2} 
  \label{eq:ewma}
\end{equation}
sendo um caso particular da equação \eqref{eq:weight}. Neste caso \(\gamma_{i+1} = \lambda\gamma_{i}\), onde 0\textless{}\(\lambda\leq1\) é uma constante, sendo \(\sigma_{n-1}\) a estimativa da volatilidade realizada no dia n-2 para o dia n-1, e \(\mu_{n-1}\) a mudança percentual diária mais recente. Ao valor de \(\lambda\) atribuido ``estudos empíricos mostram que o \emph{decay factor} (\(\lambda\)) 0,94 fornece uma boa estimativa para todos os ativos.''\citep[p.4]{riskmetrics}

De modo a entender porque à volatilidade obtida através da EWMA correspondem pesos que diminuem exponencialmente vamos substituir \(\sigma_{n-1}^{2}\) na equação \eqref{eq:ewma} de modo a obter

\begin{equation} 
  \sigma_{n}^{2} = (1-\lambda)(\mu_{n-1}^{2}+\lambda\mu_{n-2}^{2})+\lambda^{2}\sigma_{n-2}^{2}
  \label{eq:ewma1}
\end{equation}

Continuando a substituir acabamos por obter

\begin{equation} 
  \sigma_{n}^{2} = (1-\lambda)\sum_{i=1}^{m}\lambda^{i-1}\mu_{n-1}^{2}+\lambda^{m}\mu_{n-m}^{2}
  \label{eq:ewma2}
\end{equation}

Como podemos ver pela equação \eqref{eq:ewma2} o ``peso de \(\mu_{i}\) decresce a uma taxa \(\lambda\) a medida que vamos recuando no tempo. Cada peso é \(\lambda\) vezes o peso anterior.'' \citep[p.226]{HullRisk2018}. Como os pesos diminuem geometricamente, o EWMA também é referido como média móvel geométrica.

\hypertarget{generalized-autoregressive-conditional-heteroskedasticity-garch}{%
\subsection{Generalized autoregressive conditional heteroskedasticity (GARCH)}\label{generalized-autoregressive-conditional-heteroskedasticity-garch}}

Em 1986 um modelo mais flexível que o modelo ARCH foi proposto, sendo este o modelo \emph{Generalized} ARCH\footnote{Introduzido por Bollerslev(1986)}. De acordo com \citet{volatilitymodels} ``Uma grande vantagem dos modelos GARCH é que os retornos não são assumidos independentes, e mesmo se forem assumidos condicionais gaussianos para retornos anteriores, incondicionalmente, eles não são gaussianos, porque o agrupamento de volatilidade gera leptocurtose''(p.2). Também, e de acordo com \citet{portanalyse}, ``A volatilidade agora depende de ambos, uma combinação linear dos erros quadráticos da previsão (um termo autoregressivo) e variâncias condicional passada (um termo de média móvel).''(p.136)

A equação que define o modelo GARCH(1,1) é

\begin{equation} 
  \sigma_{n}^{2} = \gamma\mathcal{V}_{L} + \alpha\mu_{n-1}^{2} + \beta\sigma_{n-1}^{2}
  \label{eq:garch}
\end{equation}

Nesta equação, verifica-se que \(\sigma_{n}^{2}\) é calculado a partir da taxa de variação média de longo prazo \(\mathcal{V}_{L}\), como também a partir de \(\sigma_{n-1}\) e \(\mu_{n-1}\), sendo que o modelo EWMA é um caso particular do modelo GARCH(1,1) onde \(\gamma=0\), \(\alpha=1-\lambda\) e \(\beta=\lambda\). Tal como referido nos modelos anteriores, a soma dos diferentes pesos deve ser igual a 1, sendo \[\gamma+\sigma+\beta=1\]

O modelo genérico de GARCH é GARCH(p,q) onde o modelo calcula \(\sigma_{n}^{2}\) a partir das observações \emph{p} mais recentes de \(\mu^2\) e as mais recentes estimações \emph{q} da taxa de variância. Desta forma, o modelo "``(1,1) em GARCH(1,1) indica que \(\sigma_{n}^{2}\) é baseado nas mais recentes observações de \(\mu^2\) e nas mais recentes estimações da taxa de variância.''\citep[p.227]{Hull2018}

Considerando \(\omega=\gamma\mathcal{V}_{L}\), o modelo GARCH(1,1) pode ser definido como

\begin{equation} 
  \sigma_{n}^{2} = \omega + \alpha\mu_{n-1}^{2} + \beta\sigma_{n-1}^{2}
  \label{eq:garch2}
\end{equation}

A equação \eqref{eq:garch2} é a que costuma ser utilizada de forma a estimar os parâmetros. De notar de que para obter um processo estável GARCH(1,1) é necessário que \(\sigma+\beta<1\), ou então o peso aplicado a variância de longo prazo é negativa.
A estimação dos parâmetros, tanto para o modelo EWMA como para o modelo GARCH(1,1), é realizado utilizando um processo conhecido como \emph{maximum likelihood method}, onde se utilizam os dados históricos de modo a escolher os parâmetros que maximizem a probabilidade de ocorrência dos dados, de acordo com a equação

\begin{equation} 
  \sum_{i=1}^{m}=\bigg[-ln(\sigma_{i}^{2})-\frac{\mu_{i}^{2}}{\sigma_{i}^{2}}\bigg]
  \label{eq:mgarch}
\end{equation}

\hypertarget{volatilidade-impluxedcita}{%
\subsection{Volatilidade implícita}\label{volatilidade-impluxedcita}}

O modelo de Black-Scholes-Merton\footnote{Os autores, Robert Merton e Myron Scholes, foram reconhecidos com o Nobel da economia em 1997} foi um modelo desenvolvido nos anos 70, considerado um ponto de ruptura na definição do preço de opções sobre acções europeias.

De entre os pressupostos\footnote{Para mais informação ver \citet{BlackScholes},pp.~640, capitulo ``The valuation formula''} utilizados para derivar a equação diferencial, importa salientar de que a taxa de juro sem risco, r, é constante e a mesma ao longo do tempo. De acordo com \citet{Hull2018} ``É importante considerar que a avaliação sem risco (ou o pressuposto de que todos os investidores são neutros ao risco) é meramente um artifício para obter solução para a equação diferencial de Black-Scholes-Merton''(p.312).

O processo que se assume ser aplicado ao preço dos activos é o descrito pela equação \eqref{eq:ito}. De salientar de que nenhumas das variáveis da equação é afectada pelas preferências de risco dos investidores, sendo que as variáveis que aparecem na equação são o valor presente do activo financeiro, tempo, volatilidade e a taxa de juro sem risco.

As soluções obtidas a partir da equação diferenciável de interesse para calculo da volatilidade implícita, são as aqui apresentadas para valorizar opções de compra (\emph{call}) e opções de venda (\emph{put}) do tipo europeias:

\begin{equation} 
  c = S_0N(d_1) - Ke^{-rT}N(d_2);
  \label{eq:call}
\end{equation}
e
\begin{equation} 
  p = Ke^{-rT}N(-d_2) - S_0N(-d_1);
  \label{eq:put}
\end{equation}
onde
\begin{equation} 
  d_1 = \frac{In(S_0/K)+(r+\sigma^2/2)T}{\sigma\sqrt{T}}
  \label{eq:d1}
\end{equation}
\begin{equation} 
  d_2 = \frac{In(S_0/K)+(r-\sigma^2/2)T}{\sigma\sqrt{T}}=d_1-\sigma\sqrt{T}
  \label{eq:d2}
\end{equation}

A função N(x) representa a função distribuição para uma distribuição normal padrão, sendo a probabilidade de uma variável ser menor que x (ver exemplo na figura \ref{fig:fdistribuicao}). O valor de N(x) pode ser obtido com a função do R pnorm(). A variável T representa o tempo medido em dias de negociação que faltam até a expiração da opção dividido pelos dias de negociação nesse ano, sendo S\textsubscript{0} o valor do activo subjacente no tempo 0, r a taxa de juro sem risco, \(\sigma\) a volatilidade anual e K o preço de exercício da opção.

\begin{figure}

{\centering \includegraphics[width=0.45\linewidth]{image/fdistribuicao} 

}

\caption{Função distribuição N(x)}\label{fig:fdistribuicao}
\end{figure}
\FloatBarrier
\centering

Fonte: Elaboração própria.

\justifying
\bigskip

O parâmetro da volatilidade não é um parâmetro que se consiga obter ou observar directamente, sendo um valor que representa a volatilidade esperada pelos investidores no futuro, conhecido como \emph{volatilidade implícita}. Um modo de obter este valor é a partir dos restantes parâmetros, ou seja, tendo o valor de uma opção de compra, e considerando os valores de S\textsubscript{0}, K, r e T, substituir estes pelos respectivos valores e obter o valor de \(\sigma\) que iguale o valor da \emph{call} utilizando as equações \eqref{eq:call} e \eqref{eq:d1} através de processos por aproximação iterativo.

A volatilidade implícita será diferente consoante o preço de exercício da opção, considerando todos os outros parâmetros iguais. Da conjugação dos valore de volatilidade obtidos para cada um dos preços de exercício da opção obtêm-se um gráfico conhecido como \emph{volatility smile}(figura \ref{fig:volatilitysmile}). Este gráfico será o mesmo, quer se esteja a considerar uma opção do tipo \emph{call} ou a mesma equivalente opção do tipo \emph{put}.

A variável volatilidade, \(\sigma\), é definida como o desvio padrão do retorno fornecido pela
variável por unidade de tempo quando o retorno é expresso usando juros compostos.
Quando a volatilidade é usada para valorizar opções, a unidade de tempo é normalmente 1 ano, sendo a volatilidade o desvio padrão do retorno compostos por ano.
Quando a volatilidade é usada para a gestão de risco, a unidade de tempo usual é 1 dia
de forma a que a volatilidade é o desvio padrão do retorno composto por dia.''(pp.213-
214)

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{image/volatilitysmile} 

}

\caption{Volatility Smile}\label{fig:volatilitysmile}
\end{figure}
\FloatBarrier
\centering

Fonte: \citep[pp.182]{volatilitysmile}

\justifying
\bigskip

Como de pode ver pela figura \ref{fig:volatilitysmile} a opção é considerada \emph{out-the-money} se o seu valor for inferior ao do respectivo subjacente, \emph{at-the-money} se for superior e \emph{in-the-money} se o valor for igual. No calculo do valor da volatilidade será utilizado o valor de preço de exercício \emph{in-the-money} de opções do tipo \emph{call}, ou na impossibilidade do valor do subjacente ser o mesmo do K, o mais próximo deste.

Quando comparado com outros métodos para calcular a volatilidade onde os dados utilizados são dados históricos, este método incorpora o sentimento presente dos investidores relativo a volatilidade futura de um determinado ativo ou instrumento financeiro.

\hypertarget{portfolios-muxe9dia-variuxe2ncia}{%
\section{Portfolios média-variância}\label{portfolios-muxe9dia-variuxe2ncia}}

A otimização de portfolios através da diversificação é um conceito básico que teve origem em Markowitz, criando o conceito de fronteira eficiente. Existem vários pressupostos definidos na obtenção deste modelo, não sendo, no entanto, o âmbito aqui analisar esses mesmos pressupostos, considerando que independentemente disso esses mesmos pressupostos são verificados. De acordo com \citet{Modern2013}, ``todas os pressupostos acerca da analise de portfolio foram demonstradas serem simplistas, e em alguns casos demasiado simplistas.{[}\ldots{]}Pessoas necessitam apenas de se comportar como se fossem descritas pelos pressupostos para uma teoria ser válida'' \citep[pp.5]{Modern2013}.

Para aplicação deste modelo deve-se obter os seguintes dados dos instrumentos financeiros que vão constituir o portfolio:

\begin{itemize}
\tightlist
\item
  A taxa do retorno esperado, E(r);
\item
  O desvio padrão dos retornos, \(\sigma\);
\item
  O coeficiente de correlação,\(\rho\), entre cada um dos activos.
\end{itemize}

O retorno esperado vai depender de vários factores, essencialmente a taxa de retorno sem risco que se verifica no mercado, a taxa de inflação e o risco a que o investidor estará sujeito, sendo que quanto maior o risco, maior será o retorno esperado.

As séries dos retornos diários para cada um dos activos é calculada de acordo com a seguinte formula:

\begin{equation} 
  R_i = ln\Big(\frac{S_f}{S_i}\Big)
  \label{eq:logRet}
\end{equation}

A média dos retornos de cada um dos activos é calculada de acordo com a sua média aritmética:

\begin{equation} 
  \overline{R} = \frac{\displaystyle\sum_{i=1}^n R_i}{n}
  \label{eq:meanRet}
\end{equation}

O retorno de um portfolio de activos financeiros será uma média ponderada do retorno dos activos individuais, de acordo com a seguinte equação

\begin{equation} 
    R_{p} = \sum_{i=1}^{N}(X_{i}R_{ij})
  \label{eq:retp}
\end{equation}
onde \(X_{i}\) representa a fracção investida no activo \emph{i}.

O desvio padrão representa a volatilidade, ou risco, associada ao activo. Considerando que essa volatilidade é calculada com base nos dados históricos e nas formulas acima, então a estatística da amostra para o desvio padrão representa-se pela seguinte formula:

\begin{equation} 
  \hat{\sigma} = \sqrt\frac{\displaystyle\sum_{i=1}^n (R_i-\overline{R})^2}{n-1}
  \label{eq:estdesviopadrao}
\end{equation}

A variância para o portfolio é um pouco mais complicada a calcular do que o calculo para o retorno e para as variância individuais de cada um dos activos, como podemos verificar pela seguinte equação

\begin{equation} 
  \sigma_{p}^{2} = \sum_{j=1}^{N}(X_{j}^{2}\sigma_{j}^{2})+\sum_{j=1}^{N}\sum_{k=1}^{N}(X_{j}X_{k}\sigma_{jk})
  \label{eq:estdesviopadraop}
\end{equation}
onde \(k\neq j\). O termo \(\sigma_{jk}\) designa-se por covariância representando o modo como 2 activos se movem conjuntamente, sendo o valor calculado do seguinte modo,

\begin{equation} 
  Cov(R_{i},R_{j}) = E([R_{i}-E(R_{i})][R_{j}-E(R_{j})])
  \label{eq:covariancia}
\end{equation}

Se todos os termos forem independentes, isto é, a covariância for igual a 0, então apenas se mantêm o primeiro termo/somátorio na equação\#ref(eq:estdesviopadraop).

Quando se pretende interpretar o valor da covariância é prática comum utilizar o que se designa por coeficiente de correlação, sendo que o valor obtido varia entre -1 e +1, sendo que o -1 representa uma correlação negativa perfeita e o +1 uma correlação positiva perfeita. Se o valor for 0 então não existe relação linear entre as variáveis. De forma genérica podemos afirmar que a correlação mede a força da relação linear entre 2 variáveis, sendo a sua forma matemática \[\rho_{ij}=\frac{\sigma_{ij}}{\sigma_{i}\sigma_{j}}\]
Aos incluir-mos mais activos no nosso portfolio estamos a diversificar o risco e a diminuir a variância esperada do portfolio. De acordo com \citet{Goetzmann2014}:

\begin{spacing}{1}
\begin{adjustwidth}{28.3464pt}{28.3464pt}\footnotesize
"A contribuição para a variância da carteira da variância dos títulos individuais vai para zero à medida que N fica muito grande. No entanto, a contribuição dos termos de covariância aproxima-se do valor da covariância média conforme N aumenta.O risco individual dos activos pode ser diversificados, mas a contribuição para o risco total causado pelos termos de covariância não podem ser diversificados" (pp.56-57).
\normalsize\end{adjustwidth}
\end{spacing}
\medskip

Na (figura \ref{fig:covusa}) podemos ver que a partir de um determinado número de activos, normalmente compreendido entre 15 e 20, a percentagem de risco que pode ser eliminada pela diversificação estabiliza.



\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{image/covusa} 

}

\caption{Evolução da covariância ao aumentar a diversificação no portfolio.}\label{fig:covusa}
\end{figure}
\FloatBarrier
\centering

Fonte: \citep[pp.58]{Goetzmann2014}

\justifying
\bigskip

Com base no apresentado até agora, o que se propõe é optimizar um portfolio em que os activos que o constituem apresentem pesos de modo a minimizar o risco, ou seja, minimizar a variância total, sem a possibilidade de vendas a descoberto e de activo sem risco, determinando a carteira eficiente. O problema a que se propõe é minimizar \(\sigma_{p}^{2}\) de acordo com a equação \#ref(eq:estdesviopadraop), sujeito ás seguintes restrições:

\begin{equation} 
  \sum_{i=1}^{N}X_{i}\overline{R}_{i}=\overline{R}_{p}
  \label{eq:und}
\end{equation}
\[X_{i}\geq0\] e \[\sum_{i=1}^{N}X_{i}=1\]
O problema pode ser resolvido construindo a função Lagrangeana

\begin{equation} 
  \mathcal{L} = \sum_{j=1}^{N}\sum_{k=1}^{N}(X_{j}X_{k}\sigma_{jk})+\lambda_{1}(\overline{R}_{p}-\sum_{j=1}^{N}X_{j}\overline{R}_{j})+\lambda_{2}(1-\sum_{j=1}^{N}X_{j})
  \label{eq:estdesviopadraop}
\end{equation}
embora a sua resolução envolva normalmente métodos computacionais.

Desta forma, se considerar-mos a figura \ref{fig:eficient} a fronteira eficiente para o conjunto de portfolios encontra-se entre o ponto II e o ponto III, sendo que de acordo com os pressupostos de minimização do risco o ponto referente a II é o que apresenta um menor risco na fronteira eficiente definida.



\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{image/eficient} 

}

\caption{Fronteira eficiente}\label{fig:eficient}
\end{figure}
\FloatBarrier
\centering

Fonte: \citep[p.33]{invest}

\justifying
\medskip

A definição e optimização de portfolios está sujeita a outras restrições que não serão aqui apresentadas, tais como custos de \emph{trading}, custos de oportunidade ou custos associados a regulamentação e fiscalidade\footnote{O artigo \citet{Fabozzi2014} ``60 Years of portfolio optimization:Practical challenges and current trends'' aborda várias outras restrições na abordagem da optimização na média-variância proposta por Markowitz}.

\hypertarget{value-at-risk}{%
\section{Value at Risk}\label{value-at-risk}}

A quantificação do risco é fundamental para a gestão e atenuação de perdas no valor da carteira ao longo do tempo. Na gestão da carteira a aplicação de métricas de risco permite a adaptação contínua do portfólio aos fatores de risco quantificáveis, podendo-se, através de uma gestão ativa, manter o investidor devidamente informado relativamente ao risco que o seu investimento incorpora e poder tomar medidas proactivas de adaptação do investimento ao nível de risco verificado, tendo em consideração o perfil do investidor.O Value at Risk (VaR) é uma dessas métricas de risco.

O Value at Risk (VaR)\footnote{Markowitz foi dos primeiros autores a contemplar a análise de risco em investimentos, como se pode verificar em \citet{Markowitz1952}} é uma medida probabilística para a perda máxima provável de uma carteira para um nível de confiança determinado,num horizonte temporal especificado. Pode-se definir o VaR como ``descrevendo o quantil da distribuição de ganhos e perdas projectado ao longo do horizonte alvo. Se \emph{c} for o intervalo de confiança selecionado, VaR corresponde ao nível inferior da cauda 1-\emph{c}''\citep[pp.17]{philippe}. Este valor é sempre positivo.

O calculo do valor do VaR é de carácter obrigatório para entidades financeiras e seguradoras, sendo que os reguladores, dependendo da sua jurisdição, determinam os parâmetros quantitativos a serem utilizados.
No caso do Banco Central Europeu\footnote{ver relatório técnico \citet{ecb}}, esses parâmetros são de que o cálculo deve ser efectuado para um intervalo temporal de 10 dias de negociação e para um intervalo de confiança de 99\%, sendo considerado para esses cálculos pelo menos 250 dias negociação de observação de valores históricos.

O cálculo do VaR pode ser realizado de modos diferentes, existindo vários métodos, sendo considerados métodos de tipo não paramétrico, como o método histórico em que não se assume nenhum pressuposto na distribuição desses dados, ou métodos do tipo paramétrico, onde se assume um determinado tipo de distribuição dos dados. Para efeito desta dissertação será aplicado um método paramétrico para cálculo do VaR.

\hypertarget{var-paramuxe9trico-gaussiana}{%
\subsection{VaR Paramétrico (Gaussiana)}\label{var-paramuxe9trico-gaussiana}}

O VaR paramétrico pressupõe que os retornos diários apresentem uma distribuição normal (figura \ref{fig:var}), sendo que a sua representação matemática se encontra definida na equação \eqref{eq:var}.
\begin{equation} 
  VaR_{t+1}^{p} = -\sigma_{t+1}\Phi_{p}^{-1}
  \label{eq:var}
\end{equation}


\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{image/VaR} 

}

\caption{VaR com intervalo confiança 95\% e 99\%.}\label{fig:var}
\end{figure}
\FloatBarrier
\centering

Fonte: \citep[pp.13]{phdthesis}

\justifying
\bigskip

O \(\Phi (p)\) representa a função distribuição e \(\Phi^{-1} (p)\) a sua inversa, sendo que, por exemplo, para um intervalo de confiança de 99\% o valor de \(\Phi^{-1} (p)\) corresponde a -2.33. Se considerarmos que a volatilidade prevista a 1 dia é de 2\%, teremos um VaR = -0.020*(-2.33), o que corresponde a um valor de 0.0466. Podemos interpretar o VaR como sendo a existência de 1\% de probabilidade de perder mais do que 4.66\% do valor investido no activo no dia de hoje.

O \emph{Daily Value at Risk} (DEaR) é o valor diariamente em risco, sendo calculado de acordo com a equação \eqref{eq:dear}.
\begin{equation} 
  €DEaR = € \textnormal{Valor de mercado do investimento} * VaR
  \label{eq:dear}  
\end{equation}

O valor do VaR a mais de um dia pode-se calcular a partir do DEaR a um dia, de acordo com a equação \eqref{eq:vardays}, onde N representa o número de dias.
\begin{equation} 
  VaR = DEaR*\sqrt{N}
  \label{eq:vardays}
\end{equation}

Se estivermos a analisar o VaR de um portfolio, esse é calculado da mesma forma que a variância de um portfolio (equação \eqref{eq:varport}), considerando o DEaR individual de cada componente.
\begin{equation} 
  DEaR_{portfolio}^{2} = \sum_{i=1}^{N}\sum_{j=1}^{N}Cov(DEaR_i,DEaR_j)
  \label{eq:varport}
\end{equation}
onde
\begin{equation} 
  Cov(DEaR_i,DEaR_j) = DEaR_{i}DEaR_{j}\rho(DEaR_i,DEaR_j)
  \label{eq:covport}
\end{equation}

Por exemplo, considerando 2 activos, A e B, constituintes de um portfolio, teríamos:
\begin{equation} 
  DEaR_{A+B}^{2} = DEar_{A}^{2}+DEaR_{B}^{2}+2\rho_{AB} DEaR_{A} DEaR_B
  \label{eq:ab}
\end{equation}

\hypertarget{var-paramuxe9trico-aproximauxe7uxe3o-cornish-fisher}{%
\subsection{VaR Paramétrico (Aproximação Cornish-Fisher)}\label{var-paramuxe9trico-aproximauxe7uxe3o-cornish-fisher}}

Quando a distribuição dos retornos apresentam excesso de curtose\footnote{medida de dispersão que caracteriza o achatamento da curva da função de distribuição} (\emph{Kurtosis}) e/ou assimetria\footnote{permite distinguir as distribuições assimétricas} (\emph{Skewness}) relativamente a uma distribuição normal pode-se proceder à aproximação Cornish-Fisher, permitindo desta forma uma aproximação ao VaR. Por exemplo, na figura \ref{fig:quant} temos uma distribuição do tipo leptocúrtica, sendo caracterizada por um pico mais alto e caudas mais pesadas que uma distribuição normal.
\bigskip

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{image/kurtosis} 

}

\caption{Kurtosis}\label{fig:quant}
\end{figure}
\centering

Fonte: \citep[pp.46]{quant}

\justifying

O cálculo do VaR com aproximação Cornish-Fisher efectua-se de acordo com a equação \eqref{eq:varcf}, sendo que para calcular o valor referente a CF se aplica a equação \eqref{eq:cf}.
\begin{equation} 
  VaR_{t+1}^{p} = -\sigma_{t+1}*CF_{p}^{-1}
  \label{eq:varcf}
\end{equation}
onde
\begin{equation} 
  CF_{p}^{-1} = \Phi_{p}^{-1} + \frac{\zeta_{1}}{6}[(\Phi_{p}^{-1})^2-1] + \frac{\zeta_{2}}{24}[(\Phi_{p}^{-1})^3-3\Phi_{p}^{-1}] - \frac{\zeta_{1}^{2}}{36}[2(\Phi_{p}^{-1})^3-5\Phi_{p}^{-1}]
  \label{eq:cf}
\end{equation}

Os parâmetros referentes a \(\zeta_1\) e \(\zeta_2\) são respectivamente os valores da assimetria e do excesso de curtose. Esses valores são obtidos de acordo com as equações \eqref{eq:assimetria} e \eqref{eq:curtose}.
\begin{equation} 
 \zeta_1 = \frac{1}{n}\sum\bigg[\frac{X_i - \overline{X}}{\sigma}\bigg]^3
  \label{eq:assimetria}
\end{equation}
\begin{equation} 
 \zeta_2 = \frac{1}{n}\sum\bigg[\frac{X_i - \overline{X}}{\sigma}\bigg]^4 - 3
  \label{eq:curtose}
\end{equation}

\hypertarget{pacotes-do-r-para-anuxe1lise}{%
\chapter{Pacotes do R para análise}\label{pacotes-do-r-para-anuxe1lise}}

\newpage

We describe our methods in this chapter.

\hypertarget{aplicauxe7uxe3o-a-dados-do-modelo}{%
\chapter{Aplicação a dados do modelo}\label{aplicauxe7uxe3o-a-dados-do-modelo}}

\endgroup
\newpage

\hypertarget{introduuxe7uxe3o}{%
\section{Introdução}\label{introduuxe7uxe3o}}

\hypertarget{anuxe1lise-descritiva-dos-dados}{%
\section{Análise descritiva dos dados}\label{anuxe1lise-descritiva-dos-dados}}

A primeira fase consiste em extrair de forma aleatória 4 acções constituintes do Euro Stoxx 50, estando os valores obtidos representados na figura \ref{fig:empresas}.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{image/cotacao} 

}

\caption{Empresas extraidas do Euro Stoxx 50}\label{fig:empresas}
\end{figure}
\FloatBarrier
\centering

Fonte: Elaboração própria.

\justifying
\bigskip
\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{TEF.MC\textless{}{-}}\KeywordTok{read\_xlsx}\NormalTok{ (}\StringTok{"data/TEF.MC.xlsx"}\NormalTok{)}
\NormalTok{TEF.MC \textless{}{-}}\StringTok{ }\KeywordTok{xts}\NormalTok{(TEF.MC[, }\DecValTok{{-}1}\NormalTok{], }\DataTypeTok{order.by=}\KeywordTok{as.Date}\NormalTok{(TEF.MC}\OperatorTok{$}\NormalTok{Date))}
\NormalTok{GLE.PA\textless{}{-}}\KeywordTok{read\_xlsx}\NormalTok{ (}\StringTok{"data/GLE.PA.xlsx"}\NormalTok{)}
\NormalTok{GLE.PA \textless{}{-}}\StringTok{ }\KeywordTok{xts}\NormalTok{(GLE.PA[, }\DecValTok{{-}1}\NormalTok{], }\DataTypeTok{order.by=}\KeywordTok{as.Date}\NormalTok{(GLE.PA}\OperatorTok{$}\NormalTok{Date))}
\NormalTok{ENEL.MI\textless{}{-}}\KeywordTok{read\_xlsx}\NormalTok{ (}\StringTok{"data/ENEL.MI.xlsx"}\NormalTok{)}
\NormalTok{ENEL.MI \textless{}{-}}\StringTok{ }\KeywordTok{xts}\NormalTok{(ENEL.MI[, }\DecValTok{{-}1}\NormalTok{], }\DataTypeTok{order.by=}\KeywordTok{as.Date}\NormalTok{(ENEL.MI}\OperatorTok{$}\NormalTok{Date))}
\NormalTok{AIR.PA\textless{}{-}}\KeywordTok{read\_xlsx}\NormalTok{ (}\StringTok{"data/AIR.PA.xlsx"}\NormalTok{)}
\NormalTok{AIR.PA \textless{}{-}}\StringTok{ }\KeywordTok{xts}\NormalTok{(AIR.PA[, }\DecValTok{{-}1}\NormalTok{], }\DataTypeTok{order.by=}\KeywordTok{as.Date}\NormalTok{(AIR.PA}\OperatorTok{$}\NormalTok{Date))}
\end{Highlighting}
\end{Shaded}

\normalsize

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-4}Société Générale.Euronext Paris-25-05-2020/01-06-2020}
\centering
\begin{tabular}[t]{rr}
\toprule
Close & Adj Close\\
\midrule
12.544 & 10.344\\
13.424 & 13.424\\
14.304 & 14.304\\
13.916 & 13.916\\
13.232 & 13.232\\
\addlinespace
13.820 & 13.820\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:\url{https://finance.yahoo.com/}

\justifying
\bigskip

\begin{figure}

{\centering \includegraphics[width=0.45\linewidth]{bookdown-demo_files/figure-latex/cotacao-1} \includegraphics[width=0.45\linewidth]{bookdown-demo_files/figure-latex/cotacao-2} \includegraphics[width=0.45\linewidth]{bookdown-demo_files/figure-latex/cotacao-3} \includegraphics[width=0.45\linewidth]{bookdown-demo_files/figure-latex/cotacao-4} 

}

\caption{Evolução das cotações nos últimos 5 anos}\label{fig:cotacao}
\end{figure}
\FloatBarrier
\centering

Fonte: Elaboração própria.

\justifying
\bigskip

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-5}Cotações a preços ajustados-25-05-2020/01-06-2020}
\centering
\begin{tabular}[t]{rrrr}
\toprule
TEF.MC & ENEL.MI & GLE.PA & AIR.PA\\
\midrule
3.849220 & 6.254183 & 10.344 & 58.64\\
3.699806 & 6.259947 & 13.424 & 62.81\\
3.787268 & 6.327197 & 14.304 & 61.13\\
3.952170 & 6.525101 & 13.916 & 60.12\\
3.863797 & 6.629818 & 13.232 & 56.70\\
\addlinespace
4.008655 & 6.723007 & 13.820 & 59.44\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:\url{https://finance.yahoo.com/}

\justifying
\bigskip

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-6}Estatísticas das cotações}
\centering
\begin{tabular}[t]{lllll}
\toprule
  &     TEF.MC &    ENEL.MI &     GLE.PA &     AIR.PA\\
\midrule
 & Min.   :3.355 & Min.   :2.943 & Min.   : 9.702 & Min.   : 44.66\\
 & 1st Qu.:6.097 & 1st Qu.:3.891 & 1st Qu.:20.735 & 1st Qu.: 64.67\\
 & Median :6.456 & Median :4.331 & Median :25.922 & Median : 85.56\\
 & Mean   :6.375 & Mean   :4.624 & Mean   :25.603 & Mean   : 85.65\\
 & 3rd Qu.:6.792 & 3rd Qu.:5.267 & 3rd Qu.:31.364 & 3rd Qu.:108.01\\
\addlinespace
 & Max.   :8.089 & Max.   :8.229 & Max.   :35.649 & Max.   :134.60\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip
\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-7}Retornos logarítmicos diários-25-05-2020/01-06-2020}
\centering
\begin{tabular}[t]{rrrr}
\toprule
TEF.RET & ENEL.RET & GLE.RET & AIR.RET\\
\midrule
0.0300 & 0.0155 & 0.0083 & 0.0817\\
-0.0396 & 0.0009 & 0.2606 & 0.0687\\
0.0234 & 0.0107 & 0.0635 & -0.0271\\
0.0426 & 0.0308 & -0.0275 & -0.0167\\
-0.0226 & 0.0159 & -0.0504 & -0.0586\\
\addlinespace
0.0368 & 0.0140 & 0.0435 & 0.0472\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip
\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-8}Matrix correlação dos retornos}
\centering
\begin{tabular}[t]{lrrrr}
\toprule
  & TEF.RET & ENEL.RET & GLE.RET & AIR.RET\\
\midrule
TEF.RET & 1.0000000 & 0.5792880 & 0.5416984 & 0.3144011\\
ENEL.RET & 0.5792880 & 1.0000000 & 0.4564904 & 0.3423647\\
GLE.RET & 0.5416984 & 0.4564904 & 1.0000000 & 0.5417957\\
AIR.RET & 0.3144011 & 0.3423647 & 0.5417957 & 1.0000000\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip
\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-9}Estatísticas dos retornos}
\centering
\begin{tabular}[t]{lrrrr}
\toprule
  & TEF.RET & ENEL.RET & GLE.RET & AIR.RET\\
\midrule
média.anual & -0.128565 & 0.186336 & -0.142061 & 0.035758\\
volatilidade.anual & 0.270075 & 0.249512 & 0.407981 & 0.381835\\
mediana & -0.000500 & 0.000900 & -0.000300 & 0.000200\\
skewness & -1.199014 & -3.212281 & -0.652772 & -1.084556\\
kurtosis & 27.848870 & 43.434065 & 25.410242 & 24.429017\\
\addlinespace
min & -0.175800 & -0.221200 & -0.230300 & -0.250600\\
max & 0.163800 & 0.072500 & 0.260600 & 0.186200\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip
\begin{figure}

{\centering \includegraphics[width=0.45\linewidth]{bookdown-demo_files/figure-latex/volatilidade-1} \includegraphics[width=0.45\linewidth]{bookdown-demo_files/figure-latex/volatilidade-2} \includegraphics[width=0.45\linewidth]{bookdown-demo_files/figure-latex/volatilidade-3} \includegraphics[width=0.45\linewidth]{bookdown-demo_files/figure-latex/volatilidade-4} 

}

\caption{Volatilidade nos últimos 4 anos}\label{fig:volatilidade}
\end{figure}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip
\begin{figure}

{\centering \includegraphics[width=1\linewidth]{bookdown-demo_files/figure-latex/distr-1} 

}

\caption{Distribuição dos retornos}\label{fig:distr}
\end{figure}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip
\begin{figure}

{\centering \includegraphics[width=1\linewidth]{bookdown-demo_files/figure-latex/teste-1} 

}

\caption{Teste a normalidade das distribuições}\label{fig:teste}
\end{figure}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip
\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-10}Teste normalidade Shapiro-Wilk}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{lllll}
\toprule
  & TEF.RET & ENEL.RET & GLE.RET & AIR.RET\\
\midrule
statistic & c(W = 0.806556139172951) & c(W = 0.81527958050879) & c(W = 0.781822265470115) & c(W = 0.781772438450224)\\
p.value & 4.1518298262632e-33 & 1.62872401140161e-32 & 1.10625328031641e-34 & 1.09857623834578e-34\\
\bottomrule
\end{tabular}}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

\hypertarget{ewma}{%
\section{EWMA}\label{ewma}}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-11}EWMA}
\centering
\begin{tabular}[t]{lrrrr}
\toprule
  & TEF.RET & ENEL.RET & GLE.RET & AIR.RET\\
\midrule
ewma & 0.034085 & 0.023709 & 0.075245 & 0.054579\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{bookdown-demo_files/figure-latex/TELp-1} 

}

\caption{EWMA}\label{fig:TELp}
\end{figure}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

\hypertarget{simulauxe7uxe3o-ewma}{%
\subsection{Simulação EWMA}\label{simulauxe7uxe3o-ewma}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dfewma \textless{}{-}}\StringTok{ }\KeywordTok{as.data.frame}\NormalTok{(pewma)}

\NormalTok{N \textless{}{-}}\StringTok{ }\DecValTok{80}
\NormalTok{dia \textless{}{-}}\StringTok{ }\DecValTok{1}\OperatorTok{:}\NormalTok{N}
\NormalTok{M \textless{}{-}}\StringTok{ }\DecValTok{1000}
\NormalTok{mu \textless{}{-}}\StringTok{ }\FloatTok{{-}0.00575}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{TEF.preco\_inicial \textless{}{-}}\StringTok{ }\NormalTok{TEF.MC}\OperatorTok{$}\NormalTok{Close[[}\KeywordTok{nrow}\NormalTok{(TEF.MC}\OperatorTok{$}\NormalTok{Close)]]}
\NormalTok{TEF.MC.sigma \textless{}{-}}\StringTok{ }\NormalTok{dfewma}\OperatorTok{$}\NormalTok{TEF.RET}\OperatorTok{*}\KeywordTok{sqrt}\NormalTok{(}\DecValTok{252}\NormalTok{)}
\NormalTok{TEF.MC.mean \textless{}{-}}\StringTok{ }\NormalTok{(mu}\OperatorTok{{-}}\NormalTok{(TEF.MC.sigma}\OperatorTok{\^{}}\DecValTok{2}\NormalTok{)}\OperatorTok{/}\DecValTok{2}\NormalTok{)}\OperatorTok{*}\NormalTok{(}\DecValTok{1}\OperatorTok{/}\DecValTok{252}\NormalTok{)}

\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{monte\_carlo\_sim \textless{}{-}}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\DataTypeTok{nrow=}\NormalTok{N, }\DataTypeTok{ncol =}\NormalTok{ M)}
\ControlFlowTok{for}\NormalTok{(j }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{M)\{}
\NormalTok{  monte\_carlo\_sim[[}\DecValTok{1}\NormalTok{,j]] \textless{}{-}}\StringTok{ }\NormalTok{TEF.preco\_inicial}
    \ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{2}\OperatorTok{:}\NormalTok{N)\{}
\NormalTok{      monte\_carlo\_sim[[i,j]] \textless{}{-}}\StringTok{ }\NormalTok{monte\_carlo\_sim[[i}\DecValTok{{-}1}\NormalTok{,j]]}\OperatorTok{*}\KeywordTok{exp}\NormalTok{(TEF.MC.mean}\OperatorTok{+}\NormalTok{TEF.MC.sigma}\OperatorTok{*}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{)}\OperatorTok{*}\KeywordTok{sqrt}\NormalTok{(}\DecValTok{1}\OperatorTok{/}\DecValTok{252}\NormalTok{))}
\NormalTok{    \}}
\NormalTok{\}}

\NormalTok{TEF.MC\_MC\_sim \textless{}{-}}\StringTok{ }\KeywordTok{as\_tibble}\NormalTok{(}\KeywordTok{cbind}\NormalTok{(dia,monte\_carlo\_sim))}
\NormalTok{w \textless{}{-}}\StringTok{ }\KeywordTok{str\_c}\NormalTok{(}\StringTok{\textquotesingle{}Sim\textquotesingle{}}\NormalTok{,}\KeywordTok{seq}\NormalTok{(}\DecValTok{1}\NormalTok{,M))}
\NormalTok{w \textless{}{-}}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{\textquotesingle{}Dia\textquotesingle{}}\NormalTok{,w)}
\KeywordTok{names}\NormalTok{(TEF.MC\_MC\_sim) \textless{}{-}}\StringTok{ }\NormalTok{w}
\NormalTok{TEF.MC\_MC\_sim \textless{}{-}}\StringTok{ }\KeywordTok{gather}\NormalTok{(TEF.MC\_MC\_sim, }\DataTypeTok{key=}\StringTok{\textquotesingle{}Simulation\textquotesingle{}}\NormalTok{, }\DataTypeTok{value =} \StringTok{\textquotesingle{}Preço\textquotesingle{}}\NormalTok{,}\OperatorTok{{-}}\NormalTok{(Dia))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.45\linewidth]{bookdown-demo_files/figure-latex/sim-1} \includegraphics[width=0.45\linewidth]{bookdown-demo_files/figure-latex/sim-2} \includegraphics[width=0.45\linewidth]{bookdown-demo_files/figure-latex/sim-3} \includegraphics[width=0.45\linewidth]{bookdown-demo_files/figure-latex/sim-4} 

}

\caption{Simulação Monte Carlo para 80 dias}\label{fig:sim}
\end{figure}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-17}Valores simulados}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{lrrrr}
\toprule
  & M.TEF.MC & M.ENEL.MI & M.GLE.PA & M.AIR.PA\\
\midrule
75 & 4.188878 & 6.925697 & 11.62720 & 54.64831\\
76 & 4.192417 & 6.915972 & 11.55361 & 54.42756\\
77 & 4.216259 & 6.911018 & 11.50560 & 54.29371\\
78 & 4.201474 & 6.873053 & 11.28486 & 53.56600\\
79 & 4.202018 & 6.851637 & 11.15256 & 53.13935\\
\addlinespace
80 & 4.195701 & 6.833317 & 11.03732 & 52.76993\\
\bottomrule
\end{tabular}}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

\hypertarget{portfolio-ewma}{%
\subsection{Portfolio EWMA}\label{portfolio-ewma}}

\hypertarget{garch}{%
\section{GARCH}\label{garch}}

\hypertarget{telefuxf3nica}{%
\subsection{TELEFÓNICA}\label{telefuxf3nica}}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-18}TEF coeficientes}
\centering
\begin{tabular}[t]{lrrrr}
\toprule
  &  Estimate &  Std. Error &  t value & Pr(>|t|)\\
\midrule
mu & -0.000275 & 0.000349 & -0.786996 & 0.431284\\
omega & 0.000009 & 0.000003 & 2.626875 & 0.008617\\
alpha1 & 0.094462 & 0.028183 & 3.351714 & 0.000803\\
beta1 & 0.862275 & 0.035908 & 24.013557 & 0.000000\\
shape & 4.849731 & 0.699459 & 6.933546 & 0.000000\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-19}Information Criterion Statistics}
\centering
\begin{tabular}[t]{lr}
\toprule
  & x\\
\midrule
AIC & -5.880106\\
BIC & -5.855799\\
SIC & -5.880154\\
HQIC & -5.870873\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-20}Standardized Residuals Tests}
\centering
\begin{tabular}[t]{lrrr}
\toprule
  & lags & statistic & p-value\\
\midrule
Ljung-Box Test 10 & 10 & 5.365586 & 0.8654579\\
Ljung-Box Test 15 & 15 & 6.370089 & 0.9728383\\
Ljung-Box Test 20 & 20 & 9.016115 & 0.9827199\\
Ljung-Box Test 10 R\textasciicircum{}2 & 10 & 3.984322 & 0.9480515\\
Ljung-Box Test 15 R\textasciicircum{}2 & 15 & 4.641853 & 0.9947489\\
\addlinespace
Ljung-Box Test 20 R\textasciicircum{}2 & 20 & 5.629360 & 0.9993135\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip
\begin{figure}

{\centering \includegraphics[width=1\linewidth]{bookdown-demo_files/figure-latex/TELplot-1} 

}

\caption{Telefónica}\label{fig:TELplot}
\end{figure}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

\hypertarget{enel}{%
\subsection{ENEL}\label{enel}}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-22}ENEL coeficientes}
\centering
\begin{tabular}[t]{lrrrr}
\toprule
  &  Estimate &  Std. Error &  t value & Pr(>|t|)\\
\midrule
mu & 0.001136 & 0.000341 & 3.327331 & 0.000877\\
omega & 0.000015 & 0.000006 & 2.452925 & 0.014170\\
alpha1 & 0.101807 & 0.034761 & 2.928744 & 0.003403\\
beta1 & 0.820593 & 0.054752 & 14.987439 & 0.000000\\
shape & 4.505741 & 0.641796 & 7.020522 & 0.000000\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-23}ENEL Information Criterion Statistics}
\centering
\begin{tabular}[t]{lr}
\toprule
  & x\\
\midrule
AIC & -5.924634\\
BIC & -5.900327\\
SIC & -5.924682\\
HQIC & -5.915401\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-24}ENEL Standardized Residuals Tests}
\centering
\begin{tabular}[t]{lrrr}
\toprule
  & lags & statistic & p-value\\
\midrule
Ljung-Box Test 10 & 10 & 7.094059 & 0.7165364\\
Ljung-Box Test 15 & 15 & 10.856248 & 0.7627166\\
Ljung-Box Test 20 & 20 & 14.205137 & 0.8199445\\
Ljung-Box Test 10 R\textasciicircum{}2 & 10 & 14.667299 & 0.1446705\\
Ljung-Box Test 15 R\textasciicircum{}2 & 15 & 21.005772 & 0.1366450\\
\addlinespace
Ljung-Box Test 20 R\textasciicircum{}2 & 20 & 21.869880 & 0.3476129\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip
\begin{figure}

{\centering \includegraphics[width=1\linewidth]{bookdown-demo_files/figure-latex/ENELplot-1} 

}

\caption{ENEL}\label{fig:ENELplot}
\end{figure}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

\hypertarget{sociuxe9te-guxe9nuxe9rale}{%
\subsection{SOCIÉTE GÉNÉRALE}\label{sociuxe9te-guxe9nuxe9rale}}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-26}GLE coeficientes}
\centering
\begin{tabular}[t]{lrrrr}
\toprule
  &  Estimate &  Std. Error &  t value & Pr(>|t|)\\
\midrule
mu & -0.000206 & 0.000440 & -0.468768 & 0.639235\\
ar1 & 0.105854 & 0.031107 & 3.402874 & 0.000667\\
omega & 0.000006 & 0.000003 & 2.027070 & 0.042655\\
alpha1 & 0.082622 & 0.023947 & 3.450161 & 0.000560\\
beta1 & 0.906152 & 0.025807 & 35.112916 & 0.000000\\
\addlinespace
shape & 4.586812 & 0.639949 & 7.167466 & 0.000000\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-27}GLE Information Criterion Statistics}
\centering
\begin{tabular}[t]{lr}
\toprule
  & x\\
\midrule
AIC & -5.270385\\
BIC & -5.241217\\
SIC & -5.270454\\
HQIC & -5.259305\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-28}GLE Standardized Residuals Tests}
\centering
\begin{tabular}[t]{lrrr}
\toprule
  & lags & statistic & p-value\\
\midrule
Ljung-Box Test 10 & 10 & 5.878758 & 0.8253445\\
Ljung-Box Test 15 & 15 & 7.740314 & 0.9337712\\
Ljung-Box Test 20 & 20 & 14.427032 & 0.8082015\\
Ljung-Box Test 10 R\textasciicircum{}2 & 10 & 6.727049 & 0.7509375\\
Ljung-Box Test 15 R\textasciicircum{}2 & 15 & 8.145806 & 0.9178041\\
\addlinespace
Ljung-Box Test 20 R\textasciicircum{}2 & 20 & 8.431973 & 0.9886019\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip
\begin{figure}

{\centering \includegraphics[width=1\linewidth]{bookdown-demo_files/figure-latex/GLEplot-1} 

}

\caption{ENEL}\label{fig:GLEplot}
\end{figure}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

\hypertarget{airbus}{%
\subsection{Airbus}\label{airbus}}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-30}AIR coeficientes}
\centering
\begin{tabular}[t]{lrrrr}
\toprule
  &  Estimate &  Std. Error &  t value & Pr(>|t|)\\
\midrule
mu & 0.000161 & 0.000128 & 1.254022 & 0.209834\\
ar1 & 0.849062 & 0.115516 & 7.350151 & 0.000000\\
ma1 & -0.873890 & 0.106280 & -8.222483 & 0.000000\\
omega & 0.000014 & 0.000005 & 2.730241 & 0.006329\\
alpha1 & 0.112889 & 0.027696 & 4.076007 & 0.000046\\
\addlinespace
beta1 & 0.849060 & 0.034133 & 24.875270 & 0.000000\\
shape & 5.460341 & 0.965924 & 5.652974 & 0.000000\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-31}AIR Information Criterion Statistics}
\centering
\begin{tabular}[t]{lr}
\toprule
  & x\\
\midrule
AIC & -5.381134\\
BIC & -5.347105\\
SIC & -5.381229\\
HQIC & -5.368208\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-32}AIR Standardized Residuals Tests}
\centering
\begin{tabular}[t]{lrrr}
\toprule
  & lags & statistic & p-value\\
\midrule
Ljung-Box Test 10 & 10 & 6.933033 & 0.7317516\\
Ljung-Box Test 15 & 15 & 13.058807 & 0.5977556\\
Ljung-Box Test 20 & 20 & 16.121427 & 0.7090631\\
Ljung-Box Test 10 R\textasciicircum{}2 & 10 & 24.459099 & 0.0064707\\
Ljung-Box Test 15 R\textasciicircum{}2 & 15 & 25.491652 & 0.0437178\\
\addlinespace
Ljung-Box Test 20 R\textasciicircum{}2 & 20 & 29.344316 & 0.0811977\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip
\begin{figure}

{\centering \includegraphics[width=1\linewidth]{bookdown-demo_files/figure-latex/AIRplot-1} 

}

\caption{ENEL}\label{fig:AIRplot}
\end{figure}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

\hypertarget{volatilidade-implicita}{%
\section{Volatilidade implicita}\label{volatilidade-implicita}}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{image/opcao} 

}

\caption{Opções call sobre as empresas }\label{fig:opcao}
\end{figure}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-34}Volatilidade Implícita}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{lrrrr}
\toprule
  & TEF.RET & ENEL.RET & GLE.RET & AIR.RET\\
\midrule
Volatilidade implícita & 0.037038 & 0.030534 & 0.053162 & 0.052567\\
\bottomrule
\end{tabular}}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

\hypertarget{conclusuxe3o}{%
\chapter*{Conclusão}\label{conclusuxe3o}}
\addcontentsline{toc}{chapter}{Conclusão}

We have finished a nice book.

  \bibliography{book.bib,packages.bib}

\part*{Apêndices}
\addcontentsline{toc}{part}{Apêndices}

\newpage
\part*{\normalfont\huge\bfseries\centering Apêndice I}
\newpage

\part*{\normalfont\huge\bfseries\centering Apêndice II}
\newpage




\end{document}
