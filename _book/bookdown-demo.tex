% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  12pt,
  a4paper,
  openany]{book}
\usepackage{lmodern}
\usepackage{setspace}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
  \setmainfont[]{Arial}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[left=3.5cm,right=2cm,top=3cm,bottom=3cm, asymmetric]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\pagestyle{plain}
\usepackage{booktabs}
\usepackage{amsmath,amsfonts,amsthm,bm} % Math packages
\usepackage{mathtools, cases}
\usepackage{fontspec}
\usepackage[utf8]{inputenc}
\usepackage[portuguese]{babel}

\usepackage{etoolbox}

\usepackage{ragged2e}

\usepackage{titlesec}

\usepackage{setspace}

\usepackage{changepage}

\usepackage{placeins}

\usepackage{makeidx}
\makeindex
\usepackage[nottoc]{tocbibind}

\makeatletter
\patchcmd{\ttl@save@mkschap}{*}{}{}{}
\makeatother

\usepackage{indentfirst}
\usepackage{floatrow}
\floatsetup[figure]{capposition=top}
\floatsetup[table]{capposition=top}
\usepackage{subfig}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\ifluatex
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{apalike}

\author{}
\date{\vspace{-2.5em}}

\begin{document}

%titlepage
\thispagestyle{empty}
\begin{center}
\begin{minipage}{0.90\linewidth}
    \centering
%University logo
    \includegraphics[width=1\textwidth]{image/biglogo.png}

%Thesis title
    {\uppercase{\Large Impacto da volatilidade na otimização de portfolios financeiros\par}}
    \vspace{2cm}
%Author's name
    {\Large Leonel da Silva Baptista\par}
    \vspace{2cm}
%Degree
    {\Large Mestrado em Estatística, Matemática e Computação\par}
    {\Large Ramo Estatística Computacional\par}
    \vspace{2cm}

%Date
    {\Large 2020}
\end{minipage}
\end{center}


%titlepage
\thispagestyle{empty}
\begin{center}
\begin{minipage}{0.90\linewidth}
    \centering
%University logo
    \includegraphics[width=1\textwidth]{image/logo.png}

%Thesis title
    {\uppercase{\Large Impacto da volatilidade na otimização de portfolios financeiros\par}}
    \vspace{2cm}
%Author's name
    {\Large Leonel da Silva Baptista\par}
    \vspace{2cm}
%Degree
    {\Large Mestrado em Estatística, Matemática e Computação\par}
    {\Large Ramo Estatística Computacional\par}
    \vspace{2cm}
%oriented
    {\Large Dissertação orientada pelo\par}
    {\Large Professor Doutor Amílcar Manuel do Rosário Oliveira\par}
    \vspace{2cm}
%Date
    {\Large 2020}
\end{minipage}
\end{center}

\pagenumbering{gobble}% Remove page numbers (and reset to 1)

\clearpage

\chapter*{Resumo}
\fontsize{12}{21}\selectfont
A presente dissertação têm como âmbito a análise de três métodos diferentes de obter a volatilidade de instrumentos financeiros, nomeadamente valores mobiliários, e seu consequente impacto no resultado da rentabilidade de portfolios constituídos utilizando como pressuposto a média variância, assim como a sua exposição ao risco, sendo que a volatilidade constitui uma peça central na constituição de determinados instrumentos financeiros e respetivo calculo de exposição ao risco.

Os métodos analisados para calculo da volatilidade são a Média Movel Exponencial (EWMA), o modelo da heteroscedasticidade condicional auto-regressiva generalizada (GARCH) e a volatilidade implícita. Os dois primeiros métodos têm como subjacentes dados históricos dos instrumentos financeiros, sendo que a volatilidade implícita é a volatilidade esperada pelo mercado, sendo obtida através da cotação das opções dos respetivos subjacentes.

A análise de risco é efetuada aplicando dois métodos complementares de análise. O Value at Risk (VaR), que contempla a percentagem de perdas que excedem o VaR e o Expected shortfall (ES), que contempla a magnitude dessas perdas.

Este trabalho é realizado tendo como ferramenta de apoio a linguagem de programação R.
\bigbreak

\noindent\textbf{Palavras chave:} Volatilidade, portfolio, rentabilidade, risco, R




\pagenumbering{roman}% Arabic page numbers (and reset to 1)
\setcounter{page}{2}

\chapter*{Abstract}
\fontsize{12}{21}\selectfont
The scope of this dissertation is to analyze three different methods of obtaining the volatility of financial instruments, namely securities, and their consequent impact on the profitability of portfolios constituted using the assumption of mean-variance, as well as their exposure to risk, volatility is a central element in the constitution of certain financial instruments and the respective calculation of exposure to risk.

The methods analyzed for calculating the volatility are the Exponential Moving Average (EWMA), the generalized autoregressive conditional heteroscedasticity model (GARCH) and the implied volatility. The first two methods are based on historical data on financial instruments, the implied volatility being the volatility expected by the market, being obtained through the quotation of the options of the respective underlying.

The risk analysis is carried out using two complementary methods of analysis. Value at Risk (VaR), which includes the percentage of losses that exceed VaR and Expected shortfall (ES), which considers the magnitude of these losses.

This work is carried out using the R programming language as a support tool.

\bigbreak

\noindent\textbf{Keywords:} Volatility, portfolio, profitability, risk, R

\newenvironment{dedication}
  {\clearpage           % we want a new page
   \itshape             % the text is in italics
   \raggedleft          % flush to the right margin
  }
  {\par % end the paragraph
   \vspace{\stretch{3}} % space at bottom is three times that at the top
   \clearpage           % finish off the page
  }
\begin{dedication}
{\Large Dedicado a minha esposa\par}
\end{dedication}

\chapter*{Agradecimentos}

\renewcommand*\contentsname{Índice}
{
\setcounter{tocdepth}{2}
\tableofcontents
}
\listoftables
\listoffigures
\setstretch{1.5}
\hypertarget{simbologia-e-notauxe7uxf5es}{%
\chapter*{Simbologia e notações}\label{simbologia-e-notauxe7uxf5es}}
\addcontentsline{toc}{chapter}{Simbologia e notações}

\mainmatter

\hypertarget{intro}{%
\chapter*{Introdução}\label{intro}}
\addcontentsline{toc}{chapter}{Introdução}

A estatística aplicada ao sector financeiro têm sido pratica comum nas últimas décadas, sendo que a sua aplicação não se resume apenas a estatística descritiva, tendo vindo a beneficiar dos avanços verificados na aplicação de ferramentas estatísticas para analise preditiva dos dados, devido essencialmente aos avanços tecnológicos no hardware de equipamentos informáticos que permitem a aplicação de algoritmos mais complexos que de outro modo não seria possível utilizar, pelo menos em tempo útil.

Um dos sectores com grande aplicabilidade dos métodos matemáticos e estatísticos nas finanças é a analise quantitativa, sendo as principais áreas de aplicação a estruturação de derivados, gestão do risco, trading automático e gestão de investimentos.

Historicamente, a analise quantitativa iniciou-se em 1900 com Louis Jean-Baptiste Alphonse Bachelier, onde a sua tese de doutoramento forneceu um modelo para estipular o preço de opções considerando uma distribuição normal (\url{https://en.wikipedia.org/wiki/Quantitative_analysis_(finance)}).

Na década de 50, Harry Markowitz escreveu um artigo intitulado ``Portfolio Selection'' que viria a revolucionar o modo como selecionar uma carteira de instrumentos financeiros, aplicando princípios de correlação e variância de modo a constituir portfolios de ações , onde a ``fronteira eficiente'' representa portfolios que maximizam retornos de acordo com o risco assumido, providenciando modelos que demonstravam que só com a diversificação de investimentos é que se conseguiria atingir a eficiência, embora só bastante mais tarde esta teoria começa-se a ver a sua aplicabilidade nas instituições financeiras. A aplicabilidade de técnicas estatísticas fica saliente quando Markowitz estipula que ``para usar a regra da média-variância na seleção de ações devemos ter procedimentos para encontrar \(\mu_i\) e \(\sigma_{ij}\) razoáveis. Estes procedimentos, eu acredito, devem combinar técnicas estatísticas e julgamento prático do Homem'' \citep[pp.91]{Markowitz1952}. As limitações do modelo prendem-se com pressuposto que não representam exatamente a realidade, como o pressuposto de que os retornos das ações seguem uma distribuição normal, sendo que a distribuição dos retornos segue muitas vezes uma distribuição com curtose leptocúrtica, apresentando caudas pesadas e um pico superior ao da distribuição normal.

Na década de 60, Sharpe, Lintner and Mossin desenvolveram um modelo para equilíbrio de mercado, definido como \emph{Capital Asset Pricing Model} (CAPM), descrevendo a relação entre risco sistemático e o retorno esperado. O modelo pressupõe que, se todos os investidores contêm o mesmo portfolio, então, em equilíbrio esse deve ser o portfolio de mercado. De acordo com \citet{Sharpe1964}, em equilíbrio os preços dos ativos de capital foram ajustados de forma que o investidor consiga atingir qualquer ponto desejado ao longo da reta do mercado capital, ou \emph{capital market line} (CMP), pressupondo que o investidor siga uma estratégia de diversificação do investimento. O CMP pode ser utilizado de modo a otimizar um portfolio caso seja contemplado uma taxa de juro sem risco na sua estruturação, sendo o ponto tangente a curva denominada de fronteira eficiente.

Também na década de 60 foi apresentado pela primeira vez o modelo de Black-Scholes-Merton, fornecendo uma solução para valorizar opções europeias e outros derivados. O modelo assume que os preços têm uma distribuição lognormal e que a volatilidade é constante ao longo do tempo. A volatilidade que é assumida neste modelo é a volatilidade implícita da opção, ou seja, a volatilidade para o qual o valor dado pelo modelo Black-Scholes-Merton iguala o preço de mercado. Outros modelos foram desenvolvidos de modo a valorizar opções e outros derivados financeiros, entre eles a arvore binomial e simulação de Monte Carlo.

Os vários modelos apresentados têm como finalidade contribuir para uma decisão mais informada por parte do investidor, sendo que na generalidade o investidor irá optar pelo investimento que apresenta um maior retorno de acordo com o risco a que se dispõem estar exposto, tendo em consideração o seu perfil e expectativas.A escolha do portfólio é feita resolvendo um problema de otimização, no qual o risco do portfólio é minimizado sendo definido como retrição o valor desejado de retorno esperado. Desta forma é importante quantificar o risco. Existem vários modelos para quantificar o risco, ou seja quantificar a perda esperada de acordo com a hipótese de ocorrência de determinado cenário, sendo que 2 desses modelos para análise do risco são o \emph{Value at Risk} (VaR) e o \emph{Expected Shortfall}, também denominado \emph{Conditional Value at Risk} (CVaR). De acordo com \citet{HistVaR}, em 1922 no New York Stock Exchange já eram exigidos requisitos de capital a alguns dos seus membros, tendo na década de 50 Markowitz e Roy, separadamente, publicado metodos para quantificar o VaR, sendo ambos bastante similares e com a finalidade de quantificar o risco a que estaria exposto um portfolio. A necessidade de utilizar medidas de risco mais sofisticada tornou-se mais visível na década de 80 devido ao aparecimento de produtos mais complexos e ao aumento da volatilidade dos mercados, sendo que devido a regulamentação cada vez mais exigente, como o Basel III e Solvency II, as instituições financeiras e seguradoras devem implementar mecanismos de gestão de risco, sendo que os requisitos de capital são bastante mais exigentes desde a ocorrência da crise do subprime em 2007. De acordo com os acordos de Basel o VaR deve ser estimado diariamente utilizando o percentil 99\textsuperscript{th}.

Todos estes modelos têm tido aplicabilidade na análise quantitativa financeira, sendo que novos modelos foram sendo desenvolvidos ou apenas melhorados de modo a dar resposta à realidade verificada no mercado. Como podemos subentender uma das disciplinas fundamentais na definição destes modelos é o conhecimento de estatística e a sua aplicação prática, quer através de técnicas paramétricas, onde se assume um pressuposto forte de que os valores de uma variável têm uma distribuição normal, seja através de técnicas não paramétricas, onde não se assume que a distribuição dos valores de uma variável apresentam distribuição normal.

O trabalho desenvolvido ao longo desta tese, propõem-se analisar o impacto que poderá ter o método de calculo da volatilidade sobre a definição de um portfolio, o seu retorno esperado assim como quantificar o risco a que se estará exposto. Desde os primeiros trabalhos de \citet{Markowitz1952} acerca da otimização de portfolios que vários outros trabalhos foram desenvolvidos para constituição e otimização de portfolios, sendo que nesta dissertação se irá aplicar o método introduzido por \citet{Markowitz1952}, utilizando a teoria da média-variância para a constituição de um portfolio. O mesmo se poderá afirmar acerca do cálculo da exposição ao risco por um portfolio, sendo, no entanto, o VaR e o CVaR dois dos métodos mais utilizados para quantificar essa métrica, sendo que de acordo com \citet{OptVaR2000} o CVaR é conhecido por ter melhores propriedades que o VaR. Como iremos ver existem diferentes métodos de calculo do VaR e CVaR, sendo que neste trabalho iremos utilizar a que for mais adequada ao tipo de dados em análise.

Como inicialmente referido, o objetivo é analisar as diferentes formas de calcular a variância, sendo que iremos focar-nos em três formas diferentes de calcular esse valor, análisar a sua implicação no resultado final, assim como o valor que resulta da quantificação de risco e o seu impacto na perceção pelo investidor.

A investigação decorrerá aplicando-se os diferentes métodos de calculo da variância a dados do mercado, assim como os pressupostos teóricos de cada um dos métodos, sendo constituída uma carteira de ações integrantes do Euro Stoxx 50, calculando o seu retorno final para cada uma das volatilidades, assim como o risco a que está exposto um investidor. O retorno obtido será também comparado com um \emph{benchmark}, neste caso o Euro Stoxx 50.

Ao longo deste percurso será também analisada a forma como é constituídos um portfolio, a teoria subjacente a média-variância, as retrições aplicáveis ao modelo desenvolvido, assim como a teoria subjacente aos vários métodos para análise da exposição ao risco aquando da constituição de um portfolio.

A aplicação pratica dos métodos aos dados do mercado será realizado com o apoio da linguagem de programação R, utilizando para esse efeito os vários ``packages'' disponíveis para aplicação ao sector financeiro. Um dos capítulos será dedicado a apresentação e descrição dos principais ``packages'' utilizados para análise dos dados, sendo que o R é parte integrante desta dissertação como ferramenta de análise estatísticas e aplicabilidade ao sector financeiro.

\begingroup
\titleformat{\chapter}[display]
{\normalfont\huge\bfseries\centering}{\chaptertitlename\ \thechapter}{20pt}{\Huge}

\hypertarget{modelauxe7uxe3o-estatuxedstica-na-otimizauxe7uxe3o-de-portfuxf3lios}{%
\chapter{Modelação Estatística na Otimização de Portfólios}\label{modelauxe7uxe3o-estatuxedstica-na-otimizauxe7uxe3o-de-portfuxf3lios}}

\newpage

\hypertarget{series-temporais}{%
\section{Series Temporais}\label{series-temporais}}

O valor da cotação de activos financeiros, como acções ou opções, são representados de forma sequencial ao longo do tempo, considerando determinado intervalo, que pode ser segundos, minutos, dias, semanas ou outro intervalo considerado útil para representação dos dados ao longo do tempo. Quando tal acontece estamos em presença de series temporais.

Os preços de activos financeiros ao longo do tempo formam o que é denominado por processos estocásticos. Processos estocásticos são uma classe de series temporais onde o valor da variável muda ao longo de tempo de forma aleatória. Os processo estocásticos podem ser classificados de discretos ou contínuos, sendo que na análise de activos financeiros, embora estes sigam processos discretos, serão considerados processos estocásticos contínuos ao longo do tempo, sendo que estes modelos acabam por ser bastante úteis na modelização dos preços de activos financeiros de acordo com \citet{Hull2018}.

\hypertarget{modelauxe7uxe3o-do-preuxe7o-de-acuxe7uxf5es}{%
\subsection{Modelação do preço de acções}\label{modelauxe7uxe3o-do-preuxe7o-de-acuxe7uxf5es}}

Os preços das acções seguem habitualmente o que é conhecido por um processo de Markov, onde apenas o valor presente importa para prever o valor futuro. Desta forma a única informação relevante é o seu valor no momento, sendo que os valores e trajecto verificado no passado não irão ter importância na definição da distribuição probabilística do preço no futuro \citep{Hull2018}.Desta forma as propriedades de Markov no preço das acções é consistente com a eficiência dos mercados na forma fraca, constituindo esta uma das três formas de eficiência de mercado definidas por Eugene Fama\footnote{Ver ``\url{https://pt.wikipedia.org/wiki/Eugene_Fama}''}.

O modelo representado aqui e que será utilizado para simular preços de activos financeiros atravessou vários pressupostos até a sua conclusão final, sendo apresentado de uma forma muito sucinta as principais etapas de desenvolvimento desse modelo.

Um dos primeiros modelos era representado por um processo de Wiener, sendo este um processo particular do processo estocástico Markov, referido como movimento Browniano, descrevendo a evolução de uma variável com distribuição normal padrão. A modelação pressupõe que a variável z possa ser dada pela seguinte equação:

\begin{equation} 
  dz = \varepsilon \sqrt{dt}\qquad   \varepsilon \sim N(0,1);
  \label{eq:wiener}
\end{equation}

Desta forma a variável z segue um processo de Wiener, sendo uma variável independente e identicamente distribuída (i.i.d).

Como este modelo não preenchia todos os pressupostos, aplicou-se um processo generalizado de Wiener (também conhecido como movimento Browniano (BM)), onde é incluindo um amplificador/redutor na parte aleatória do processo de forma a ajustar o processo a propriedades especificas de cada acção, ilustrado na equação \eqref{eq:gwiener}. Este processo descreve a evolução de um processo de uma variável com distribuição normal, com um desvio \(\mu\) por unidade de tempo e uma taxa de variância de \(\sigma^2\) também por unidade de tempo.

\begin{equation} 
  \delta S = \mu\delta t +\sigma\varepsilon\sqrt{\delta t}\qquad\varepsilon \sim N(0,1);
  \label{eq:gwiener}
\end{equation}

A diferença relativo a um processo de Wiener é que no processo generalizado de Wiener a taxa de desvio e variância pode ter como valor qualquer constante, sendo que no processo de Wiener esses valores são de 0 e 1 respectivamente.

Outro processo estocástico, conhecido como processo Itô, foi desenvolvido, representando um processo generalizado de Wiener, sendo que neste caso o valor dos parâmetros \(\mu\) e \(\sigma\) são funções do valor subjacente da variável S e do tempo t. Este modelo é o que vai ser utilizado para simulação do preço das acções sendo representado pelas seguintes equações:

\begin{equation} 
  \frac{\delta S}{S} = \mu\delta t +\sigma\varepsilon\sqrt{\delta t}\qquad\varepsilon \sim N(0,1);
  \label{eq:ito}
\end{equation}
\begin{equation} 
  In S_1 - InS_0 \approx\phi\Big[\Big(\mu-\frac{\sigma^2}{2}\Big)\delta t, \sigma\sqrt{\delta t}\Big]
  \label{eq:Inito}
\end{equation}
\begin{equation} 
  S_1 =S_0 e^{\Big(\mu-\frac{\sigma^2}{2}\Big)\delta t + \sigma\varepsilon\sqrt{\delta t}}
  \label{eq:logprice}
\end{equation}

Nesta equação o \(\mu\) representa a taxa de retorno anual esperado, sendo que \(\sigma\) representa o desvio padrão ou volatilidade da acção, parâmetro muito importante para a determinação do valor de vários derivados, havendo várias formas de calcular este valor como veremos mais adiante. Estes valores são função do corrente valor de S e do tempo actual t. Numa economia neutra face ao risco \(\mu\) é igual a taxa de juro sem risco. O \(\varepsilon\) representa uma variável com distribuição normal(N(0,1)).

Este processo é conhecido como movimento Browniano geométrico (GBM). De acordo com \citet{AppliedFinancial} um ``GBM pode ser considerado como um movimento probabilístico contínuo no qual o logaritmo da quantidade que varia aleatoriamente segue um movimento Browniano (processo de Wiener) com desvio.'' Este modelo é a base do modelo de Black-Scholes, que será revisto mais adiante, aquando do cálculo da volatilidade implícita nas opções.

Tendo em consideração a equação \eqref{eq:logprice}, \emph{S} segue uma distribuição lognormal. Uma distribuição lognormal é mais realístico de acordo com o movimento do preço das acções, prevenindo que o valor se torne negativo.

Em simulação, este processo é realizado considerando uma distribuição normal com média e variância dada pela equação \eqref{eq:Inito} \citep{FRM1}.

\hypertarget{simulauxe7uxe3o-de-monte-carlo}{%
\subsection{Simulação de Monte Carlo}\label{simulauxe7uxe3o-de-monte-carlo}}

A simulação de Monte Carlo consiste na geração de valores a partir de uma determinada distribuição ou amostra, sendo que ``o termo Monte Carlo é usado para se referir a técnicas que envolvem simulação computacional''\citep[pp.457]{ProgSim}.

Ao simular os preços dos activos financeiros iremos utilizar a técnica de Monte Carlo de modo a gerar amostras aleatórias de acordo com a equação \eqref{eq:logprice}. Os preços serão simulados criando várias tentativas com valores aleatórios para \(\varepsilon\) a partir de \(\phi\)(0,1). A precisão dos valores obtidos na simulação depende do número de tentativas efectuadas, sendo considerado 1000 tentativas por cada dia e considerar o valor médio dessas tentativas como o valor simulado para cada um dos dias simulados.

\hypertarget{arma}{%
\section{ARMA}\label{arma}}

Antes de entrar no tema relativo a volatilidade, vamos introduzir o tema relativo ao modelo auto-regressivo de médias móveis ou ARMA, sendo um modelo que descreve processo estocásticos estacionários, ou seja, processos cujo parâmetros como a média e a variância não mudam ao longo do tempo, combinando dois factores, um relativo ao processo autoregressivo (AR) de ordem \emph{p} e outro relativo à média móvel (MA) de orfem\emph{q}, permitindo desta forma que o número de parâmetros seja pequeno e alcançando parcimônia na parametrização (\citet{parcimonia}).

Como a estacionariedade é um pressuposto assente em muitos processo estatísticos utilizados em séries temporais, dados não-estacionários são muitas vezes transformados de modo a tornarem-se estacionários (\citet{stwiki}).

Para podermos entender melhor este processo, vou introduzir o termo da auto-correlação, referindo-se à medida da relação linear entre valores desfasados ou \emph{lagged values} numa serie temporal, medindo a força e a direcção da associação linear, sendo que os coeficientes de correlação são visualizados em gráfico através da função de auto-correlação ou \emph{ACF} (\citet{foregeorge}). Series temporais que não demonstram auto-correlação são designados de \emph{white noise}. O que se pretende ao trabalhar com os retornos nas acções e não com o preço destas, é ter dados que apresentem um processo estocástico estacionário, sendo que os dados não apresentem auto-correlação.

Voltando ao termo ARMA(p,q), onde o p representa a ordem da parte referente ao processo autoregressivo, ou seja, ao AR(p), este é útil porque nos fornece um modo de ter dependência em relação ao tempo exibindo um declínio geométrico,sendo que as correlações entre as variáveis mais afastadas no tempo vão diminuindo, podendo ser descrito pela seguinte equação \eqref{eq:ar}

\begin{equation} 
  y_t =c+\phi_1y_{y-1}+\phi_2y_{y-2}+...+\phi_py_{y-p}+\varepsilon_t\qquad   -1<\phi<1
  \label{eq:ar}
\end{equation}
\begin{equation} 
  \nonumber \varepsilon \sim iid N(0,\sigma_{\epsilon}^{2})
\end{equation}
onde \(\varepsilon\) representa \emph{white noise} e o \(\phi\) o coeficiente de autorregressão. Ou seja, esta equação diz-nos que os valores presentes da variável dependem do seu valor passado.

O q refere-se à ordem da média móvel, ou MA(q), descrito do seguinte modo:

\begin{equation} 
  y_t =c+\varepsilon_t+\phi_1\varepsilon_{t-1}+\phi_2\varepsilon_{t-2}+...+\phi_q\varepsilon_{t-q}\qquad   -\infty<\phi<\infty 
  \label{eq:ma}
\end{equation}
\begin{equation} 
  \nonumber \varepsilon \sim iid N(0,\sigma_{\epsilon}^{2})
\end{equation}

A variável \(y_t\) é uma série de variáveis aleatórias não correlacionadas com média zero e variância constante, sendo \(\phi\) o coeficiente relativo à média móvel, onde a média móvel utiliza valores referentes aos erros no modelo de regressão. Este modelo é ideal, por exemplo quando se quer criar um modelo que apenas exibe dependência em relação a um período, como em retornos sobrepostos. Este modelo fornece uma boa descrição pra a evolução de taxas de juro e para a taxa crescimento de variáveis macroeconómicas.

O modelo ARMA(p,q) é definido pela equação \eqref{eq:arma}

\begin{equation} 
  y_t =\phi_1y_{y-1}+...+\phi_py_{y-p}+c+\phi_1\varepsilon_{t-1}+...+\phi_q\varepsilon_{t-q}
  \label{eq:arma}
\end{equation}

No mundo real, os processos de retorno podem ser estacionários, combinado-se o modelo ARMA e o modelo GARCH, onde usamos ARMA para ajustar a média e GARCH para ajustar a variância, visto que nos modelos ARMA a variância condicional dado o passado é constante.

De acordo com \citet{oscar}:

\begin{spacing}{1}
\begin{adjustwidth}{28.3464pt}{28.3464pt}\footnotesize
"Para entender melhor o modelo ARMA-GARCH, devemos esclarecer a distinção entre a média e variância incondicional e a variância e média  condicional de uma série temporal de retornos. A média incondicional e a variância são apenas a média e a variância da distribuição dos retornos, que são assumidos como constantes ao longo do todo o período considerado. Pode ser considerada como a média e a variância média de longo prazo durante esse período. Por exemplo, se o modelo for o simples "os retornos são independentes e distribuídos de forma idêntica (i.i.d.)", podemos desconsiderar a ordenação dos retornos na amostra e apenas estime a média e a variância da amostra.
Por outro lado, a média condicional e a variância condicional mudarão a cada momento. A média condicional e a variância condicional dependem do histórico de retornos até aquele ponto. Ou seja, nós contamos com as propriedades dinâmicas dos retornos, considerando sua distribuição em qualquer ponto no tempo como sendo condicional a todos as informações até esse ponto. As previsões feitas a partir dos modelos ARMA-GARCH não são iguais às atuais estimativas. Em vez disso, as previsões de retorno e volatilidade podem ser maiores ou menores do que a média no curto prazo, mas a medida que o horizonte de previsão aumenta as previsões de retorno e de volatilidade convergem para a volatilidade incondicional de longo prazo." (p.17)
\normalsize\end{adjustwidth}
\end{spacing}
\medskip

\hypertarget{volatilidade}{%
\section{Volatilidade}\label{volatilidade}}

Na indústria financeira o desvio padrão associado a instrumentos financeiros é definido como volatilidade. Desta forma quando estamos a falar de volatilidade estamos a considerar o desvio padrão observado.

De acordo com \citet{HullRisk2018}:

\begin{spacing}{1}
\begin{adjustwidth}{28.3464pt}{28.3464pt}\footnotesize
"A variável volatilidade, $\sigma$, é definida como o desvio padrão do retorno fornecido pela variável por unidade de tempo quando o retorno é expresso usando juros compostos. Quando a volatilidade é usada para valorizar opções, a unidade de tempo é normalmente 1 ano, sendo a volatilidade o desvio padrão do retorno compostos por ano. Quando a volatilidade é usada para a gestão de risco, a unidade de tempo usual é 1 dia de forma a que a volatilidade é o desvio padrão do retorno composto por dia." (pp.213-214)
\normalsize\end{adjustwidth}
\end{spacing}
\medskip

Vários são os modelos para calculo da volatilidade, sendo que um dos modelos mais simples é o do cálculo da variância de acordo com a equação \eqref{eq:estdesviopadrao} utilizando os dados históricos dos retornos, sendo que neste modelo o peso atribuído aos dados é o mesmo independentemente da sua antiguidade. Outros modelos como a Média Móvel Exponencial Ponderada (EWMA) e Heteroscedasticidade condicional auto-regressiva generalizada (GARCH) são modelos, que embora utilizem dados históricos, reconhecem que tanto a volatilidade como a correlação não são constantes ao longo do tempo, atribuindo maior peso aos dados mais recentes. Por fim, um dos modelos que não integra dados históricos mas sim as expectativas futuras para o cálculo da volatilidade é o da volatilidade implícita, utilizando o modelo de Black-Scholes-Merton na valorização das respectivas opções relativamente ao subjacente.

Nos cálculos que utilizem dados históricos a escolha do tamanho da amostra \emph{n} deve ser grande o suficiente de modo a garantir uma melhor precisão nas estatísticas obtidas, sendo que neste caso devemos considerar que a volatilidade não é constante ao longo do tempo e que valores mais antigos podem não ser tão relevantes como os valores mais recentes. De acordo com \citep{Hull2018} esse valor deve ser compreendido entre 90 a 180 dias para a cotação de activos.

Para o calculo da volatilidade anual utiliza-se os número de dias de negociação, sendo considerado 252 dias por ano como valor de referência.

\hypertarget{autoregressive-conditional-heteroscedasticity-arch}{%
\subsection{AutoRegressive Conditional Heteroscedasticity (ARCH)}\label{autoregressive-conditional-heteroscedasticity-arch}}

Existem equações para o cálculo da variância que atribuem igual peso aos valores passados independentemente da sua antiguidade. Outros métodos atribuem mais peso aos dados mais recentes, pois pressupõem-se que esses carregam mais informação útil acerca da variável em estudo, criando modelos que prevêem com menor erro os valores futuros em estudo.

Uma das formas de cálculo da volatilidade tendo em consideração os valores mais recentes dos retornos é aplicando a equação

\begin{equation} 
  \sigma_{n}^{2} =\sum_{i=1}^{m}\alpha_i\mu_{n-1}^{2}
  \label{eq:weight}
\end{equation}
A variável \(\alpha\) representa o peso associado a observação \emph{i} dos retornos, sendo que a soma dos respectivos pesos deve ser igual a 1.

Tendo em consideração \citet{Hull2018} se a média a longo prazo da taxa de variância for considerada e assignado um peso a ela então teremos

\begin{equation} 
  \sigma_{n}^{2} =\gamma\mathcal{V}_{L}+\sum_{i=1}^{m}\alpha_i\mu_{n-1}^{2}
  \label{eq:arch}
\end{equation}
sendo que \(\mathcal{V}_{L}\) é a taxa de variância de longo prazo e \(\gamma\) é o peso associado a cada \(\mathcal{V}_{L}\), sendo que os repectivos pesos devem somar 1, de acordo com \[\gamma + \sum_{i=1}^{m}\alpha_i = 1\]

A equação \eqref{eq:arch} é conhecida como um modelo \emph{AutoRegressive Conditional Heteroscedasticity} ou ARCH(m)\footnote{Introduzido por Robert F.Engle em 1982, tendo-lhe sido atribuído o prémio Nobel da economia em 2003}, sendo que em finanças é uma das classes de modelos mais utilizada para prever a volatilidade. O \emph{m} representa o número de observações, sendo que a variável aleatória \(\mu\) segue uma distribuição normal, sendo no entanto prática comum considerar outros tipos de distribuições como a distribuição t-student, devido ao factos da distribuição dos retornos apresentarem caudas mais pesadas que uma distribuição normal.

Auto-regressivo significa que a variância presente depende do seu próprio passado e não num regressor exógeno. O facto de ser condicional significa que a variância de amanhã depende das variâncias mais recentes. Já a heteroscedasticidade significa que a variância não é constante ao longo do tempo. Quando a variância e a covariância variam ao longo do tempo falamos de heteroscedasticidade condicional.

O pressuposto destes modelos é de que a variância dos retornos seguem um processo previsível, sendo que os modelos ARCH são menos convincentes na previsão quando a volatilidade têm alterações bruscas. A apresentação do modelo ARCH serve como forma introdutória de apresentação aos modelos \emph{exponentially weighted moving average} (EWMA) e \emph{generalized autoregressive conditional heteroskedasticity} (GARCH).

\hypertarget{exponentially-weighted-moving-average-ewma}{%
\subsection{Exponentially weighted moving average (EWMA)}\label{exponentially-weighted-moving-average-ewma}}

O modelo da média móvel exponencial ponderada (EWMA) é um estimador calculado a partir de amostras sequenciais da população onde é atribuindo maior peso aos valores mais recentes, sendo que esse peso diminui exponencialmente a medida que vamos recuando no tempo. A formula utilizada para actualizar o valor para a volatilidade é

\begin{equation} 
  \sigma_{n}^{2} = \lambda\sigma_{n-1}^{2}+(1-\lambda)\mu_{n-1}^{2} 
  \label{eq:ewma}
\end{equation}
sendo um caso particular da equação \eqref{eq:weight}. Neste caso \(\gamma_{i+1} = \lambda\gamma_{i}\), onde 0\textless{}\(\lambda\leq1\) é uma constante, sendo \(\sigma_{n-1}\) a estimativa da volatilidade realizada no dia n-2 para o dia n-1, e \(\mu_{n-1}\) a mudança percentual diária mais recente. Ao valor de \(\lambda\) atribuido ``estudos empíricos mostram que o \emph{decay factor} (\(\lambda\)) 0,94 fornece uma boa estimativa para todos os ativos.''\citep[p.4]{riskmetrics}

De modo a entender porque à volatilidade obtida através da EWMA correspondem pesos que diminuem exponencialmente vamos substituir \(\sigma_{n-1}^{2}\) na equação \eqref{eq:ewma} de modo a obter

\begin{equation} 
  \sigma_{n}^{2} = (1-\lambda)(\mu_{n-1}^{2}+\lambda\mu_{n-2}^{2})+\lambda^{2}\sigma_{n-2}^{2}
  \label{eq:ewma1}
\end{equation}
Continuando a substituir acabamos por obter
\begin{equation} 
  \sigma_{n}^{2} = (1-\lambda)\sum_{i=1}^{m}\lambda^{i-1}\mu_{n-1}^{2}+\lambda^{m}\mu_{n-m}^{2}
  \label{eq:ewma2}
\end{equation}

Como podemos ver pela equação \eqref{eq:ewma2} o ``peso de \(\mu_{i}\) decresce a uma taxa \(\lambda\) a medida que vamos recuando no tempo. Cada peso é \(\lambda\) vezes o peso anterior.'' \citep[p.226]{HullRisk2018}. Como os pesos diminuem geometricamente, o EWMA também é referido como média móvel geométrica.

\hypertarget{generalized-autoregressive-conditional-heteroskedasticity-garch}{%
\subsection{Generalized autoregressive conditional heteroskedasticity (GARCH)}\label{generalized-autoregressive-conditional-heteroskedasticity-garch}}

Em 1986 um modelo mais flexível que o modelo ARCH foi proposto, sendo este o modelo \emph{Generalized} ARCH\footnote{Introduzido por Bollerslev(1986)}. De acordo com \citet{volatilitymodels} ``Uma grande vantagem dos modelos GARCH é que os retornos não são assumidos independentes, e mesmo se forem assumidos condicionais gaussianos para retornos anteriores, incondicionalmente, eles não são gaussianos, porque o agrupamento de volatilidade gera leptocurtose''(p.2). Também, e de acordo com \citet{portanalyse}, ``A volatilidade agora depende de ambos, uma combinação linear dos erros quadráticos da previsão (um termo autoregressivo) e variâncias condicional passada (um termo de média móvel).''(p.136)

A equação que define o modelo GARCH(1,1) é

\begin{equation} 
  \sigma_{n}^{2} = \gamma\mathcal{V}_{L} + \alpha\mu_{n-1}^{2} + \beta\sigma_{n-1}^{2}
  \label{eq:garch}
\end{equation}

Nesta equação, verifica-se que \(\sigma_{n}^{2}\) é calculado a partir da taxa de variação média de longo prazo \(\mathcal{V}_{L}\), como também a partir de \(\sigma_{n-1}\) e \(\mu_{n-1}\), sendo que o modelo EWMA é um caso particular do modelo GARCH(1,1) onde \(\gamma=0\), \(\alpha=1-\lambda\) e \(\beta=\lambda\). Tal como referido nos modelos anteriores, a soma dos diferentes pesos deve ser igual a 1, sendo \[\gamma+\sigma+\beta=1\]

O modelo genérico de GARCH é GARCH(p,q) onde o modelo calcula \(\sigma_{n}^{2}\) a partir das observações \emph{p} mais recentes de \(\mu^2\) e as mais recentes estimações \emph{q} da taxa de variância. Desta forma, o modelo "``(1,1) em GARCH(1,1) indica que \(\sigma_{n}^{2}\) é baseado nas mais recentes observações de \(\mu^2\) e nas mais recentes estimações da taxa de variância.''\citep[p.227]{Hull2018}

Considerando \(\omega=\gamma\mathcal{V}_{L}\), o modelo GARCH(1,1) pode ser definido como

\begin{equation} 
  \sigma_{n}^{2} = \omega + \alpha\mu_{n-1}^{2} + \beta\sigma_{n-1}^{2}
  \label{eq:garch2}
\end{equation}

A equação \eqref{eq:garch2} é a que costuma ser utilizada de forma a estimar os parâmetros. De notar de que para obter um processo estável GARCH(1,1) é necessário que \(\sigma+\beta<1\), ou então o peso aplicado a variância de longo prazo é negativa. A soma \(\sigma+\beta\) representa o que é conhecido como a persistência. A persistência num modelo GARCH representa o modo como a volatilidades decai rapidamente após um grande choque.

A estimação dos parâmetros, tanto para o modelo EWMA como para o modelo GARCH(1,1), é realizado utilizando um processo conhecido como \emph{maximum likelihood method}, onde se utilizam os dados históricos de modo a escolher os parâmetros que maximizem a probabilidade de ocorrência dos dados, de acordo com a equação

\begin{equation} 
  \sum_{i=1}^{m}=\bigg[-ln(\sigma_{i}^{2})-\frac{\mu_{i}^{2}}{\sigma_{i}^{2}}\bigg]
  \label{eq:mgarch}
\end{equation}

Os modelos standard GARCH não apresentam resposta adequada em modelos onde os dados tenham diferenças significativas devido ao impacto de boas ou más noticias, por exemplo, no comportamento da variável em estudo, sendo que existem outros modelos desenvolvidos com base no modelo standard GARCH para dar resposta a essas oscilações, como o modelo EGARCH.

\hypertarget{exponential-generalized-autoregressive-conditional-heteroscedastic-egarch}{%
\subsection{Exponential Generalized Autoregressive Conditional Heteroscedastic (EGARCH)}\label{exponential-generalized-autoregressive-conditional-heteroscedastic-egarch}}

O modelo EGARCH será utilizado na modelação da volatilidade da cotação de uma das empresas aqui em análise, sendo importante uma breve descrição do modelo.

Este modelo foi desenvolvido para capturar as assimetrias na volatilidade induzidas por grandes oscilações positivas e negativas nos retornos dos activos.

De acordo com \citet{marta} este modelo é expresso pela equação onde a variância condicionada, \(\sigma_t^2\) é uma função assimétrica dos valores passados de \(\mu_t\), ou seja:

\begin{equation} 
  Ln \sigma_{t}^{2}= \omega+\sum_{i=1}^n\beta_iln\sigma_{t-1}^2+\sum_{i=1}^n\alpha_i(\frac{|\mu_{t-i}|}{\sigma_{t-i}})+\sum_{i=1}^n\gamma_i(\frac{|\mu_{t-i}|}{\sigma_{t-i}})
  \label{eq:egarch}
\end{equation}
sendo que \(\alpha_0\) é uma constante, o \(\beta_i\), \(\alpha_i\) e \(\gamma_i\) parâmetros do modelo, \(\mu_{t-i}\) o erro observado em t-i e \(\sigma_{t-i}\) o desvio padrão observado em t-i. Também, e de acordo com \citet{marta} o ``modelo EGARCH garante que a variância será sempre positiva, por ser apresentada em logaritmos, sendo isto um fator vantajoso''(p.17).No entanto, e devido a sua extrutura exponencial, o modelo pode sobrestimar o impacto de observações anómalas na volatilidade.

\hypertarget{volatilidade-impluxedcita}{%
\subsection{Volatilidade implícita}\label{volatilidade-impluxedcita}}

O modelo de Black-Scholes-Merton\footnote{Os autores, Robert Merton e Myron Scholes, foram reconhecidos com o Nobel da economia em 1997} foi um modelo desenvolvido nos anos 70, considerado um ponto de ruptura na definição do preço de opções sobre acções europeias.

De entre os pressupostos\footnote{Para mais informação ver \citet{BlackScholes},pp.~640, capitulo ``The valuation formula''} utilizados para derivar a equação diferencial, importa salientar de que a taxa de juro sem risco, r, é constante e a mesma ao longo do tempo. De acordo com \citet{Hull2018} ``É importante considerar que a avaliação sem risco (ou o pressuposto de que todos os investidores são neutros ao risco) é meramente um artifício para obter solução para a equação diferencial de Black-Scholes-Merton''(p.312).

O processo que se assume ser aplicado ao preço dos activos é o descrito pela equação \eqref{eq:ito}. De salientar de que nenhumas das variáveis da equação é afectada pelas preferências de risco dos investidores, sendo que as variáveis que aparecem na equação são o valor presente do activo financeiro, tempo, volatilidade e a taxa de juro sem risco.

As soluções obtidas a partir da equação diferenciável de interesse para calculo da volatilidade implícita, são as aqui apresentadas para valorizar opções de compra (\emph{call}) e opções de venda (\emph{put}) do tipo europeias:

\begin{equation} 
  c = S_0N(d_1) - Ke^{-rT}N(d_2);
  \label{eq:call}
\end{equation}
e
\begin{equation} 
  p = Ke^{-rT}N(-d_2) - S_0N(-d_1);
  \label{eq:put}
\end{equation}
onde
\begin{equation} 
  d_1 = \frac{In(S_0/K)+(r+\sigma^2/2)T}{\sigma\sqrt{T}}
  \label{eq:d1}
\end{equation}
\begin{equation} 
  d_2 = \frac{In(S_0/K)+(r-\sigma^2/2)T}{\sigma\sqrt{T}}=d_1-\sigma\sqrt{T}
  \label{eq:d2}
\end{equation}

A função N(x) representa a função distribuição para uma distribuição normal padrão, sendo a probabilidade de uma variável ser menor que x (ver exemplo na figura \ref{fig:fdistribuicao}). O valor de N(x) pode ser obtido com a função do R pnorm(). A variável T representa o tempo medido em dias de negociação que faltam até a expiração da opção dividido pelos dias de negociação nesse ano, sendo S\textsubscript{0} o valor do activo subjacente no tempo 0, r a taxa de juro sem risco, \(\sigma\) a volatilidade anual e K o preço de exercício da opção.

\begin{figure}

{\centering \includegraphics[width=0.45\linewidth]{image/fdistribuicao} 

}

\caption{Função distribuição N(x)}\label{fig:fdistribuicao}
\end{figure}
\FloatBarrier
\centering

Fonte: Elaboração própria.

\justifying
\bigskip

O parâmetro da volatilidade não é um parâmetro que se consiga obter ou observar directamente, sendo um valor que representa a volatilidade esperada pelos investidores no futuro, conhecido como \emph{volatilidade implícita}. Um modo de obter este valor é a partir dos restantes parâmetros, ou seja, tendo o valor de uma opção de compra, e considerando os valores de S\textsubscript{0}, K, r e T, substituir estes pelos respectivos valores e obter o valor de \(\sigma\) que iguale o valor da \emph{call} utilizando as equações \eqref{eq:call} e \eqref{eq:d1} através de processos por aproximação iterativo.

A volatilidade implícita será diferente consoante o preço de exercício da opção, considerando todos os outros parâmetros iguais. Da conjugação dos valore de volatilidade obtidos para cada um dos preços de exercício da opção obtêm-se um gráfico conhecido como \emph{volatility smile}(figura \ref{fig:volatilitysmile}). Este gráfico será o mesmo, quer se esteja a considerar uma opção do tipo \emph{call} ou a mesma equivalente opção do tipo \emph{put}.

A variável volatilidade, \(\sigma\), é definida como o desvio padrão do retorno fornecido pela
variável por unidade de tempo quando o retorno é expresso usando juros compostos.
Quando a volatilidade é usada para valorizar opções, a unidade de tempo é normalmente 1 ano, sendo a volatilidade o desvio padrão do retorno compostos por ano.
Quando a volatilidade é usada para a gestão de risco, a unidade de tempo usual é 1 dia
de forma a que a volatilidade é o desvio padrão do retorno composto por dia.''(pp.213-
214)

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{image/volatilitysmile} 

}

\caption{Volatility Smile}\label{fig:volatilitysmile}
\end{figure}
\FloatBarrier
\centering

Fonte: \citep[pp.182]{volatilitysmile}

\justifying
\bigskip

Como de pode ver pela figura \ref{fig:volatilitysmile} a opção é considerada \emph{out-the-money} se o seu valor for inferior ao do respectivo subjacente, \emph{at-the-money} se for superior e \emph{in-the-money} se o valor for igual. No calculo do valor da volatilidade será utilizado o valor de preço de exercício \emph{in-the-money} de opções do tipo \emph{call}, ou na impossibilidade do valor do subjacente ser o mesmo do K, o mais próximo deste.

Quando comparado com outros métodos para calcular a volatilidade onde os dados utilizados são dados históricos, este método incorpora o sentimento presente dos investidores relativo a volatilidade futura de um determinado ativo ou instrumento financeiro.

\hypertarget{portfolios-muxe9dia-variuxe2ncia}{%
\section{Portfolios média-variância}\label{portfolios-muxe9dia-variuxe2ncia}}

A otimização de portfolios através da diversificação é um conceito básico que teve origem em Markowitz, criando o conceito de fronteira eficiente. Existem vários pressupostos definidos na obtenção deste modelo, não sendo, no entanto, o âmbito aqui analisar esses mesmos pressupostos, considerando que independentemente disso esses mesmos pressupostos são verificados. De acordo com \citet{Modern2013}, ``todas os pressupostos acerca da analise de portfolio foram demonstradas serem simplistas, e em alguns casos demasiado simplistas.{[}\ldots{]}Pessoas necessitam apenas de se comportar como se fossem descritas pelos pressupostos para uma teoria ser válida'' \citep[pp.5]{Modern2013}.

Para aplicação deste modelo deve-se obter os seguintes dados dos instrumentos financeiros que vão constituir o portfolio:

\begin{itemize}
\tightlist
\item
  A taxa do retorno esperado, E(r);
\item
  O desvio padrão dos retornos, \(\sigma\);
\item
  O coeficiente de correlação,\(\rho\), entre cada um dos activos.
\end{itemize}

O retorno esperado vai depender de vários factores, essencialmente a taxa de retorno sem risco que se verifica no mercado, a taxa de inflação e o risco a que o investidor estará sujeito, sendo que quanto maior o risco, maior será o retorno esperado.

As séries dos retornos diários para cada um dos activos é calculada de acordo com a seguinte formula:

\begin{equation} 
  R_i = ln\Big(\frac{S_f}{S_i}\Big)
  \label{eq:logRet}
\end{equation}
A média dos retornos de cada um dos activos é calculada de acordo com a sua média aritmética:
\begin{equation} 
  \overline{R} = \frac{\displaystyle\sum_{i=1}^n R_i}{n}
  \label{eq:meanRet}
\end{equation}\\
O retorno de um portfolio de activos financeiros será uma média ponderada do retorno dos activos individuais, de acordo com a seguinte equação
\begin{equation} 
    R_{p} = \sum_{i=1}^{N}(X_{i}R_{ij})
  \label{eq:retp}
\end{equation}
onde \(X_{i}\) representa a fracção investida no activo \emph{i}.
O desvio padrão representa a volatilidade, ou risco, associada ao activo. Considerando que essa volatilidade é calculada com base nos dados históricos e nas formulas acima, então a estatística da amostra para o desvio padrão representa-se pela seguinte formula:

\begin{equation} 
  \hat{\sigma} = \sqrt\frac{\displaystyle\sum_{i=1}^n (R_i-\overline{R})^2}{n-1}
  \label{eq:estdesviopadrao}
\end{equation}

A variância para o portfolio é um pouco mais complicada a calcular do que o calculo para o retorno e para as variância individuais de cada um dos activos, como podemos verificar pela seguinte equação

\begin{equation} 
  \sigma_{p}^{2} = \sum_{j=1}^{N}(X_{j}^{2}\sigma_{j}^{2})+\sum_{j=1}^{N}\sum_{k=1}^{N}(X_{j}X_{k}\sigma_{jk})
  \label{eq:estdesviopadraop}
\end{equation}
onde \(k\neq j\). O termo \(\sigma_{jk}\) designa-se por covariância representando o modo como 2 activos se movem conjuntamente, sendo o valor calculado do seguinte modo,

\begin{equation} 
  Cov(R_{i},R_{j}) = E([R_{i}-E(R_{i})][R_{j}-E(R_{j})])
  \label{eq:covariancia}
\end{equation}

Se todos os termos forem independentes, isto é, a covariância for igual a 0, então apenas se mantêm o primeiro termo/somátorio na equação\#ref(eq:estdesviopadraop).

Quando se pretende interpretar o valor da covariância é prática comum utilizar o que se designa por coeficiente de correlação, sendo que o valor obtido varia entre -1 e +1, sendo que o -1 representa uma correlação negativa perfeita e o +1 uma correlação positiva perfeita. Se o valor for 0 então não existe relação linear entre as variáveis. De forma genérica podemos afirmar que a correlação mede a força da relação linear entre 2 variáveis, sendo a sua forma matemática \[\rho_{ij}=\frac{\sigma_{ij}}{\sigma_{i}\sigma_{j}}\]
Aos incluir-mos mais activos no nosso portfolio estamos a diversificar o risco e a diminuir a variância esperada do portfolio. De acordo com \citet{Goetzmann2014}:

\begin{spacing}{1}
\begin{adjustwidth}{28.3464pt}{28.3464pt}\footnotesize
"A contribuição para a variância da carteira da variância dos títulos individuais vai para zero à medida que N fica muito grande. No entanto, a contribuição dos termos de covariância aproxima-se do valor da covariância média conforme N aumenta.O risco individual dos activos pode ser diversificados, mas a contribuição para o risco total causado pelos termos de covariância não podem ser diversificados" (pp.56-57).
\normalsize\end{adjustwidth}
\end{spacing}
\medskip

Na (figura \ref{fig:covusa}) podemos ver que a partir de um determinado número de activos, normalmente compreendido entre 15 e 20, a percentagem de risco que pode ser eliminada pela diversificação estabiliza.



\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{image/covusa} 

}

\caption{Evolução da covariância ao aumentar a diversificação no portfolio.}\label{fig:covusa}
\end{figure}
\FloatBarrier
\centering

Fonte: \citep[pp.58]{Goetzmann2014}

\justifying
\bigskip

Com base no apresentado até agora, o que se propõe é optimizar um portfolio em que os activos que o constituem apresentem pesos de modo a minimizar o risco, ou seja, minimizar a variância total, sem a possibilidade de vendas a descoberto e de activo sem risco, determinando a carteira eficiente. O problema a que se propõe é minimizar \(\sigma_{p}^{2}\) de acordo com a equação \eqref{eq:estdesviopadraop}, sujeito ás seguintes restrições:

\begin{equation} 
  \sum_{i=1}^{N}X_{i}\overline{R}_{i}=\overline{R}_{p}
  \label{eq:und}
\end{equation}
\[X_{i}\geq0\] e \[\sum_{i=1}^{N}X_{i}=1\]
O problema pode ser resolvido construindo a função Lagrangeana

\begin{equation} 
  \mathcal{L} = \sum_{j=1}^{N}\sum_{k=1}^{N}(X_{j}X_{k}\sigma_{jk})+\lambda_{1}(\overline{R}_{p}-\sum_{j=1}^{N}X_{j}\overline{R}_{j})+\lambda_{2}(1-\sum_{j=1}^{N}X_{j})
  \label{eq:lagrangeana}
\end{equation}
embora a sua resolução envolva normalmente métodos computacionais.

Desta forma, se considerar-mos a figura \ref{fig:eficient} a fronteira eficiente para o conjunto de portfolios encontra-se entre o ponto II e o ponto III, sendo que de acordo com os pressupostos de minimização do risco o ponto referente a II é o que apresenta um menor risco na fronteira eficiente definida.



\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{image/eficient} 

}

\caption{Fronteira eficiente}\label{fig:eficient}
\end{figure}
\FloatBarrier
\centering

Fonte: \citep[p.33]{invest}

\justifying
\medskip

A definição e optimização de portfolios está sujeita a outras restrições que não serão aqui apresentadas, tais como custos de \emph{trading}, custos de oportunidade ou custos associados a regulamentação e fiscalidade\footnote{O artigo \citet{Fabozzi2014} ``60 Years of portfolio optimization:Practical challenges and current trends'' aborda várias outras restrições na abordagem da optimização na média-variância proposta por Markowitz}.

\hypertarget{value-at-risk}{%
\section{Value at Risk}\label{value-at-risk}}

A quantificação do risco é fundamental para a gestão e atenuação de perdas no valor da carteira ao longo do tempo. Na gestão da carteira a aplicação de métricas de risco permite a adaptação contínua do portfólio aos fatores de risco quantificáveis, podendo-se, através de uma gestão ativa, manter o investidor devidamente informado relativamente ao risco que o seu investimento incorpora e poder tomar medidas proactivas de adaptação do investimento ao nível de risco verificado, tendo em consideração o perfil do investidor.O Value at Risk (VaR) é uma dessas métricas de risco.

O Value at Risk (VaR)\footnote{Markowitz foi dos primeiros autores a contemplar a análise de risco em investimentos, como se pode verificar em \citet{Markowitz1952}} é uma medida probabilística para a perda máxima provável de uma carteira para um nível de confiança determinado,num horizonte temporal especificado. Pode-se definir o VaR como ``descrevendo o quantil da distribuição de ganhos e perdas projectado ao longo do horizonte alvo. Se \emph{c} for o intervalo de confiança selecionado, VaR corresponde ao nível inferior da cauda 1-\emph{c}''\citep[pp.17]{philippe}. Este valor é sempre positivo.

O calculo do valor do VaR é de carácter obrigatório para entidades financeiras e seguradoras, sendo que os reguladores, dependendo da sua jurisdição, determinam os parâmetros quantitativos a serem utilizados.
No caso do Banco Central Europeu\footnote{ver relatório técnico \citet{ecb}}, esses parâmetros são de que o cálculo deve ser efectuado para um intervalo temporal de 10 dias de negociação e para um intervalo de confiança de 99\%, sendo considerado para esses cálculos pelo menos 250 dias negociação de observação de valores históricos.

O cálculo do VaR pode ser realizado de modos diferentes, existindo vários métodos, sendo considerados métodos de tipo não paramétrico, como o método histórico em que não se assume nenhum pressuposto na distribuição desses dados, ou métodos do tipo paramétrico, onde se assume um determinado tipo de distribuição dos dados. Para efeito desta dissertação será aplicado um método paramétrico para cálculo do VaR.

\hypertarget{var-paramuxe9trico-gaussiana}{%
\subsection{VaR Paramétrico (Gaussiana)}\label{var-paramuxe9trico-gaussiana}}

O VaR paramétrico pressupõe que os retornos diários apresentem uma distribuição normal (figura \ref{fig:var}), sendo que a sua representação matemática se encontra definida na equação \eqref{eq:var}.

\begin{equation} 
  VaR_{t+1}^{p} = -\sigma_{t+1}\Phi_{p}^{-1}
  \label{eq:var}
\end{equation}


\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{image/VaR} 

}

\caption{VaR com intervalo confiança 95\% e 99\%.}\label{fig:var}
\end{figure}
\FloatBarrier
\centering

Fonte: \citep[pp.13]{phdthesis}

\justifying
\bigskip

O \(\Phi (p)\) representa a função distribuição e \(\Phi^{-1} (p)\) a sua inversa, sendo que, por exemplo, para um intervalo de confiança de 99\% o valor de \(\Phi^{-1} (p)\) corresponde a -2.33. Se considerarmos que a volatilidade prevista a 1 dia é de 2\%, teremos um VaR = -0.020*(-2.33), o que corresponde a um valor de 0.0466. Podemos interpretar o VaR como sendo a existência de 1\% de probabilidade de perder mais do que 4.66\% do valor investido no activo no dia de hoje.

O \emph{Daily Value at Risk} (DEaR) é o valor diariamente em risco, sendo calculado de acordo com a equação \eqref{eq:dear}.

\begin{equation} 
  €DEaR = € \textnormal{Valor de mercado do investimento} * VaR
  \label{eq:dear}  
\end{equation}

O valor do VaR a mais de um dia pode-se calcular a partir do DEaR a um dia, de acordo com a equação \eqref{eq:vardays}, onde N representa o número de dias.

\begin{equation} 
  VaR = DEaR*\sqrt{N}
  \label{eq:vardays}
\end{equation}

Se estivermos a analisar o VaR de um portfolio, esse é calculado da mesma forma que a variância de um portfolio (equação \eqref{eq:varport}), considerando o DEaR individual de cada componente.

\begin{equation} 
  DEaR_{portfolio}^{2} = \sum_{i=1}^{N}\sum_{j=1}^{N}Cov(DEaR_i,DEaR_j)
  \label{eq:varport}
\end{equation}
onde
\begin{equation} 
  Cov(DEaR_i,DEaR_j) = DEaR_{i}DEaR_{j}\rho(DEaR_i,DEaR_j)
  \label{eq:covport}
\end{equation}

Por exemplo, considerando 2 activos, A e B, constituintes de um portfolio, teríamos:

\begin{equation} 
  DEaR_{A+B}^{2} = DEar_{A}^{2}+DEaR_{B}^{2}+2\rho_{AB} DEaR_{A} DEaR_B
  \label{eq:ab}
\end{equation}

\hypertarget{var-paramuxe9trico-aproximauxe7uxe3o-cornish-fisher}{%
\subsection{VaR Paramétrico (Aproximação Cornish-Fisher)}\label{var-paramuxe9trico-aproximauxe7uxe3o-cornish-fisher}}

Quando a distribuição dos retornos apresentam excesso de curtose\footnote{medida de dispersão que caracteriza o achatamento da curva da função de distribuição} (\emph{Kurtosis}) e/ou assimetria\footnote{permite distinguir as distribuições assimétricas} (\emph{Skewness}) relativamente a uma distribuição normal pode-se proceder à aproximação Cornish-Fisher, permitindo desta forma uma aproximação ao VaR. Por exemplo, na figura \ref{fig:quant} temos uma distribuição do tipo leptocúrtica, sendo caracterizada por um pico mais alto e caudas mais pesadas que uma distribuição normal.
\bigskip

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{image/kurtosis} 

}

\caption{Kurtosis}\label{fig:quant}
\end{figure}
\centering

Fonte: \citep[pp.46]{quant}

\justifying

O cálculo do VaR com aproximação Cornish-Fisher efectua-se de acordo com a equação \eqref{eq:varcf}, sendo que para calcular o valor referente a CF se aplica a equação \eqref{eq:cf}.

\begin{equation} 
  VaR_{t+1}^{p} = -\sigma_{t+1}*CF_{p}^{-1}
  \label{eq:varcf}
\end{equation}
onde
\begin{equation} 
  CF_{p}^{-1} = \Phi_{p}^{-1} + \frac{\zeta_{1}}{6}[(\Phi_{p}^{-1})^2-1] + \frac{\zeta_{2}}{24}[(\Phi_{p}^{-1})^3-3\Phi_{p}^{-1}] - \frac{\zeta_{1}^{2}}{36}[2(\Phi_{p}^{-1})^3-5\Phi_{p}^{-1}]
  \label{eq:cf}
\end{equation}

Os parâmetros referentes a \(\zeta_1\) e \(\zeta_2\) são respectivamente os valores da assimetria e do excesso de curtose. Esses valores são obtidos de acordo com as equações \eqref{eq:assimetria} e \eqref{eq:curtose}.

\begin{equation} 
 \zeta_1 = \frac{1}{n}\sum\bigg[\frac{X_i - \overline{X}}{\sigma}\bigg]^3
  \label{eq:assimetria}
\end{equation}
\begin{equation} 
 \zeta_2 = \frac{1}{n}\sum\bigg[\frac{X_i - \overline{X}}{\sigma}\bigg]^4 - 3
  \label{eq:curtose}
\end{equation}

\hypertarget{software-r}{%
\chapter{Software R}\label{software-r}}

\newpage

\hypertarget{introduuxe7uxe3o}{%
\section{Introdução}\label{introduuxe7uxe3o}}

O presente trabalho foi elaborado tendo como apoio na análise dos dados a linguagem de programação R\footnote{O seu criador é tido como John Chambers, no ano de 1976, nos laboratórios Bell sediados nos Estados Unidos}, sendo por isso fundamental uma breve descrição da mesma, assim como a apresentação e descrição dos principais pacotes utilizados, sendo também o objectivo a aplicabilidade de ferramentas de computação na análise de dados.

O R é uma linguagem de programação \emph{open source} bastante utilizada para computação estatística, havendo uma grande comunidade de suporte à linguagem, assim como uma grande diversidade de pacotes de software para várias áreas de matemática e estatística aplicada, sendo bastante utilizada em \emph{data mining} e \emph{machine learning}. A capacidade do R deve-se em grande parte a extensão dada à linguagem através dos pacotes desenvolvidos pela comunidade R, sendo \emph{open source}, que desta forma vão dando resposta aos desafios presentes na resolução de problemas estatísticos e na análise de dados, tornando esta linguagem de fácil utilização , não sendo necessário grandes conhecimentos de programação para aplicar esses modelos a casos práticos.

Desta forma, e havendo uma grande disponibilidade de pacotes desenvolvidos para o sector financeiro, optou-se pela sua utilização no desenvolvimento deste trabalho, sendo parte essencial para extração, tratamento e análise dos dados. Também foi parte basilar da construção do documento, sendo utilizado o BOOKDOWN, pacote para desenvolvimento e escrita de HTML, PDF, EPub e livros (\citet{R-bookdown}).

A versão utilizada no desenvolvimento do trabalho foi o R-4.0.3\footnote{Disponível em ``\url{https://cran.r-project.org/bin/windows/base/}''}, sendo utilizado como IDE o RStudio versão 1.3.1093\footnote{Disponível em ``\url{https://rstudio.com/products/rstudio/download/\#download}''}. O presente trabalho, o código R utilizado, assim como os dados analisados, encontram-se disponíveis no repositório \emph{online} GitHub, em ``\url{https://github.com/lsbaptista/Thesis}''.

\hypertarget{finanuxe7as-e-r}{%
\section{Finanças e R}\label{finanuxe7as-e-r}}

O R disponibiliza uma grande variedade de pacotes desenvolvidos pela sua comunidade. No entanto, devido a essa diversidade torna-se às vezes complicado saber qual o mais adequado para utilizar em cada uma das situações. A opção ao longo do trabalho prendeu-se essencialmente por optar por aqueles que deram uma melhor resposta ao problema em análise, havendo utilização de pacotes diferentes dentro de um mesmo tipo de análise, por de alguma forma um se adequar melhor que o outro, nem que fosse apenas na extração dos dados para posterior apresentação em tabelas. Salienta-se o facto de muitos destes pacotes dependerem de outros, sendo que ao serem instalados essas dependências também são instaladas.Dito isto passo seguidamente a apresentar e descrever de forma sumaria os principais pacotes aplicados na análise e modelação dos dados.

\hypertarget{fgarch}{%
\subsection{fGarch}\label{fgarch}}

O pacote \emph{fGarch} faz parte da organização Rmetrics, sendo este um projecto de software de desenvolvimento livre para o ensino de finanças computacionais\footnote{Disponível em ``\url{https://www.rmetrics.org/}''}. O \emph{fGarch} disponibiliza uma colecção de funções para analisar e modelar comportamento que apresentam heteroscedasticidade em modelos de séries temporais (\citet{fGarch}).

Uma das funções utilizadas foi o \emph{garchFit()}, que estima os parâmetros de um processo univariado ARMA-GARCH. Na função pode-se definir os parâmetros \emph{p} e \emph{q} relativos a ordem, sendo que GARCH(1,1) representa um modelo de primeira ordem. O tipo de distribuição dos dados pode ser escolhida de entre um grupo, sendo que o valor por defeito é o de uma distribuição normal. Vários valores podem ser extraidos, como um vector numérico dos resíduos ou dos respectivos desvio padrão calculados. Com a função \emph{summary()} obtemos descrição estatística do modelo e podemos obter vários gráficos de interesse com a função \emph{plot()}.

\hypertarget{fportfolio}{%
\subsection{fPortfolio}\label{fportfolio}}

O pacote \emph{fPortfolio} é mais um pacote de análise financeira disponibilizado pela Rmetrics, sendo que disponibiliza uma colecção de funções para optimizar portfolios a para analisa-los de diferentes pontos de vista (\citet{fPortfolio}).

Um dos métodos utilizados para a definição de portfolios foi o \emph{minvariancePortfolio()} que retorna um portfolio com a mínima variância na fronteira eficiente, minimizando o risco. Nesta função pode-se definir as restrições impostas na definição do portfolio, como a possibilidade de vendas a descoberto.

Este pacote apresenta depêndencias com outros, designadamente \emph{fBasics}, pacote desenvolvido pela Rmetrics tendo como finalidade disponibilizar funções gerais de análise estatística para o sector financeiro, como estimação de parâmetros, testes de hipótese e várias funções para distribuições de retornos financeiros como a Distribuição Hiperbólica Generalizada (\citet{fBasics}), o \emph{MFTSR}, pacote para modelar series temporais financeiras sendo parte integrante do livro ``\emph{Modelling Financial Time Series with R}'' (\citet{MFTSR}). Uma das funções utilizadas foi a do cálculo do \emph{EWMA}, utilizando o ewmaVol() e o \emph{fAssets}, pacote desenvolvido pela Rmetrics, que providência uma colecção de funções para gerir, investigar e analisar um conjunto de dados de activos financeiros (\citet{fAssets}).

\hypertarget{portes}{%
\subsection{Portes}\label{portes}}

Pacote que contêm univariados e multivariados \emph{portmanteau} testes estatísticos de series temporais baseados em distribuição assintótica e em testes de significância de Monte Carlo (\citet{portes}). Um dos testes \emph{portmanteau} utilizados foi o teste Ljun-Box para testar a autocorrelação. Estes testes são bastante úteis ao trabalhar com modelos ARIMA.

Este pacote têm como uma das depêndencias o pacote \emph{forecast} que contêm métodos e ferramentas para analisar e prever series temporais univariadas como modelos automáticos ARIMA.

\hypertarget{rquantlib}{%
\subsection{RQuantLib}\label{rquantlib}}

O \emph{RQuantLib} é desenvolvido pelo QuantLib, sendo uma biblioteca de código aberto para finanças quantitativas (\citet{RQuantLib}). A função utilizada foi a \emph{EuropeanOptionImpliedVolatility()} para cálculo da volatilidade implícita nas opções em análise.

\hypertarget{rugarch}{%
\subsection{rugarch}\label{rugarch}}

\emph{Rugarch} é um pacote que contêm uma grande variedade de modelos unívariados GARCH, com métodos para simulação, inferência e criar gráficos (\citet{rugarch}). Neste caso foi utilizada a função \emph{ugarchspec()} para utilizar o método eGARCH, que fornecia uma melhor resposta no modelo em análise do que utilizando o modelo generalista GARCH. Este modelo disponibiliza toda a informação estatística necessária para validar o modelo e seus pressupostos, sendo que comparativamente com o pacote fGarch, permite aplicação de outros modelos GARCG.

\hypertarget{tidyquant}{%
\subsection{Tidyquant}\label{tidyquant}}

O pacote \emph{Tidyquant} é uma colecção de outros pacotes financeiros, fornecendo deste modo de uma só vez vários pacotes utilizados para o sector financeiro e de gestão (\citet{tidyquant}). Temos o \emph{PerformanceAnalytics} sendo uma colecção de funções econométricas para performance e análise de risco (\citet{PerformanceAnalytics}). Uma das funções utilizadas foi a do \emph{VaR()}, permitindo definir o tipo de método a aplicar no cálculo do \emph{Value at Risk}. O \emph{quantmod} é uma \emph{framework} para modelos de finanças quantitativas, contendo funções para aceder a várias \emph{api} para obter dados de cotações, como no yahoo finance, assim como para o cálculo de retornos e visualização dos dados (\citet{quantmod}). O \emph{TTR} providencia uma colecção de mais de 50 indicadores técnicos para criar regras de \emph{trading} (\citet{TTR}). Outros pacotes, como o \emph{lubridate}, contêm funções para lidar com datas e tempos, o \emph{zoo} utilizado para series temporais regulares e irregulares e o pacote \emph{xts} para lidar com \emph{timestamps} em series temporais.

\hypertarget{aplicauxe7uxe3o-a-dados-do-modelo}{%
\chapter{Aplicação a dados do modelo}\label{aplicauxe7uxe3o-a-dados-do-modelo}}

\newpage

\hypertarget{introduuxe7uxe3o-1}{%
\section{Introdução}\label{introduuxe7uxe3o-1}}

A análise contempla, numa primeira fase, extrair 4 empresas constituintes do Euro Stoxx 50\footnote{\url{https://etf.invesco.com/pt/institutional/en/product/invesco-euro-stoxx-50-ucits-etf-acc/index-components}}, sendo que essa escolha foi realizado tendo em consideração a diversificação do portfolio por sector de actividade e por presença geográfica, possibilitando deste modo minimizar a correlação que possa existir, apostando em sectores considerados cíclicos e também em sectores defensivos, estando as empresas seleccionadas representados na figura \ref{fig:empresas}, onde podemos verificar o sector de actividade e a sua cotação no último dia considerado.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{image/cotacao} 

}

\caption{Empresas extraidas do Euro Stoxx 50}\label{fig:empresas}
\end{figure}
\FloatBarrier
\centering

Fonte: Elaboração própria.

\justifying
\bigskip

O intervalo temporal utilizado na obtenção dos dados foi de 01/06/2016 a 01/06/2020, contemplando 4
anos de dados históricos, tendo sido obtidos a partir do Yahoo.finance, perfazendo 1014 dias de negociação. De acordo com \citet{NG2006} ``\ldots recomenda-se usar 1000 amostras para a estimação do modelo GARCH convencional''. Ainda considerando \citet{smallsample} ``\ldots foi demonstrado que um nível elevado de persistência obtido em modelos GARCH(1,1) usando um número elevado de observações têm auto-correlação menor do que as estimações sugeridas com amostras pequenas''

Resumindo as várias etapas e de acordo com a figura \ref{fig:processo}, após a obtenção e tratamento dos dados é realizada uma análise descritiva dos mesmos, sendo depois estimada a volatilidade para o último dia de acordo com os modelos em estudo. O modelo de simulação integra esses valores obtidos de variância para cada um dos activos e de acordo com o modelo utilizado, sendo constituído um portfolio que minimize a variância com base em 80 dias de simulação de preços, sendo as restrições aplicáveis ao modelo a não possibilidade de posições curtas, investir em activos sem risco e empréstimo de capital.

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{image/modelação} 

}

\caption{Modelação do processo}\label{fig:processo}
\end{figure}
\FloatBarrier
\centering

Fonte: Elaboração própria.

\justifying

Ao longo do trabalho e sempre que se verifique necessário será disponibilizado no próprio conteúdo do trabalho o código R utilizado para tratamento e obtenção dos dados apresentados. As tabelas originadas que contemplam todo o \emph{output} de um determinado código serão colocadas em anexo.

\hypertarget{anuxe1lise-descritiva-dos-dados}{%
\section{Análise descritiva dos dados}\label{anuxe1lise-descritiva-dos-dados}}

Na tabela \ref{tab:sogtail} estão representados os valores para as acções da empresa Société Générale nos últimos 5 dias em análise, sendo os valores representativos do preço de fecho e do preço ajustado. O preço ajustado contempla a remuneração do acionista com dividendos a serem pagos ou pagos e também o ajuste a ocorrência de \emph{split} das acções. No calculo do retorno utiliza-se o preço ajustado.

\begin{table}[!h]

\caption{\label{tab:sogtail}Société Générale.Euronext Paris-25-05-2020/01-06-2020}
\centering
\begin{tabular}[t]{rr}
\toprule
Close & Adj Close\\
\midrule
12.544 & 10.344\\
13.424 & 13.424\\
14.304 & 14.304\\
13.916 & 13.916\\
13.232 & 13.232\\
\addlinespace
13.820 & 13.820\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:\url{https://finance.yahoo.com/}

\justifying
\bigskip

Na figura \ref{fig:cotacao} temos a evolução da cotação das acções das empresas nos últimos 4 anos, verificando-se no inicio do ano de 2020 uma queda abrupta nas cotações, devido as possíveis repercussões económicas negativas com o alastrar de infecções de COVID-19 a nível mundial, tendo originado nalgumas destas empresas quedas superiores a 50\% do seu valor.

\begin{figure}

{\centering \includegraphics[width=0.45\linewidth]{bookdown-demo_files/figure-latex/cotacao-1} \includegraphics[width=0.45\linewidth]{bookdown-demo_files/figure-latex/cotacao-2} \includegraphics[width=0.45\linewidth]{bookdown-demo_files/figure-latex/cotacao-3} \includegraphics[width=0.45\linewidth]{bookdown-demo_files/figure-latex/cotacao-4} 

}

\caption{Evolução das cotações nos últimos 5 anos}\label{fig:cotacao}
\end{figure}
\FloatBarrier
\centering

Fonte: Elaboração própria.

\justifying
\bigskip

Com a função \emph{summary} agrega-se na tabela \ref{tab:estcot} algumas estatísticas referentes a variação das cotações, apresentando os valores mínimos e máximos, assim como quartis e a média. Os valores referentes a média e mediana ilustram que existem empresas cuja distribuição dos valores apresentam uma cauda mais à direita(ENI), enquanto outras apresentam uma cauda mais a esquerda (GLE), de acordo com os dados dos últimos 4 anos.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#R CODE}
\NormalTok{pt \textless{}{-}}\KeywordTok{summary}\NormalTok{(}\KeywordTok{as.data.frame}\NormalTok{(newdata))}
\NormalTok{p \textless{}{-}}\StringTok{ }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
\NormalTok{  pt, }\DataTypeTok{caption =} \StringTok{"Estatísticas das cotações"}\NormalTok{,}
  \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{)}
\KeywordTok{kable\_styling}\NormalTok{(p, }\DataTypeTok{latex\_options =} \StringTok{"hold\_position"}\NormalTok{, }\DataTypeTok{position =} \StringTok{"center"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:estcot}Estatísticas das cotações}
\centering
\begin{tabular}[t]{lllll}
\toprule
  &     TEF.MC &    ENEL.MI &     GLE.PA &     AIR.PA\\
\midrule
 & Min.   :3.355 & Min.   :2.943 & Min.   : 9.702 & Min.   : 44.66\\
 & 1st Qu.:6.097 & 1st Qu.:3.891 & 1st Qu.:20.735 & 1st Qu.: 64.67\\
 & Median :6.456 & Median :4.331 & Median :25.922 & Median : 85.56\\
 & Mean   :6.375 & Mean   :4.624 & Mean   :25.603 & Mean   : 85.65\\
 & 3rd Qu.:6.792 & 3rd Qu.:5.267 & 3rd Qu.:31.364 & 3rd Qu.:108.01\\
\addlinespace
 & Max.   :8.089 & Max.   :8.229 & Max.   :35.649 & Max.   :134.60\\
\bottomrule
\end{tabular}
\end{table}
\normalsize
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

O cálculo dos retornos diários é efectuado com a função \emph{dailyreturn}, sendo aplicada a função dos retornos logarítmicos de acordo com a equação \eqref{eq:logRet}. No gráfico \ref{fig:volatilidade} estão representados os gráficos referentes aos retornos diários logarítmicos para cada uma das empresa.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#R CODE}
\NormalTok{returns \textless{}{-}}\StringTok{ }\KeywordTok{as.xts}\NormalTok{(}\KeywordTok{data.frame}\NormalTok{(}\KeywordTok{round}\NormalTok{(}\KeywordTok{dailyReturn}\NormalTok{(newdata}\OperatorTok{$}\NormalTok{TEF.MC,}\DataTypeTok{type=}\StringTok{"log"}\NormalTok{),}\DecValTok{4}\NormalTok{),}
                             \KeywordTok{round}\NormalTok{(}\KeywordTok{dailyReturn}\NormalTok{(newdata}\OperatorTok{$}\NormalTok{ENEL.MI,}\DataTypeTok{type=}\StringTok{"log"}\NormalTok{),}\DecValTok{4}\NormalTok{),}
                             \KeywordTok{round}\NormalTok{(}\KeywordTok{dailyReturn}\NormalTok{(newdata}\OperatorTok{$}\NormalTok{GLE.PA,}\DataTypeTok{type=}\StringTok{"log"}\NormalTok{),}\DecValTok{4}\NormalTok{),}
                             \KeywordTok{round}\NormalTok{(}\KeywordTok{dailyReturn}\NormalTok{(newdata}\OperatorTok{$}\NormalTok{AIR.PA,}\DataTypeTok{type=}\StringTok{"log"}\NormalTok{),}\DecValTok{4}\NormalTok{)))}
\NormalTok{returns \textless{}{-}}\StringTok{ }\NormalTok{returns[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{,]}
\KeywordTok{colnames}\NormalTok{(returns)\textless{}{-}}\KeywordTok{c}\NormalTok{(}\StringTok{"TEF.RET"}\NormalTok{,}\StringTok{"ENEL.RET"}\NormalTok{,}\StringTok{"GLE.RET"}\NormalTok{,}\StringTok{"AIR.RET"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\normalsize

\begin{figure}

{\centering \includegraphics[width=0.45\linewidth]{bookdown-demo_files/figure-latex/volatilidade-1} \includegraphics[width=0.45\linewidth]{bookdown-demo_files/figure-latex/volatilidade-2} \includegraphics[width=0.45\linewidth]{bookdown-demo_files/figure-latex/volatilidade-3} \includegraphics[width=0.45\linewidth]{bookdown-demo_files/figure-latex/volatilidade-4} 

}

\caption{Volatilidade nos últimos 4 anos}\label{fig:volatilidade}
\end{figure}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

Na matrix de correlações \ref{tab:correl} dos retornos podemos verificar que a correlação entre os vários activos financeiros pode ser considerada como apresentando uma correlação fraca ou moderada\footnote{De acordo com os valores apresentados em \url{https://pt.wikipedia.org/wiki/Coeficiente_de_correla\%C3\%A7\%C3\%A3o_de_Pearson} a 31/01/2021}.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#R CODE}
\NormalTok{retcor \textless{}{-}}\StringTok{ }\KeywordTok{cor}\NormalTok{(returns,}\DataTypeTok{method =} \StringTok{"pearson"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\normalsize

\begin{table}[!h]

\caption{\label{tab:correl}Matrix correlação dos retornos}
\centering
\begin{tabular}[t]{lrrrr}
\toprule
  & TEF.RET & ENEL.RET & GLE.RET & AIR.RET\\
\midrule
TEF.RET & 1.0000000 & 0.5792880 & 0.5416984 & 0.3144011\\
ENEL.RET & 0.5792880 & 1.0000000 & 0.4564904 & 0.3423647\\
GLE.RET & 0.5416984 & 0.4564904 & 1.0000000 & 0.5417957\\
AIR.RET & 0.3144011 & 0.3423647 & 0.5417957 & 1.0000000\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

A analise descritiva dos retornos é apresentada na tabela \ref{tab:statret}, sendo que todos apresentam uma assimetria negativa ou à esquerda, em que a cauda da distribuição nestes casos aponta para a esquerda. A curtose apresenta valores elevados e superiores a 3, sendo que as distribuições tem cauda mais pesadas do que a da distribuição normal. Neste caso as distribuições são ditas \emph{leptokurtic} sendo uma característica comum na distribuição dos retornos das acções.

As volatilidades apresentadas, assim como o retorno, são valores anuais e com peso igual atribuído a cada uma das observações.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#R CODE}
\NormalTok{retannual \textless{}{-}}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x) \{  }
  \KeywordTok{Return.annualized}\NormalTok{(x,}\DataTypeTok{geometric =} \OtherTok{FALSE}\NormalTok{)\}}
\NormalTok{retvol \textless{}{-}}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x) \{  }
  \KeywordTok{StdDev.annualized}\NormalTok{(x,}\DataTypeTok{geometric =} \OtherTok{FALSE}\NormalTok{)\}}

\NormalTok{ETFStats \textless{}{-}}\StringTok{ }\KeywordTok{do.call}\NormalTok{(data.frame, }
                    \KeywordTok{list}\NormalTok{(}\StringTok{"média anual"}\NormalTok{=}\StringTok{ }\KeywordTok{round}\NormalTok{(}\KeywordTok{apply}\NormalTok{(returns, }\DecValTok{2}\NormalTok{,retannual),}\DecValTok{6}\NormalTok{),}
                         \StringTok{"volatilidade anual"}\NormalTok{=}\StringTok{ }\KeywordTok{round}\NormalTok{(}\KeywordTok{apply}\NormalTok{(returns, }\DecValTok{2}\NormalTok{, retvol),}\DecValTok{6}\NormalTok{),}
                         \DataTypeTok{mediana =} \KeywordTok{round}\NormalTok{(}\KeywordTok{apply}\NormalTok{(returns, }\DecValTok{2}\NormalTok{, median),}\DecValTok{6}\NormalTok{),}
                         \DataTypeTok{skewness =} \KeywordTok{round}\NormalTok{(}\KeywordTok{apply}\NormalTok{(returns, }\DecValTok{2}\NormalTok{, skewness),}\DecValTok{6}\NormalTok{),}
                         \DataTypeTok{kurtosis =} \KeywordTok{round}\NormalTok{(}\KeywordTok{apply}\NormalTok{(returns, }\DecValTok{2}\NormalTok{, kurtosis),}\DecValTok{6}\NormalTok{),}
                         \DataTypeTok{min =} \KeywordTok{round}\NormalTok{(}\KeywordTok{apply}\NormalTok{(returns, }\DecValTok{2}\NormalTok{, min),}\DecValTok{6}\NormalTok{),}
                         \DataTypeTok{max =} \KeywordTok{round}\NormalTok{(}\KeywordTok{apply}\NormalTok{(returns, }\DecValTok{2}\NormalTok{, max),}\DecValTok{6}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\normalsize

\begin{table}[!h]

\caption{\label{tab:statret}Estatísticas dos retornos}
\centering
\begin{tabular}[t]{lrrrr}
\toprule
  & TEF.RET & ENEL.RET & GLE.RET & AIR.RET\\
\midrule
média.anual & -0.128565 & 0.186336 & -0.142061 & 0.035758\\
volatilidade.anual & 0.270075 & 0.249512 & 0.407981 & 0.381835\\
mediana & -0.000500 & 0.000900 & -0.000300 & 0.000200\\
skewness & -1.199014 & -3.212281 & -0.652772 & -1.084556\\
kurtosis & 27.848870 & 43.434065 & 25.410242 & 24.429017\\
\addlinespace
min & -0.175800 & -0.221200 & -0.230300 & -0.250600\\
max & 0.163800 & 0.072500 & 0.260600 & 0.186200\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

Na análise ao tipo de distribuição dos retornos estes não apresentam distribuição normal, sendo que os pressupostos subjacentes a normalidade dos dados não se verificam.

Nos histogramas (figura \ref{fig:distr}), a linha a azul representa uma distribuição normal (com média 0 e desvio padrão igual ao valor dos dados (retornos log)) de modo a comparar com o histograma, sendo que se verifica distribuição leptocúrticas nos retornos log dos vários índices, como verificado anteriormente.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{bookdown-demo_files/figure-latex/distr-1} 

}

\caption{Distribuição dos retornos}\label{fig:distr}
\end{figure}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying

Na figura \ref{fig:teste} ``qq plot'', verifica-se que nos extremos os dados não se agrupam ao redor da linha reta (negação da normalidade).

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{bookdown-demo_files/figure-latex/teste-1} 

}

\caption{Teste a normalidade das distribuições}\label{fig:teste}
\end{figure}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

Por fim, o teste Shapiro-Wilk (teste á normalidade) na tabela \ref{tab:shapiro} apresentam um valor de p\textless0.05 (considerando um nível significância a 95\%), sendo que se pode rejeitar a distribuição normal dos índices.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#R CODE}
\NormalTok{lshap\textless{}{-}}\StringTok{ }\KeywordTok{lapply}\NormalTok{(}\KeywordTok{as.data.frame}\NormalTok{(returns), shapiro.test)}
\NormalTok{lres \textless{}{-}}\StringTok{ }\KeywordTok{sapply}\NormalTok{(lshap, }\StringTok{"["}\NormalTok{, }\KeywordTok{c}\NormalTok{(}\StringTok{"statistic"}\NormalTok{,}\StringTok{"p.value"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\normalsize

\begin{table}[!h]

\caption{\label{tab:shapiro}Teste normalidade Shapiro-Wilk}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{lllll}
\toprule
  & TEF.RET & ENEL.RET & GLE.RET & AIR.RET\\
\midrule
statistic & c(W = 0.806556139172951) & c(W = 0.81527958050879) & c(W = 0.781822265470115) & c(W = 0.781772438450224)\\
p.value & 4.1518298262632e-33 & 1.62872401140161e-32 & 1.10625328031641e-34 & 1.09857623834578e-34\\
\bottomrule
\end{tabular}}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

\newpage

\hypertarget{ewma}{%
\section{EWMA}\label{ewma}}

O \emph{exponential weighted moving average} (EWMA) é calculado com um \emph{decay factor} \(\lambda\) de 0.94 e de acordo com a equação \eqref{eq:ewma2}. Para esse fim utiliza-se a função do R \emph{ewmaVol} sendo calculado todos os valores de desvio padrão deste o inicio da serie temporal.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#R CODE}
\NormalTok{ewma \textless{}{-}}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x) \{  }
\NormalTok{  x\textless{}{-}}\KeywordTok{ewmaVol}\NormalTok{(x,}\DataTypeTok{lambda =} \FloatTok{0.94}\NormalTok{)}
  \KeywordTok{return}\NormalTok{(}\KeywordTok{tail}\NormalTok{(x}\OperatorTok{$}\NormalTok{sigma,}\DecValTok{1}\NormalTok{))}
\NormalTok{\}}
\NormalTok{pewma \textless{}{-}}\StringTok{ }\KeywordTok{do.call}\NormalTok{(data.frame, }
                 \KeywordTok{list}\NormalTok{(}\StringTok{"ewma"}\NormalTok{=}\StringTok{ }\KeywordTok{round}\NormalTok{(}\KeywordTok{apply}\NormalTok{(returns,}\DecValTok{2}\NormalTok{,ewma),}\DecValTok{6}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\normalsize

Na figura \ref{fig:gewma} podemos ver como acompanha e responde o calculo do EWMA a alterações bruscas da volatilidade diária, verificando-se algum atraso nessa resposta, como esperado, tendo em consideração o próprio método em si e o facto da escolha de um \(\lambda\) de 0.94.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{bookdown-demo_files/figure-latex/gewma-1} 

}

\caption{EWMA}\label{fig:gewma}
\end{figure}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

Na tabela \ref{tab:ewmaval} temos os valores referentes ao desvio padrão calculado para o último dia de cotação, sendo esse o valor a ser utilizado na simulação.

\begin{table}[!h]

\caption{\label{tab:ewmaval}EWMA}
\centering
\begin{tabular}[t]{lrrrr}
\toprule
  & TEF.RET & ENEL.RET & GLE.RET & AIR.RET\\
\midrule
ewma & 0.034085 & 0.023709 & 0.075245 & 0.054579\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

\hypertarget{simulauxe7uxe3o-ewma}{%
\subsection{Simulação EWMA}\label{simulauxe7uxe3o-ewma}}

O procedimento para a simulação de Monte Carlo será o mesmo para todos os diferentes métodos de calculo de volatilidade, sendo que aqui apenas se apresenta o código R utilizado para a primeira simulação, sendo depois igual para todos as outras situações, onde apenas se altera o valor relativo ao desvio padrão.

A simulação será efectuada para um total de 80 dias de negociação, repetindo 1000 vezes. A equação utilizada para a simulação é a equação \eqref{eq:logprice}, em que \(\mu\) representa a taxa de juro sem risco referente a obrigações do tesouro alemão a 3 meses\footnote{Germany 3 Month Bond Yield Historical Data - \url{https://www.investing.com/rates-bonds/germany-3-month-bond-yield-historical-data}}, sendo este o prazo mais próximo do espaço temporal do investimento.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#R CODE}
\NormalTok{dfewma \textless{}{-}}\StringTok{ }\KeywordTok{as.data.frame}\NormalTok{(pewma)}

\NormalTok{N \textless{}{-}}\StringTok{ }\DecValTok{80}
\NormalTok{dia \textless{}{-}}\StringTok{ }\DecValTok{1}\OperatorTok{:}\NormalTok{N}
\NormalTok{M \textless{}{-}}\StringTok{ }\DecValTok{1000}
\NormalTok{mu \textless{}{-}}\StringTok{ }\FloatTok{{-}0.00575}

\NormalTok{TEF.preco\_inicial \textless{}{-}}\StringTok{ }\NormalTok{TEF.MC}\OperatorTok{$}\NormalTok{Close[[}\KeywordTok{nrow}\NormalTok{(TEF.MC}\OperatorTok{$}\NormalTok{Close)]]}
\NormalTok{TEF.MC.sigma \textless{}{-}}\StringTok{ }\NormalTok{dfewma}\OperatorTok{$}\NormalTok{TEF.RET}\OperatorTok{*}\KeywordTok{sqrt}\NormalTok{(}\DecValTok{252}\NormalTok{)}
\NormalTok{TEF.MC.mean \textless{}{-}}\StringTok{ }\NormalTok{(mu}\OperatorTok{{-}}\NormalTok{(TEF.MC.sigma}\OperatorTok{\^{}}\DecValTok{2}\NormalTok{)}\OperatorTok{/}\DecValTok{2}\NormalTok{)}\OperatorTok{*}\NormalTok{(}\DecValTok{1}\OperatorTok{/}\DecValTok{252}\NormalTok{)}

\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{monte\_carlo\_sim \textless{}{-}}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\DataTypeTok{nrow=}\NormalTok{N, }\DataTypeTok{ncol =}\NormalTok{ M)}
\ControlFlowTok{for}\NormalTok{(j }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{M)\{}
\NormalTok{  monte\_carlo\_sim[[}\DecValTok{1}\NormalTok{,j]] \textless{}{-}}\StringTok{ }\NormalTok{TEF.preco\_inicial}
  \ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{2}\OperatorTok{:}\NormalTok{N)\{}
\NormalTok{    monte\_carlo\_sim[[i,j]] \textless{}{-}}\StringTok{ }\NormalTok{monte\_carlo\_sim[[i}\DecValTok{{-}1}\NormalTok{,j]]}\OperatorTok{*}
\StringTok{      }\KeywordTok{exp}\NormalTok{(TEF.MC.mean}\OperatorTok{+}\NormalTok{TEF.MC.sigma }\OperatorTok{*}
\StringTok{            }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{)}\OperatorTok{*}\KeywordTok{sqrt}\NormalTok{(}\DecValTok{1}\OperatorTok{/}\DecValTok{252}\NormalTok{))}
\NormalTok{  \}}
\NormalTok{\}}
\NormalTok{TEF.MC\_MC\_sim \textless{}{-}}\StringTok{ }\KeywordTok{as\_tibble}\NormalTok{(}\KeywordTok{cbind}\NormalTok{(dia,monte\_carlo\_sim))}
\NormalTok{w \textless{}{-}}\StringTok{ }\KeywordTok{str\_c}\NormalTok{(}\StringTok{\textquotesingle{}Sim\textquotesingle{}}\NormalTok{,}\KeywordTok{seq}\NormalTok{(}\DecValTok{1}\NormalTok{,M))}
\NormalTok{w \textless{}{-}}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{\textquotesingle{}Dia\textquotesingle{}}\NormalTok{,w)}
\KeywordTok{names}\NormalTok{(TEF.MC\_MC\_sim) \textless{}{-}}\StringTok{ }\NormalTok{w}
\NormalTok{TEF.MC\_MC\_sim \textless{}{-}}\StringTok{ }\KeywordTok{gather}\NormalTok{(TEF.MC\_MC\_sim, }\DataTypeTok{key=}\StringTok{\textquotesingle{}Simulation\textquotesingle{}}\NormalTok{, }\DataTypeTok{value =} \StringTok{\textquotesingle{}Preço\textquotesingle{}}\NormalTok{,}\OperatorTok{{-}}\NormalTok{(Dia))}
\end{Highlighting}
\end{Shaded}

\normalsize

Na figura \ref{fig:sim} encontram-se as simulações efectuadas para cada uma das empresas.

\begin{figure}

{\centering \includegraphics[width=0.45\linewidth]{bookdown-demo_files/figure-latex/sim-1} \includegraphics[width=0.45\linewidth]{bookdown-demo_files/figure-latex/sim-2} \includegraphics[width=0.45\linewidth]{bookdown-demo_files/figure-latex/sim-3} \includegraphics[width=0.45\linewidth]{bookdown-demo_files/figure-latex/sim-4} 

}

\caption{Simulação Monte Carlo para 80 dias}\label{fig:sim}
\end{figure}

A partir dos valores simulados calcula-se a média para cada um dos dias de acordo com o código R abaixo, obtendo-se desta forma os dados ilustrados na tabela \ref{tab:simtabewma} referente aos últimos 5 dias.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#R CODE}
\NormalTok{M.TEF.MC \textless{}{-}}\StringTok{ }\KeywordTok{apply}\NormalTok{(monte\_carlo\_sim, }\DecValTok{1}\NormalTok{, mean)}
\NormalTok{M.ENEL.MI \textless{}{-}}\StringTok{ }\KeywordTok{apply}\NormalTok{(ENEL\_monte\_carlo\_sim, }\DecValTok{1}\NormalTok{,mean )}
\NormalTok{M.GLE.PA \textless{}{-}}\StringTok{ }\KeywordTok{apply}\NormalTok{(GLE\_monte\_carlo\_sim, }\DecValTok{1}\NormalTok{,mean )}
\NormalTok{M.AIR.PA \textless{}{-}}\StringTok{ }\KeywordTok{apply}\NormalTok{(AIR\_monte\_carlo\_sim, }\DecValTok{1}\NormalTok{,mean )}
\end{Highlighting}
\end{Shaded}

\normalsize

\begin{table}[!h]

\caption{\label{tab:simtabewma}EWMA - Valores simulados}
\centering
\begin{tabular}[t]{lrrrr}
\toprule
  & M.TEF.MC & M.ENEL.MI & M.GLE.PA & M.AIR.PA\\
\midrule
75 & 4.353636 & 7.061643 & 13.44873 & 58.97885\\
76 & 4.355204 & 7.067500 & 13.44746 & 58.85199\\
77 & 4.353707 & 7.062899 & 13.51566 & 58.91117\\
78 & 4.346170 & 7.061539 & 13.56391 & 58.75981\\
79 & 4.342754 & 7.062226 & 13.63570 & 58.73444\\
\addlinespace
80 & 4.354900 & 7.062980 & 13.64332 & 58.69858\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

\hypertarget{portfolio-ewma}{%
\subsection{Portfolio EWMA}\label{portfolio-ewma}}

Na definição do portfolio vamos utilizar os dados referentes às simulações realizadas, considerando que o objectivo é minimizar o risco, ou seja minimizar a variância. A função utilizada pelo R é \emph{minvariancePortfolio}, sendo desta forma definido os pesos de cada um dos activos que irão constituir o portfolio, apresentados na tabela \ref{tab:pewma}.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# R CODE}
\NormalTok{SimReturns \textless{}{-}}\StringTok{ }\KeywordTok{as.timeSeries}\NormalTok{(myPortfolioReturns)}
\NormalTok{FronteiraEff \textless{}{-}}\StringTok{ }\KeywordTok{portfolioFrontier}\NormalTok{(SimReturns, }\DataTypeTok{constraints =} \StringTok{"LongOnly"}\NormalTok{)}

\NormalTok{minvarewma \textless{}{-}}\StringTok{ }\KeywordTok{minvariancePortfolio}\NormalTok{(SimReturns) }
\NormalTok{minew\textless{}{-}}\KeywordTok{getPortfolio}\NormalTok{(minvarewma)}
\end{Highlighting}
\end{Shaded}

\normalsize

A figura \ref{fig:frontewma} representa o gráfico referente a fronteira eficiente para o portfolio de empresas em análise, sendo que o ponto a vermelho é onde se obtêm a mínima variância ou risco.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{bookdown-demo_files/figure-latex/frontewma-1} 

}

\caption{EWMA - Fronteira eficiente}\label{fig:frontewma}
\end{figure}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

Como se pode ver a empresa ENEL será a empresa com maior peso no portfolio com cerca de 55\%, seguida pela TELEFONICA com cerca de 25\%. As outras terão uma ponderação mais residual.

\begin{table}[!h]

\caption{\label{tab:pewma}EWMA - Pesos no portfolio}
\centering
\begin{tabular}[t]{lr}
\toprule
  & Pesos\\
\midrule
SimTEF & 0.2502928\\
SimENEL & 0.5540359\\
SimGLE & 0.1141192\\
SimAIR & 0.0815521\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

Definidos as ponderações de cada empresa no portfolio podemos calcula o VaR assim como as contribuições individuais de cada um dos activos, podendo-se verificar nos dados abaixo que a maior contribuição é dada pela ENEL, sendo natural, pois apresenta um grande peso no portfolio. No cálculo do VaR foi utilizado o VaR paramétrico com aproximação Cornish-Fisher, pois é mais representativo da realidade da distribuição dos retornos dos activos financeiros.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#R CODE}
\NormalTok{ewmaweights \textless{}{-}}\StringTok{ }\KeywordTok{c}\NormalTok{(}\FloatTok{0.2502928}\NormalTok{, }\FloatTok{0.5540359}\NormalTok{, }\FloatTok{0.1141192}\NormalTok{, }\FloatTok{0.0815521}\NormalTok{)}
\NormalTok{ModVaR\_}\DecValTok{95}\NormalTok{\_ewma \textless{}{-}}\StringTok{ }\KeywordTok{VaR}\NormalTok{(myPortfolioReturns, }\DataTypeTok{p=}\FloatTok{0.95}\NormalTok{,}\DataTypeTok{weights=}\NormalTok{ewmaweights, }
                      \DataTypeTok{portfolio\_method =} \StringTok{"component"}\NormalTok{, }\DataTypeTok{method =} \StringTok{"modified"}\NormalTok{)}
\NormalTok{ModVaR\_}\DecValTok{95}\NormalTok{\_ewma}\OperatorTok{$}\NormalTok{contribution }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       SimTEF      SimENEL       SimGLE       SimAIR 
## 2.442234e-04 4.595919e-04 1.285755e-04 7.912346e-05
\end{verbatim}

\normalsize

Analisando o valor calculado para a portfolio, pode-se verificar que para um nível de confiança 95\%, o VaR a 1 dia para dados simulados a 80 dias é de \ensuremath{9.12\times 10^{-4}}, ou seja, existe uma probabilidade de 5\% de ocorrer uma perda igual ou superior a este valor no montante total do portfolio investido.

\hypertarget{garch}{%
\section{GARCH}\label{garch}}

A aplicação do modelo GARCH para estimar a volatilidade será aplicado de acordo com a verificação dos pressupostos e da estimação dos parâmetros, sendo inicialmente utilizado o modelo genérico GARCH(1,1), e só caso não se verifique que o modelo responde adequadamente é que se tentará analisar a volatilidade com outros modelos, como o ARMA-GARCH e o EGARCH, optando pelo modelo que demonstre se adequar melhor aos dados. As tabelas relativas aos \emph{outputs} dos modelos encontram-se no apêndice I.

Nos modelos utilizados pelo pacotes rugarch e fGARCH o LM-ARCH teste é um teste \emph{portmanteau} ponderado onde se testa a hipótese nula do processo ARCH estar adequadamente ajustado, enquanto o teste Ljung-Box é outro \emph{portmanteau} teste que testa a hipótese nula da adequação do ajuste ARMA.

\hypertarget{telefuxf3nica}{%
\subsection{TELEFÓNICA}\label{telefuxf3nica}}

A aplicação do modelo é realizado com um modelo GARCH de primeira ordem, aplicando-se uma distribuição condicional dos retornos standardizados do tipo \emph{t de Student}, sendo que o teste Jarque-Bera e o Shapiro-Wilk rejeitam para um nível de significância de 5\% a normalidade dos dados, pois o valor \emph{p-value} é inferior ao nível de significância, rejeitando-se deste modo \(H_0\), ou seja, que os dados apresentam uma distribuição normal (ver Apêndice). A escolha deste tipo de distribuição prendem-se com o facto dos retornos apresentarem uma densidade do tipo \emph{leptokurtic}.(\citet{rvol})

A estimação do modelo GARCH(1,1) obteve uma boa resposta na modelação da volatilidade, sendo que todos os parâmetros do modelo, nomeadamente o \(\omega\), o \(\alpha\) e o \(\beta\) apresentam \emph{p-values} extremamente fortes, sendo significantes a um nível inferior a 5\%, evidenciando que o modelo com os parâmetros apresentados providenciam o melhor ajuste aos dados, como podemos ver na tabela \ref{tab:tefcoefgarch}.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#R CODE}
\NormalTok{TEF\textless{}{-}}\KeywordTok{garchFit}\NormalTok{(}\DataTypeTok{formula =} \OperatorTok{\textasciitilde{}}\StringTok{ }\KeywordTok{garch}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{),}\DataTypeTok{data=}\NormalTok{returns}\OperatorTok{$}\NormalTok{TEF.RET,}\DataTypeTok{cond.dist =} \StringTok{"std"}\NormalTok{,  }\DataTypeTok{include.mean=}\OtherTok{FALSE}\NormalTok{, }
              \DataTypeTok{trace=}\OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\normalsize

\begin{table}[!h]

\caption{\label{tab:tefcoefgarch}TEF coeficientes}
\centering
\begin{tabular}[t]{lrrrr}
\toprule
  &  Estimate &  Std. Error &  t value & Pr(>|t|)\\
\midrule
omega & 0.000009 & 0.000003 & 2.655911 & 0.007909\\
alpha1 & 0.095404 & 0.028264 & 3.375499 & 0.000737\\
beta1 & 0.860399 & 0.036000 & 23.900296 & 0.000000\\
shape & 4.873749 & 0.705695 & 6.906315 & 0.000000\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

o valor referente a persistência apresenta um valor de 0.9 sendo inferior a 1, apresentando deste modo uma regressão à média, ou seja que os valores referentes à volatilidade vão eventualmente regressar ao valores médios a longo prazo.

O modelo também disponibiliza os dados referentes aos critérios de informação estatísticos, como o critério de informação Akaike (AIC), sendo um modelo que estima a quantidade de informação perdida para um determinado modelo. Estes indicadores são adequados na comparação de vários modelos, sendo que quanto menor o valor deste indicador melhor o modelo. Neste caso este indicador foi utilizado sempre que se verificou que o modelo não apresentava uma boa resposta, comparando-se os vários modelos alternativos. A informação relativa a estes indicadores encontra-se no apêndice I.

O modelo também disponibiliza informação relativa aos resíduos estandardizados para verificação de auto-correlação. De acordo com (\citet{rvol}) " se a evidência sugerir auto-correlação nos resíduos estandardizados, então o modelo GARCH(1,1) não capturou toda a dinâmica da volatilidade dos retornos".

Na tabela \ref{tab:TEFLjunk} podemos verificar que as estatísticas para o teste Ljung-Box demonstram que o modelo integrou a volatilidade dos retornos, sendo que não se pode rejeitar a hipótese nula de que não existe auto-correlação entre os resíduos estandardizados, ou seja, as especificações são adequadas para capturar a auto-correlação e a variação da volatilidade no tempo nas series dos retornos.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#R CODE}
\NormalTok{TEFr \textless{}{-}}\KeywordTok{residuals}\NormalTok{(TEF, }\DataTypeTok{standardize =}\NormalTok{ T)}
\NormalTok{TEFres \textless{}{-}}\StringTok{ }\KeywordTok{as.data.frame}\NormalTok{(}\KeywordTok{LjungBox}\NormalTok{(TEFr, }\DataTypeTok{lags=}\KeywordTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{15}\NormalTok{,}\DecValTok{20}\NormalTok{), }\DataTypeTok{order=}\DecValTok{0}\NormalTok{, }\DataTypeTok{season=}\DecValTok{1}\NormalTok{, }\DataTypeTok{squared.residuals=}\OtherTok{FALSE}\NormalTok{))}
\NormalTok{TEFsre \textless{}{-}}\StringTok{ }\KeywordTok{as.data.frame}\NormalTok{(}\KeywordTok{LjungBox}\NormalTok{(TEFr}\OperatorTok{\^{}}\DecValTok{2}\NormalTok{, }\DataTypeTok{lags=}\KeywordTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{15}\NormalTok{,}\DecValTok{20}\NormalTok{), }\DataTypeTok{order=}\DecValTok{0}\NormalTok{, }\DataTypeTok{season=}\DecValTok{1}\NormalTok{, }\DataTypeTok{squared.residuals=}\OtherTok{FALSE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\normalsize

\begin{table}[!h]

\caption{\label{tab:TEFLjunk}Standardized Residuals Tests}
\centering
\begin{tabular}[t]{lrrr}
\toprule
  & lags & statistic & p-value\\
\midrule
Ljung-Box Test 10 & 10 & 5.291716 & 0.8708588\\
Ljung-Box Test 15 & 15 & 6.290389 & 0.9744462\\
Ljung-Box Test 20 & 20 & 8.960591 & 0.9833592\\
Ljung-Box Test 10 R\textasciicircum{}2 & 10 & 3.895552 & 0.9519358\\
Ljung-Box Test 15 R\textasciicircum{}2 & 15 & 4.523814 & 0.9954480\\
\addlinespace
Ljung-Box Test 20 R\textasciicircum{}2 & 20 & 5.476007 & 0.9994425\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

Na figura \ref{fig:TELplot} temos representados 4 gráficos, um com o desvio padrão estimado pelo modelo, outro com o ajuste da volatilidade estimada com um intervalo de confiança para 95\%, assim como o gráfico relativo à função de auto-correlação (ACF) para os resíduos estandardizados e os resíduos estandardizados ao quadrado, sendo que se verifica que a auto-correlação se encontra próximo de 0. De acordo com \citet{foregeorge}, ``Se um ou mais picos grandes estiverem fora desses limites, ou se substancialmente mais de 5\% dos picos estiverem fora desses limites, a série provavelmente não é \emph{white noise}''. Estes gráficos apenas vêm confirmar o que já tinha sido verificado com o teste Ljung-Box.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{bookdown-demo_files/figure-latex/TELplot-1} 

}

\caption{Telefónica}\label{fig:TELplot}
\end{figure}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

O valor de desvio padrão diário que vamos utilizar para efeitos de simulação, é o valor de 0.029292, sendo este o valor representativo da volatilidade condicional no último dia de cotação.

\hypertarget{enel}{%
\subsection{ENEL}\label{enel}}

A aplicação do modelo neste caso continua a ser realizado com um modelo GARCH de primeira ordem, aplicando-se uma distribuição condicional dos retornos standardizados do tipo \emph{t de Student}, sendo que o teste Jarque-Bera e o Shapiro-Wilk rejeitam para um nível de significância de 5\% a normalidade dos dados, pois o valor \emph{p-value} é inferior ao nível de significância, rejeitando-se deste modo \(H_0\), ou seja, que os dados apresentam uma distribuição normal (ver Apêndice).

A estimação do modelo GARCH(1,1) obteve uma boa resposta na modelação da volatilidade, sendo que todos os parâmetros do modelo, nomeadamente o \(\omega\), o \(\alpha\) e o \(\beta\) apresentam \emph{p-values} extremamente fortes, sendo significantes a um nível inferior a 5\%, evidenciando que o modelo com os parâmetros apresentados providenciam o melhor ajuste aos dados, como podemos ver na tabela \ref{tab:ENELcoef}.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#R CODE}
\NormalTok{ENEL\textless{}{-}}\KeywordTok{garchFit}\NormalTok{(}\DataTypeTok{formula =} \OperatorTok{\textasciitilde{}}\StringTok{ }\KeywordTok{garch}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{),}\DataTypeTok{data=}\NormalTok{returns}\OperatorTok{$}\NormalTok{ENEL.RET,}\DataTypeTok{cond.dist =} \StringTok{"std"}\NormalTok{, }\DataTypeTok{include.mean=}\OtherTok{FALSE}\NormalTok{, }
               \DataTypeTok{trace=}\OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\normalsize

\begin{table}[!h]

\caption{\label{tab:ENELcoef}ENEL coeficientes}
\centering
\begin{tabular}[t]{lrrrr}
\toprule
  &  Estimate &  Std. Error &  t value & Pr(>|t|)\\
\midrule
omega & 0.000015 & 0.000006 & 2.354472 & 0.018549\\
alpha1 & 0.094757 & 0.033815 & 2.802232 & 0.005075\\
beta1 & 0.827381 & 0.055900 & 14.801095 & 0.000000\\
shape & 4.496901 & 0.642043 & 7.004055 & 0.000000\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

o valor referente a persistência apresenta um valor de 0.9 sendo inferior a 1, apresentando deste modo uma regressão à média e um processo GARCH(1,1) estável.

Os dados referentes aos critérios de informação estatísticos, como o critério de informação Akaike (AIC), apresentam valores bastante baixos.

Na tabela \ref{tab:ENELLjunk} podemos verificar que as estatísticas para o teste Ljung-Box demonstram que o modelo integrou a volatilidade dos retornos, sendo que não se pode rejeitar a hipótese nula de que não existe auto-correlação entre os resíduos estandardizados, ou seja, as especificações são adequadas para capturar a auto-correlação e a variação da volatilidade no tempo nas series dos retornos.

\begin{table}[!h]

\caption{\label{tab:ENELLjunk}ENEL Standardized Residuals Tests}
\centering
\begin{tabular}[t]{lrrr}
\toprule
  & lags & statistic & p-value\\
\midrule
Ljung-Box Test 10 & 10 & 7.259108 & 0.7007780\\
Ljung-Box Test 15 & 15 & 10.814754 & 0.7656122\\
Ljung-Box Test 20 & 20 & 14.053311 & 0.8277827\\
Ljung-Box Test 10 R\textasciicircum{}2 & 10 & 16.609755 & 0.0834576\\
Ljung-Box Test 15 R\textasciicircum{}2 & 15 & 23.083781 & 0.0823772\\
\addlinespace
Ljung-Box Test 20 R\textasciicircum{}2 & 20 & 24.007764 & 0.2420532\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

Na figura \ref{fig:ENELplot} temos representados 4 gráficos, um com o desvio padrão estimado pelo modelo, outro com o ajuste da volatilidade estimada com um intervalo de confiança para 95\%, assim como o gráfico relativo à função de auto-correlação (ACF) para os resíduos estandardizados e os resíduos estandardizados ao quadrado, sendo que se verifica que a auto-correlação se encontra próximo de 0. Estes gráficos apenas vêm confirmar o que já tinha sido verificado com o teste Ljung-Box.

\justifying
\bigskip
\begin{figure}

{\centering \includegraphics[width=1\linewidth]{bookdown-demo_files/figure-latex/ENELplot-1} 

}

\caption{ENEL}\label{fig:ENELplot}
\end{figure}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

O valor de desvio padrão diário que vamos utilizar para efeitos de simulação, é o valor de 0.017321, sendo este o valor representativo da volatilidade condicional no último dia de cotação.

\hypertarget{sociuxe9tuxe9-guxe9nuxe9rale}{%
\subsection{SOCIÉTÉ GÉNÉRALE}\label{sociuxe9tuxe9-guxe9nuxe9rale}}

A aplicação do modelo neste caso contemplou também o modelo AR(1) de modo a que o modelo respondesse melhor a auto-correlação, sendo que ao utilizar apenas o modelo GARCH(1,1) o teste Ljung-Box rejeitava a hipótese nula de que as autocorrelações até lag k são iguais a zero, para um nível de significância de 5\%.

No modelo GARCH(1,1) continuou-se a aplicar uma distribuição condicional dos retornos standardizados do tipo \emph{t de Student}, sendo que o teste Jarque-Bera e o Shapiro-Wilk rejeitam para um nível de significância de 5\% a normalidade dos dados.

Ao realizar o ajuste do modelo GARCH(1,1) com o modelo AR(1) a estimação do modelo obteve uma boa resposta na modelação da volatilidade, sendo que todos os parâmetros do modelo, nomeadamente o \(\alpha\) e o \(\beta\) apresentam \emph{p-values} extremamente fortes, sendo significantes a um nível inferior a 5\%, evidenciando que o modelo com os parâmetros apresentados providenciam um bom ajuste aos dados, como podemos ver na tabela \ref{tab:EGLEcoefk}.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{GLE\textless{}{-}}\KeywordTok{garchFit}\NormalTok{(}\DataTypeTok{formula =} \OperatorTok{\textasciitilde{}}\StringTok{ }\KeywordTok{arma}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{) }\OperatorTok{+}\StringTok{ }\KeywordTok{garch}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{),}\DataTypeTok{data=}\NormalTok{returns}\OperatorTok{$}\NormalTok{GLE.RET,}\DataTypeTok{cond.dist =} \StringTok{"std"}\NormalTok{,}\DataTypeTok{include.mean=}\OtherTok{FALSE}\NormalTok{, }\DataTypeTok{trace=}\OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\normalsize

\begin{table}[!h]

\caption{\label{tab:GLEcoefk}GLE coeficientes}
\centering
\begin{tabular}[t]{lrrrr}
\toprule
  &  Estimate &  Std. Error &  t value & Pr(>|t|)\\
\midrule
ar1 & 0.105966 & 0.031112 & 3.405979 & 0.000659\\
omega & 0.000006 & 0.000003 & 2.031093 & 0.042246\\
alpha1 & 0.082746 & 0.023940 & 3.456358 & 0.000548\\
beta1 & 0.905877 & 0.025835 & 35.064369 & 0.000000\\
shape & 4.598190 & 0.641739 & 7.165205 & 0.000000\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

o valor referente a persistência apresenta um valor de 0.9 sendo inferior a 1, apresentando deste modo uma regressão à média e um processo GARCH(1,1) estável.

Os dados referentes aos critérios de informação estatísticos, como o critério de informação Akaike (AIC), foram analisados no comparativo com vários modelos, sendo que este modelo apresentava valores bastante baixos.

Na tabela \ref{tab:GLELjunk} podemos verificar que as estatísticas para o teste Ljung-Box demonstram que o modelo integrou a volatilidade dos retornos, sendo que não se pode rejeitar a hipótese nula de que não existe auto-correlação entre os resíduos estandardizados, ou seja, as especificações são adequadas para capturar a auto-correlação e a variação da volatilidade no tempo nas series dos retornos.

\begin{table}[!h]

\caption{\label{tab:GLELjunk}GLE Standardized Residuals Tests}
\centering
\begin{tabular}[t]{lrrr}
\toprule
  & lags & statistic & p-value\\
\midrule
Ljung-Box Test 10 & 10 & 5.825066 & 0.8297400\\
Ljung-Box Test 15 & 15 & 7.686251 & 0.9357445\\
Ljung-Box Test 20 & 20 & 14.408783 & 0.8091798\\
Ljung-Box Test 10 R\textasciicircum{}2 & 10 & 6.637454 & 0.7591706\\
Ljung-Box Test 15 R\textasciicircum{}2 & 15 & 8.022346 & 0.9228837\\
\addlinespace
Ljung-Box Test 20 R\textasciicircum{}2 & 20 & 8.300829 & 0.9896830\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

Do mesmo na figura @ref\{fig:GLEplot\} podemos visualizar o gráfico referente aos desvios padrão calculados pelo modelo, assim como a volatilidade para um intervalo de confiança a 95\%, verificando-se uma boa resposta por parte do modelo.

Os gráficos ACF vêm complementar a informação relativa aos teste Ljung-Box.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{bookdown-demo_files/figure-latex/GLEplot-1} 

}

\caption{SOCIÉTÉ GÉNÉRALE}\label{fig:GLEplot}
\end{figure}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

O valor de desvio padrão diário que vamos utilizar para efeitos de simulação, é o valor de 0.075983, sendo este o valor representativo da volatilidade condicional no último dia de cotação.

\hypertarget{airbus}{%
\subsection{AIRBUS}\label{airbus}}

O modelo aplicado aos retornos da empresa Airbus foi o EGARCH(2,2), conjuntamente com o ARIMA(1,1), sendo este que apresentava melhor reposta ao modelo ajustado. A tentativa de aplicação de outros modelos como o GARCH(1,1) não permitia extrair nenhum parâmetro do modelo que apresenta-se significância a um nível inferior a 5\%. Outros modelos com ordem de 1 falhavam no teste ARCH, embora no teste Ljung-Box apresentassem uma resposta razoável.

Assim, aceita-se o modelo ARIMA(1,1)-EGARCH(2,2), sendo que se conseguem extrair vários parâmetros significantes a um nível inferior a 5\%, de acordo com a tabela \citet{ref}(tab:AIRcoefk).

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#R CODE}
\NormalTok{AIR.spec \textless{}{-}}\StringTok{ }\KeywordTok{ugarchspec}\NormalTok{(}\DataTypeTok{variance.model=}\KeywordTok{list}\NormalTok{(}\DataTypeTok{model=}\StringTok{"eGARCH"}\NormalTok{,}\DataTypeTok{garchOrder=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{)),}
                           \DataTypeTok{mean.model=}\KeywordTok{list}\NormalTok{(}\DataTypeTok{armaOrder=}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{)),}\DataTypeTok{distribution.model=}\StringTok{"std"}\NormalTok{)}

\NormalTok{AIR \textless{}{-}}\StringTok{ }\KeywordTok{ugarchfit}\NormalTok{(AIR.spec, returns}\OperatorTok{$}\NormalTok{AIR.RET) }
\end{Highlighting}
\end{Shaded}

\normalsize

\begin{table}[!h]

\caption{\label{tab:AIRcoefk}AIR coeficientes}
\centering
\begin{tabular}[t]{lrrrr}
\toprule
  &  Estimate &  Std. Error &  t value & Pr(>|t|)\\
\midrule
mu & 0.000378 & 0.000256 & 1.478670 & 0.139229\\
ar1 & -0.690353 & 0.049772 & -13.870237 & 0.000000\\
ma1 & 0.713683 & 0.048171 & 14.815473 & 0.000000\\
omega & -0.420511 & 0.129163 & -3.255673 & 0.001131\\
alpha1 & -0.146353 & 0.028249 & -5.180744 & 0.000000\\
\addlinespace
alpha2 & -0.135647 & 0.029636 & -4.577144 & 0.000005\\
beta1 & 0.022517 & 0.015512 & 1.451604 & 0.146612\\
beta2 & 0.925715 & 0.009439 & 98.074257 & 0.000000\\
gamma1 & 0.054007 & 0.049166 & 1.098462 & 0.272003\\
gamma2 & 0.176758 & 0.052157 & 3.388992 & 0.000701\\
\addlinespace
shape & 5.904549 & 1.113789 & 5.301318 & 0.000000\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

o valor referente a persistência apresenta um valor de 0.9482316 sendo inferior a 1, apresentando deste modo uma regressão à média e um processo estável.

Os dados referentes aos critérios de informação estatísticos, como o critério de informação Akaike (AIC), foram analisados no comparativo com vários modelos, sendo que este modelo apresentava valores bastante baixos.

Na tabela \ref{tab:AIRLjunk} podemos verificar que as estatísticas para o teste Ljung-Box demonstram que o modelo integrou a volatilidade dos retornos. No apêndice I, na tabela referente ao \emph{output} do modelo o teste referente ao LM-ARCH também podemos confirmar que os resíduos estandardizados se comportam como um \emph{white noise}, não se podendo rejeitar a hipótese nula visto não haver evidência de auto-correlação.

\begin{table}[!h]

\caption{\label{tab:AIRLjunk}AIR Standardized Residuals Tests}
\centering
\begin{tabular}[t]{lrrr}
\toprule
  & lags & statistic & p-value\\
\midrule
Ljung-Box Test 10 & 10 & 3.180686 & 0.9768463\\
Ljung-Box Test 15 & 15 & 7.325160 & 0.9479907\\
Ljung-Box Test 20 & 20 & 10.701992 & 0.9535876\\
Ljung-Box Test 10 R\textasciicircum{}2 & 10 & 9.914234 & 0.4480498\\
Ljung-Box Test 15 R\textasciicircum{}2 & 15 & 12.112217 & 0.6705160\\
\addlinespace
Ljung-Box Test 20 R\textasciicircum{}2 & 20 & 14.427566 & 0.8081728\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

Na figura @ref\{fig:AIRplot\} podemos visualizar o gráfico referente aos desvios padrão calculados pelo modelo, assim como a volatilidade para um intervalo de confiança a 95\%, verificando-se uma boa resposta por parte do modelo.

Os gráficos ACF vêm complementar a informação relativa aos teste Ljung-Box.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{bookdown-demo_files/figure-latex/AIRplot-1} 

}

\caption{AIRBUS}\label{fig:AIRplot}
\end{figure}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

O valor de desvio padrão diário que vamos utilizar para efeitos de simulação, é o valor de 0.038301, sendo este o valor representativo da volatilidade condicional no último dia de cotação.

\hypertarget{simulauxe7uxe3o-garch}{%
\subsection{Simulação GARCH}\label{simulauxe7uxe3o-garch}}

A simulação será efectuada tendo em consideração os mesmos parâmetros utilizados pelo modelo EWMA, excepto para os valores calculados para o desvio padrão no último dia de cotação, sendo esses valores integrados no modelo.

Na figura \ref{fig:simgarch} temos a simulação efectuada 1000 vezes ao logo de 80 dias para as 4 empresas em análise.

\begin{figure}

{\centering \includegraphics[width=0.45\linewidth]{bookdown-demo_files/figure-latex/simgarch-1} \includegraphics[width=0.45\linewidth]{bookdown-demo_files/figure-latex/simgarch-2} \includegraphics[width=0.45\linewidth]{bookdown-demo_files/figure-latex/simgarch-3} \includegraphics[width=0.45\linewidth]{bookdown-demo_files/figure-latex/simgarch-4} 

}

\caption{Simulação Monte Carlo para 80 dias}\label{fig:simgarch}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{M.TEF.MC \textless{}{-}}\StringTok{ }\KeywordTok{apply}\NormalTok{(monte\_carlo\_sim, }\DecValTok{1}\NormalTok{, mean)}
\NormalTok{M.ENEL.MI \textless{}{-}}\StringTok{ }\KeywordTok{apply}\NormalTok{(ENEL\_monte\_carlo\_sim, }\DecValTok{1}\NormalTok{,mean )}
\NormalTok{M.GLE.PA \textless{}{-}}\StringTok{ }\KeywordTok{apply}\NormalTok{(GLE\_monte\_carlo\_sim, }\DecValTok{1}\NormalTok{,mean )}
\NormalTok{M.AIR.PA \textless{}{-}}\StringTok{ }\KeywordTok{apply}\NormalTok{(AIR\_monte\_carlo\_sim, }\DecValTok{1}\NormalTok{,mean )}
\end{Highlighting}
\end{Shaded}

A partir dos valores simulados calcula-se a média para cada um dos dias obtendo-se desta forma os dados ilustrados na tabela \ref{tab:simtabgarch} referente aos últimos 5 dias.

\begin{table}[!h]

\caption{\label{tab:simtabgarch}GARCH - Valores simulados}
\centering
\begin{tabular}[t]{lrrrr}
\toprule
  & M.TEF.MC & M.ENEL.MI & M.GLE.PA & M.AIR.PA\\
\midrule
75 & 4.317329 & 6.961774 & 13.66742 & 60.00317\\
76 & 4.323265 & 6.963564 & 13.69637 & 59.93394\\
77 & 4.328658 & 6.958801 & 13.74526 & 60.06126\\
78 & 4.323505 & 6.958524 & 13.74061 & 60.09178\\
79 & 4.324685 & 6.956716 & 13.81597 & 60.17193\\
\addlinespace
80 & 4.319977 & 6.960680 & 13.80472 & 60.18599\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

\hypertarget{portfolio-garch}{%
\subsection{Portfolio GARCH}\label{portfolio-garch}}

Da mesma forma que realizado aquando da definição do portfólio para o modelo EWMA, vamos utilizar os dados referentes às simulações realizadas, aplicando a mesma função R, com o objectivo de apresentar o portfolio que minimize a variância total. Os valores apurados pra os pesos de cada um dos activos que irão integrar o portfolio encontram-se na tabela \ref{tab:pgarchw}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SimReturnsG \textless{}{-}}\StringTok{ }\KeywordTok{as.timeSeries}\NormalTok{(myPortfolioReturns)}
\CommentTok{\#returns the portfolio with the minimal risk on the efficient frontier}

\NormalTok{minvarGARCH \textless{}{-}}\StringTok{ }\KeywordTok{minvariancePortfolio}\NormalTok{(SimReturnsG) }
\NormalTok{minew\textless{}{-}}\KeywordTok{getPortfolio}\NormalTok{(minvarGARCH)}
\end{Highlighting}
\end{Shaded}

A fronteira eficiente está representada na figura \ref{fig:frontgarch} sendo que o ponto a vermelho é onde se obtêm a mínima variância ou risco.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{bookdown-demo_files/figure-latex/frontgarch-1} 

}

\caption{GARCH - Fronteira eficiente}\label{fig:frontgarch}
\end{figure}

Neste modelo a empresa que apresenta maior peso continua a ser a ENEL com cerca de 61\%, sendo que a Société Générale não é integrada no portfólio.

\begin{table}[!h]

\caption{\label{tab:pgarchw}GARCH - Pesos no portfolio}
\centering
\begin{tabular}[t]{lr}
\toprule
  & Pesos\\
\midrule
SimTEF & 0.2136498\\
SimENEL & 0.6196197\\
SimGLE & 0.0000000\\
SimAIR & 0.1667305\\
\bottomrule
\end{tabular}
\end{table}

Definidos as ponderações de cada empresa no portfolio podemos calcula o VaR assim como as contribuições individuais de cada um dos activos, podendo-se verificar nos dados abaixo que a maior contribuição continua a pertencer a empresa ENEL. O calculo do VaR foi efectuado considerando a aproximação Cornish-Fisher.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{garchweights \textless{}{-}}\StringTok{ }\KeywordTok{c}\NormalTok{(}\FloatTok{0.2136498}\NormalTok{, }\FloatTok{0.6196197}\NormalTok{, }\DecValTok{0}\NormalTok{, }\FloatTok{0.1667305}\NormalTok{)}
\NormalTok{ModVaR\_}\DecValTok{95}\NormalTok{\_GARCH \textless{}{-}}\StringTok{ }\KeywordTok{VaR}\NormalTok{(myPortfolioReturns, }\DataTypeTok{p=}\FloatTok{0.95}\NormalTok{,}\DataTypeTok{weights=}\NormalTok{garchweights, }\DataTypeTok{portfolio\_method =} \StringTok{"component"}\NormalTok{, }\DataTypeTok{method =} \StringTok{"modified"}\NormalTok{)}
\NormalTok{ModVaR\_}\DecValTok{95}\NormalTok{\_GARCH}\OperatorTok{$}\NormalTok{contribution }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       SimTEF      SimENEL       SimGLE       SimAIR 
## 0.0001772924 0.0004493635 0.0000000000 0.0000754417
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{MVaRGARCH\_VaR \textless{}{-}}\StringTok{ }\KeywordTok{round}\NormalTok{(ModVaR\_}\DecValTok{95}\NormalTok{\_GARCH}\OperatorTok{$}\NormalTok{MVaR,}\DecValTok{6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Para um nível de confiança 95\%, o VaR a 1 dia para dados simulados a 80 dias é de \ensuremath{7.02\times 10^{-4}}, ou seja, existe uma probabilidade de 5\% de ocorrer uma perda igual ou superior a este valor no montante total do portfolio investido.

\hypertarget{volatilidade-implicita}{%
\section{Volatilidade implicita}\label{volatilidade-implicita}}

A volatilidade implícita é calculada de acordo com o modelo de Black-Scholes para opções europeias, sendo que o cálculo foi efectuado utilizando os valores presentes na tabela @ref\{tab:opcao\}. Os valores apresentados referem-se ao valor de opções de compra, \emph{call}\footnote{\url{https://www.eurexchange.com/exchange-en/products/equ/opt}}, para \emph{strike price} próximos ou iguais aos valores das acções, ou seja, \emph{at-the-money}. A data de vencimento das opções, ou maturidade, é a 18/09/2020.

No calculo da volatilidade implícita através da função R \emph{EuropeanOptionImpliedVolatility()} utilizou-se a mesma taxa de juro sem risco que anteriormente, tendo que ser incluído o valor percentual referente ao dividendo pago no periodo de tempo em análise, sempre que as empresas o disponibilizaram aos acionistas.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{image/opcao} 

}

\caption{Opções call sobre as empresas }\label{fig:opcao}
\end{figure}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#R CODE}
\NormalTok{TEFImp \textless{}{-}}\StringTok{ }\KeywordTok{EuropeanOptionImpliedVolatility}\NormalTok{(}\DataTypeTok{type=}\StringTok{"call"}\NormalTok{, }\DataTypeTok{value =} \FloatTok{0.27}\NormalTok{, }\DataTypeTok{underlying =} \FloatTok{4.40}\NormalTok{, }\DataTypeTok{strike =} \FloatTok{4.40}\NormalTok{,}
                                          \DataTypeTok{dividendYield =} \FloatTok{0.0407}\NormalTok{, }\DataTypeTok{riskFreeRate =} \FloatTok{{-}0.575}\NormalTok{, }
                                          \DataTypeTok{maturity =} \FloatTok{0.31746}\NormalTok{, }\DataTypeTok{volatility =} \FloatTok{0.1}\NormalTok{)}
\NormalTok{ENELImp \textless{}{-}}\StringTok{ }\KeywordTok{EuropeanOptionImpliedVolatility}\NormalTok{(}\DataTypeTok{type=}\StringTok{"call"}\NormalTok{, }\DataTypeTok{value =} \FloatTok{0.26}\NormalTok{, }\DataTypeTok{underlying =} \DecValTok{7}\NormalTok{, }\DataTypeTok{strike =} \FloatTok{7.2}\NormalTok{,}
                                           \DataTypeTok{dividendYield =} \FloatTok{0.012}\NormalTok{, }\DataTypeTok{riskFreeRate =} \FloatTok{{-}0.575}\NormalTok{,}
                                           \DataTypeTok{maturity =} \FloatTok{0.31746}\NormalTok{, }\DataTypeTok{volatility =} \FloatTok{0.1}\NormalTok{)}
\NormalTok{SOGImp \textless{}{-}}\StringTok{ }\KeywordTok{EuropeanOptionImpliedVolatility}\NormalTok{(}\DataTypeTok{type=}\StringTok{"call"}\NormalTok{, }\DataTypeTok{value =} \FloatTok{1.62}\NormalTok{, }\DataTypeTok{underlying =} \FloatTok{13.82}\NormalTok{, }\DataTypeTok{strike =} \DecValTok{14}\NormalTok{,}
                                          \DataTypeTok{dividendYield =} \DecValTok{0}\NormalTok{, }\DataTypeTok{riskFreeRate =} \FloatTok{{-}0.575}\NormalTok{, }\DataTypeTok{maturity =} \FloatTok{0.31746}\NormalTok{, }
                                          \DataTypeTok{volatility =} \FloatTok{0.1}\NormalTok{)}
\NormalTok{AIRImp \textless{}{-}}\StringTok{ }\KeywordTok{EuropeanOptionImpliedVolatility}\NormalTok{(}\DataTypeTok{type=}\StringTok{"call"}\NormalTok{, }\DataTypeTok{value =} \FloatTok{6.91}\NormalTok{, }\DataTypeTok{underlying =} \FloatTok{59.44}\NormalTok{, }
                                          \DataTypeTok{strike =} \DecValTok{60}\NormalTok{,}\DataTypeTok{dividendYield =} \DecValTok{0}\NormalTok{, }\DataTypeTok{riskFreeRate =} \FloatTok{{-}0.575}\NormalTok{, }
                                          \DataTypeTok{maturity =} \FloatTok{0.31746}\NormalTok{, }\DataTypeTok{volatility =} \FloatTok{0.1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\normalsize

Na tabela \ref{tab:tablevi} podemos ver os valores calculados para a volatilidade que permitem igualar os valores para as cotações das opções no dia 01/06/2020.

\begin{table}[!h]

\caption{\label{tab:tablevi}Volatilidade Implícita}
\centering
\begin{tabular}[t]{lrrrr}
\toprule
  & TEF.RET & ENEL.RET & GLE.RET & AIR.RET\\
\midrule
Volatilidade implícita & 0.037038 & 0.030534 & 0.053162 & 0.052567\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

\hypertarget{simulauxe7uxe3o-volatilidade-implicita}{%
\subsection{Simulação Volatilidade implicita}\label{simulauxe7uxe3o-volatilidade-implicita}}

Simulação na figura @ref\{fig:simvi\} para os 80 dias de cotação, utilizando os valores referentes a volatilidade implícita.

\begin{figure}

{\centering \includegraphics[width=0.45\linewidth]{bookdown-demo_files/figure-latex/simvi-1} \includegraphics[width=0.45\linewidth]{bookdown-demo_files/figure-latex/simvi-2} \includegraphics[width=0.45\linewidth]{bookdown-demo_files/figure-latex/simvi-3} \includegraphics[width=0.45\linewidth]{bookdown-demo_files/figure-latex/simvi-4} 

}

\caption{Simulação Monte Carlo para 80 dias}\label{fig:simvi}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{M.TEF.MC \textless{}{-}}\StringTok{ }\KeywordTok{apply}\NormalTok{(monte\_carlo\_sim, }\DecValTok{1}\NormalTok{, mean)}
\NormalTok{M.ENEL.MI \textless{}{-}}\StringTok{ }\KeywordTok{apply}\NormalTok{(ENEL\_monte\_carlo\_sim, }\DecValTok{1}\NormalTok{,mean )}
\NormalTok{M.GLE.PA \textless{}{-}}\StringTok{ }\KeywordTok{apply}\NormalTok{(GLE\_monte\_carlo\_sim, }\DecValTok{1}\NormalTok{,mean )}
\NormalTok{M.AIR.PA \textless{}{-}}\StringTok{ }\KeywordTok{apply}\NormalTok{(AIR\_monte\_carlo\_sim, }\DecValTok{1}\NormalTok{,mean )}
\end{Highlighting}
\end{Shaded}

Da mesma forma que nos outros modelos, calcula-se a média referente aos valores simulados para cada uma das empresas, estando os últimos 5 valores de cada uma representadas na tabela @ref\{tab:SimVIk\}.

\begin{table}[!h]

\caption{\label{tab:SimVIk}Vol. Implicita - Valores simulados}
\centering
\begin{tabular}[t]{lrrrr}
\toprule
  & M.TEF.MC & M.ENEL.MI & M.GLE.PA & M.AIR.PA\\
\midrule
75 & 4.412571 & 6.836974 & 13.80279 & 59.90791\\
76 & 4.407512 & 6.822441 & 13.83433 & 59.86369\\
77 & 4.412001 & 6.843420 & 13.88527 & 59.97287\\
78 & 4.423491 & 6.848677 & 13.90446 & 59.87972\\
79 & 4.420402 & 6.857666 & 13.88917 & 59.93295\\
\addlinespace
80 & 4.425597 & 6.842198 & 13.89540 & 60.00853\\
\bottomrule
\end{tabular}
\end{table}
\FloatBarrier
\centering

Fonte:Elaboração própria.

\justifying
\bigskip

\hypertarget{portfolio-volatilidade-uxedmplicita}{%
\subsection{Portfolio volatilidade ímplicita}\label{portfolio-volatilidade-uxedmplicita}}

A definição do portfólio de acordo com o método da mínima variância encontra-se definido na tabela @ref\{tab:minVIk\}, sendo que a figura @ref\{fig:frontVI\} representa a fronteira eficiente para esse mesmo modelo.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{bookdown-demo_files/figure-latex/frontVI-1} 

}

\caption{Volatilidade Implícita - Fronteira eficiente}\label{fig:frontVI}
\end{figure}

Como podemos ver neste modelo, a empresa ENEL é a que continua a ter mais peso no portfolio com cerca de 40\%, não tendo no entanto tanto peso como nos outros modelos, sendo que a empresa telefónica representa cerca de 32\%, sendo o restante repartido pelas outras 2 empresas.

\begin{table}[!h]

\caption{\label{tab:minVIk}Vol Implicita- Pesos no portfolio}
\centering
\begin{tabular}[t]{lr}
\toprule
  & Pesos\\
\midrule
SimTEF & 0.3278427\\
SimENEL & 0.4001305\\
SimGLE & 0.1278029\\
SimAIR & 0.1442238\\
\bottomrule
\end{tabular}
\end{table}

\begin{verbatim}
##       SimTEF      SimENEL       SimGLE       SimAIR 
## 0.0004108999 0.0005071254 0.0001274677 0.0001702760
\end{verbatim}

No cálculo do VaR foi utilizado o VaR paramétrico com aproximação Cornish-Fisher, pois é mais representativo da realidade da distribuição dos retornos dos activos financeiros, sendo que para um nível de confiança 95\%, o VaR a 1 dia para dados simulados a 80 dias é de 0.001216, ou seja, existe uma probabilidade de 5\% de ocorrer uma perda igual ou superior a este valor no montante total do portfolio investido.

\hypertarget{apresentauxe7uxe3o-dos-resultados}{%
\chapter{Apresentação dos resultados}\label{apresentauxe7uxe3o-dos-resultados}}

\endgroup
\newpage

\hypertarget{apresentauxe7uxe3o-dos-resultados-1}{%
\section{Apresentação dos resultados}\label{apresentauxe7uxe3o-dos-resultados-1}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{TEF.MC.R \textless{}{-}}\KeywordTok{read\_xlsx}\NormalTok{ (}\StringTok{"data/TEF.MC.R.xlsx"}\NormalTok{)}
\NormalTok{TEF.MC.R \textless{}{-}}\StringTok{ }\KeywordTok{xts}\NormalTok{(TEF.MC.R[, }\DecValTok{{-}1}\NormalTok{], }\DataTypeTok{order.by=}\KeywordTok{as.Date}\NormalTok{(TEF.MC.R}\OperatorTok{$}\NormalTok{Date))}
\NormalTok{GLE.PA.R \textless{}{-}}\KeywordTok{read\_xlsx}\NormalTok{ (}\StringTok{"data/GLE.PA.R.xlsx"}\NormalTok{)}
\NormalTok{GLE.PA.R \textless{}{-}}\StringTok{ }\KeywordTok{xts}\NormalTok{(GLE.PA.R[, }\DecValTok{{-}1}\NormalTok{], }\DataTypeTok{order.by=}\KeywordTok{as.Date}\NormalTok{(GLE.PA.R}\OperatorTok{$}\NormalTok{Date))}
\NormalTok{ENEL.MI.R \textless{}{-}}\KeywordTok{read\_xlsx}\NormalTok{ (}\StringTok{"data/ENEL.MI.R.xlsx"}\NormalTok{)}
\NormalTok{ENEL.MI.R \textless{}{-}}\StringTok{ }\KeywordTok{xts}\NormalTok{(ENEL.MI.R[, }\DecValTok{{-}1}\NormalTok{], }\DataTypeTok{order.by=}\KeywordTok{as.Date}\NormalTok{(ENEL.MI.R}\OperatorTok{$}\NormalTok{Date))}
\NormalTok{AIR.PA.R \textless{}{-}}\KeywordTok{read\_xlsx}\NormalTok{ (}\StringTok{"data/AIR.PA.R.xlsx"}\NormalTok{)}
\NormalTok{AIR.PA.R \textless{}{-}}\StringTok{ }\KeywordTok{xts}\NormalTok{(AIR.PA.R[, }\DecValTok{{-}1}\NormalTok{], }\DataTypeTok{order.by=}\KeywordTok{as.Date}\NormalTok{(AIR.PA.R}\OperatorTok{$}\NormalTok{Date))}

\NormalTok{myPortfolioR \textless{}{-}}\KeywordTok{na.omit}\NormalTok{(}\KeywordTok{merge}\NormalTok{(TEF.MC.R}\OperatorTok{$}\StringTok{\textasciigrave{}}\DataTypeTok{Adj Close}\StringTok{\textasciigrave{}}\NormalTok{,ENEL.MI.R}\OperatorTok{$}\StringTok{\textasciigrave{}}\DataTypeTok{Adj Close}\StringTok{\textasciigrave{}}\NormalTok{,GLE.PA.R}\OperatorTok{$}\StringTok{\textasciigrave{}}\DataTypeTok{Adj Close}\StringTok{\textasciigrave{}}\NormalTok{,}
\NormalTok{                             AIR.PA.R}\OperatorTok{$}\StringTok{\textasciigrave{}}\DataTypeTok{Adj Close}\StringTok{\textasciigrave{}}\NormalTok{))}

\NormalTok{myPortfolioReturnsR \textless{}{-}}\StringTok{ }\KeywordTok{ROC}\NormalTok{(myPortfolioR,}\DataTypeTok{type=}\StringTok{"discrete"}\NormalTok{)[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{,]}
\KeywordTok{colnames}\NormalTok{(myPortfolioReturnsR) \textless{}{-}}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"RealTEF"}\NormalTok{,}\StringTok{"RealENEL"}\NormalTok{,}\StringTok{"RealGLE"}\NormalTok{,}\StringTok{"RealAIR"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SimReturnsRvi \textless{}{-}}\StringTok{ }\KeywordTok{as.timeSeries}\NormalTok{(myPortfolioReturnsR)}
\NormalTok{equalweightsvi \textless{}{-}}\StringTok{ }\KeywordTok{Return.portfolio}\NormalTok{(SimReturnsRvi,}\DataTypeTok{weights =} \KeywordTok{c}\NormalTok{(}\FloatTok{0.3278427}\NormalTok{, }\FloatTok{0.4001305}\NormalTok{, }\FloatTok{0.1278029}\NormalTok{, }\FloatTok{0.1442238}\NormalTok{)) }
\KeywordTok{stdev}\NormalTok{(equalweightsvi}\OperatorTok{$}\NormalTok{portfolio.returns)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.0189834
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{optweightsvi \textless{}{-}}\StringTok{ }\KeywordTok{c}\NormalTok{(}\FloatTok{0.3278427}\NormalTok{, }\FloatTok{0.4001305}\NormalTok{, }\FloatTok{0.1278029}\NormalTok{, }\FloatTok{0.1442238}\NormalTok{)}
\NormalTok{ModVaR\_}\DecValTok{95}\NormalTok{\_vi \textless{}{-}}\StringTok{ }\KeywordTok{VaR}\NormalTok{(myPortfolioReturnsR, }\DataTypeTok{p=}\FloatTok{0.95}\NormalTok{,}\DataTypeTok{weights=}\NormalTok{optweightsvi, }\DataTypeTok{portfolio\_method =} \StringTok{"component"}\NormalTok{, }\DataTypeTok{method =} \StringTok{"modified"}\NormalTok{)}
\NormalTok{ModVaR\_}\DecValTok{95}\NormalTok{\_vi}\OperatorTok{$}\NormalTok{MVaR}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.02994267
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SimReturnsRgarch \textless{}{-}}\StringTok{ }\KeywordTok{as.timeSeries}\NormalTok{(myPortfolioReturnsR)}
\NormalTok{equalweightsgarch \textless{}{-}}\StringTok{ }\KeywordTok{Return.portfolio}\NormalTok{(SimReturnsRgarch,}\DataTypeTok{weights =} \KeywordTok{c}\NormalTok{(}\FloatTok{0.2136498}\NormalTok{, }\FloatTok{0.6196197}\NormalTok{, }\DecValTok{0}\NormalTok{, }\FloatTok{0.1667305}\NormalTok{)) }
\KeywordTok{stdev}\NormalTok{(equalweightsgarch}\OperatorTok{$}\NormalTok{portfolio.returns)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.01704112
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{optweightsgarch \textless{}{-}}\StringTok{ }\KeywordTok{c}\NormalTok{(}\FloatTok{0.2136498}\NormalTok{, }\FloatTok{0.6196197}\NormalTok{, }\DecValTok{0}\NormalTok{, }\FloatTok{0.1667305}\NormalTok{)}
\NormalTok{ModVaR\_}\DecValTok{95}\NormalTok{\_garch \textless{}{-}}\StringTok{ }\KeywordTok{VaR}\NormalTok{(myPortfolioReturnsR, }\DataTypeTok{p=}\FloatTok{0.95}\NormalTok{,}\DataTypeTok{weights=}\NormalTok{optweightsgarch, }\DataTypeTok{portfolio\_method =} \StringTok{"component"}\NormalTok{, }\DataTypeTok{method =} \StringTok{"modified"}\NormalTok{)}
\NormalTok{ModVaR\_}\DecValTok{95}\NormalTok{\_garch}\OperatorTok{$}\NormalTok{MVaR}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.02593275
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SimReturnsRewma \textless{}{-}}\StringTok{ }\KeywordTok{as.timeSeries}\NormalTok{(myPortfolioReturnsR)}
\NormalTok{equalweightsewma \textless{}{-}}\StringTok{ }\KeywordTok{Return.portfolio}\NormalTok{(SimReturnsRewma,}\DataTypeTok{weights =} \KeywordTok{c}\NormalTok{(}\FloatTok{0.2502928}\NormalTok{, }\FloatTok{0.5540359}\NormalTok{, }\FloatTok{0.1141192}\NormalTok{, }\FloatTok{0.0815521}\NormalTok{)) }
\KeywordTok{stdev}\NormalTok{(equalweightsewma}\OperatorTok{$}\NormalTok{portfolio.returns)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.01718991
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{optweightsewma \textless{}{-}}\StringTok{ }\KeywordTok{c}\NormalTok{(}\FloatTok{0.2502928}\NormalTok{, }\FloatTok{0.5540359}\NormalTok{, }\FloatTok{0.1141192}\NormalTok{, }\FloatTok{0.0815521}\NormalTok{)}
\NormalTok{ModVaR\_}\DecValTok{95}\NormalTok{\_ewma \textless{}{-}}\StringTok{ }\KeywordTok{VaR}\NormalTok{(myPortfolioReturnsR, }\DataTypeTok{p=}\FloatTok{0.95}\NormalTok{,}\DataTypeTok{weights=}\NormalTok{optweightsewma, }\DataTypeTok{portfolio\_method =} \StringTok{"component"}\NormalTok{, }\DataTypeTok{method =} \StringTok{"modified"}\NormalTok{)}
\NormalTok{ModVaR\_}\DecValTok{95}\NormalTok{\_ewma}\OperatorTok{$}\NormalTok{MVaR}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.0271172
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{RealReturns \textless{}{-}}\StringTok{ }\KeywordTok{as.timeSeries}\NormalTok{(myPortfolioReturnsR)}
\NormalTok{minvarRR \textless{}{-}}\StringTok{ }\KeywordTok{minvariancePortfolio}\NormalTok{(RealReturns) }
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{RealReturns2 \textless{}{-}}\StringTok{ }\KeywordTok{as.timeSeries}\NormalTok{(returns)}
\NormalTok{minvarRR2 \textless{}{-}}\StringTok{ }\KeywordTok{minvariancePortfolio}\NormalTok{(RealReturns2) }
\end{Highlighting}
\end{Shaded}

\hypertarget{conclusuxe3o}{%
\chapter*{Conclusão}\label{conclusuxe3o}}
\addcontentsline{toc}{chapter}{Conclusão}

  \bibliography{book.bib,packages.bib}

\part*{Apêndices}
\addcontentsline{toc}{part}{Apêndices}

\newpage
\part*{\normalfont\huge\bfseries\centering Apêndice I - Dados Estatísticos}
\newpage

\begin{center}
 {\normalfont\Large\bfseries EWMA - estatísticas do portfolio}
\end{center}

\begin{center}
\begin{minipage}{0.90\linewidth}
    \centering
    \includegraphics[width=2\textwidth]{image/ewmaport.png}
\end{minipage}
\end{center}

\newpage

\begin{center}
 {\normalfont\Large\bfseries TELEFÓNICA - Modelo GARCH}
\end{center}

\begin{center}
\begin{minipage}{0.90\linewidth}
    \centering
    \includegraphics[width=2\textwidth]{image/garchtef.png}
\end{minipage}
\end{center}

\newpage

\begin{center}
 {\normalfont\Large\bfseries ENEL - Modelo GARCH}
\end{center}

\begin{center}
\begin{minipage}{0.90\linewidth}
    \centering
    \includegraphics[width=2\textwidth]{image/garchenel.png}
\end{minipage}
\end{center}

\newpage

\begin{center}
 {\normalfont\Large\bfseries SOCIÉTÉ GÉNÉRALE - Modelo GARCH}
\end{center}

\begin{center}
\begin{minipage}{0.90\linewidth}
    \centering
    \includegraphics[width=2\textwidth]{image/garchgle.png}
\end{minipage}
\end{center}

\newpage

\begin{center}
 {\normalfont\Large\bfseries AIRBUS - Modelo GARCH - parte 1}
\end{center}

\begin{center}
\begin{minipage}{0.90\linewidth}
    \centering
    \includegraphics[width=2\textwidth]{image/air1.png}
\end{minipage}
\end{center}

\newpage

\begin{center}
 {\normalfont\Large\bfseries AIRBUS - Modelo GARCH - parte 2}
\end{center}

\begin{center}
\begin{minipage}{0.90\linewidth}
    \centering
    \includegraphics[width=2\textwidth]{image/air2.png}
\end{minipage}
\end{center}

\newpage

\begin{center}
 {\normalfont\Large\bfseries GARCH - estatísticas do portfolio}
\end{center}

\begin{center}
\begin{minipage}{0.90\linewidth}
    \centering
    \includegraphics[width=2\textwidth]{image/garchport.png}
\end{minipage}
\end{center}

\newpage

\begin{center}
 {\normalfont\Large\bfseries Volatilidade Implícita -  estatísticas do portfolio}
\end{center}

\begin{center}
\begin{minipage}{0.90\linewidth}
    \centering
    \includegraphics[width=2\textwidth]{image/vi.png}
\end{minipage}
\end{center}

\end{document}
